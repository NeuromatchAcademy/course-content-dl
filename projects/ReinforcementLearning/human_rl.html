
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Using RL to Model Cognitive Tasks &#8212; Neuromatch Academy: Deep Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'projects/ReinforcementLearning/human_rl';</script>
    <link rel="shortcut icon" href="../../_static/nma-dl-logo-square-4xp.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Natural Language Processing" href="../NaturalLanguageProcessing/README.html" />
    <link rel="prev" title="Performance Analysis of DQN Algorithm on the Lunar Lander task" href="lunar_lander.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">
                        Optimization (W1D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">
                        Optimization (W1D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorials/intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/TechnicalHelp/Discord.html">Using Discord</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../prereqs/DeepLearning.html">Prerequisites and preparatory materials for NMA Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics Module</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">Basics And Pytorch (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">Tutorial 1: PyTorch</a></li>









</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">Linear Deep Learning (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">Tutorial 1: Gradient Descent and AutoGrad</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">Tutorial 2: Learning Hyperparameters</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">Tutorial 3: Deep linear neural networks</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">Bonus Lecture: Yoshua Bengio</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">Multi Layer Perceptrons (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">Tutorial 1: Biological vs. Artificial Neural Networks</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">Tutorial 2: Deep MLPs</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Fine Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">Optimization (W1D4)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D4_Optimization/student/W1D4_Tutorial1.html">Tutorial 1: Optimization techniques</a></li>













</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">Regularization (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial1.html">Tutorial 1: Regularization techniques part 1</a></li>









<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial2.html">Tutorial 2: Regularization techniques part 2</a></li>










</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/FineTuning.html">Deep Learning: The Basics and Fine Tuning Wrap-up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ConvNets and Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">Convnets And Dl Thinking (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">Tutorial 1: Introduction to CNNs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">Tutorial 2: Deep Learning Thinking 1: Cost Functions</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">Bonus Lecture: Kyunghyun Cho</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">Modern Convnets (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial1.html">Tutorial 1: Learn how to use modern convnets</a></li>












<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial2.html">Bonus Tutorial: Facial recognition using modern convnets</a></li>






</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">Generative Models (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.html">Tutorial 1: Variational Autoencoders (VAEs)</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial2.html">Tutorial 2: Diffusion models</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial3.html">Tutorial 3: Image, Conditional Diffusion and Beyond</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_BonusLecture.html">Bonus Lecture: Geoffrey Hinton</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">Attention And Transformers (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial1.html">Tutorial 1: Learn how to work with Transformers</a></li>













<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial2.html">Bonus Tutorial: Understanding Pre-training, Fine-tuning and Robustness of Transformers</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">Time Series And Natural Language Processing (W3D1)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial1.html">Tutorial 1: Introduction to processing time series</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial2.html">Tutorial 2: Natural Language Processing and LLMs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial3.html">Bonus Tutorial: Multilingual Embeddings</a></li>



</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">Dl Thinking2 (W3D2)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/student/W3D2_Tutorial1.html">Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking</a></li>








</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">Deep Learning: Convnets and NLP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unsupervised and Reinforcement Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">Unsupervised And Self Supervised Learning (W3D3)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">Tutorial 1: Un/Self-supervised learning methods</a></li>














<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">Bonus Lecture: Melanie Mitchell</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">Basic Reinforcement Learning (W3D4)</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">Tutorial 1: Basic Reinforcement Learning</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">Bonus Lecture: Chealsea Finn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">Reinforcement Learning For Games And Dl Thinking3 (W3D5)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial1.html">Tutorial 1: Reinforcement Learning For Games</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial2.html">Tutorial 2: Deep Learning Thinking 3</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial3.html">Bonus Tutorial: Planning with Monte Carlo Tree Search</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_BonusLecture.html">Bonus Lecture: Amita Kapoor</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deploy Models on the Web</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">Deploy Models (Bonus)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/student/Bonus_Tutorial1.html">Bonus Tutorial: Deploying Neural Networks on the Web</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to projects</a></li>







<li class="toctree-l1"><a class="reference internal" href="../docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modelingsteps/intro.html">Modeling Step-by-Step Guide</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_1through2_DL.html">Modeling Steps 1 - 2</a></li>




<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_3through4_DL.html">Modeling Steps 3 - 4</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_5through6_DL.html">Modeling Steps 5 - 6</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_7through9_DL.html">Modeling Steps 7 - 9</a></li>



<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_10_DL.html">Modeling Steps 10</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionDataProjectDL.html">Example Data Project: the Train Illusion</a></li>













<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionModelingProjectDL.html">Example Model Project: the Train Illusion</a></li>












<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/Example_Deep_Learning_Project.html">Example Deep Learning Project</a></li>












</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../docs/projects_overview.html">Project Templates</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../ComputerVision/README.html">Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/em_synapses.html">Knowledge Extraction from a Convolutional Neural Network</a></li>





<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/spectrogram_analysis.html">Music classification and generation with spectrograms</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/screws.html">Something Screwy - image recognition, detection, and classification of screws</a></li>







<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/data_augmentation.html">Data Augmentation in image classification models</a></li>






<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/transfer_learning.html">Transfer Learning</a></li>



</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="README.html">Reinforcement Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="ideas_and_datasets.html">Ideas</a></li>
<li class="toctree-l3"><a class="reference internal" href="robolympics.html">NMA Robolympics: Controlling robots using reinforcement learning</a></li>








<li class="toctree-l3"><a class="reference internal" href="lunar_lander.html">Performance Analysis of DQN Algorithm on the Lunar Lander task</a></li>






<li class="toctree-l3 current active"><a class="current reference internal" href="#">Using RL to Model Cognitive Tasks</a></li>




</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../NaturalLanguageProcessing/README.html">Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../NaturalLanguageProcessing/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../NaturalLanguageProcessing/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../NaturalLanguageProcessing/sentiment_analysis.html">Twitter Sentiment Analysis</a></li>






<li class="toctree-l3"><a class="reference internal" href="../NaturalLanguageProcessing/machine_translation.html">Machine Translation</a></li>








</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Neuroscience/README.html">Neuroscience</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/pose_estimation.html">Animal Pose Estimation</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/cellular_segmentation.html">Segmentation and Denoising</a></li>





<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/algonauts_videos.html">Load algonauts videos</a></li>



<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/blurry_vision.html">Vision with Lost Glasses: Modelling how the brain deals with noisy input</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/finetuning_fmri.html">Moving beyond Labels: Finetuning CNNs on BOLD response</a></li>




<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/neuro_seq_to_seq.html">Focus on what matters: inferring low-dimensional dynamics from neural recordings</a></li>








</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../docs/datasets_and_models.html">Models and Data sets</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Fprojects/ReinforcementLearning/human_rl.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../_sources/projects/ReinforcementLearning/human_rl.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Using RL to Model Cognitive Tasks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Using RL to Model Cognitive Tasks
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objective">
   Objective
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cognitive-tests-environment">
   Cognitive Tests Environment
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#human-dataset">
     Human dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#environment">
       Environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-a-random-agent">
       Define a random agent
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#initialize-the-environment">
       Initialize the environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-the-loop">
       Run the loop
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="using-rl-to-model-cognitive-tasks">
<h1>Using RL to Model Cognitive Tasks<a class="headerlink" href="#using-rl-to-model-cognitive-tasks" title="Permalink to this heading">#</a></h1>
<p><strong>By Neurmatch Academy</strong></p>
<p><strong>Content creators:</strong> Morteza Ansarinia, Yamil Vidal, Mobin Nesari</p>
<p><strong>Production editor:</strong> Spiros Chavlis</p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="objective">
<h1>Objective<a class="headerlink" href="#objective" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>This project aims to use behavioral data to train an agent and then use the agent to investigate data produced by human subjects. Having a computational agent that mimics humans in such tests, we will be able to compare its mechanics with human data.</p></li>
<li><p>In another conception, we could fit an agent that learns many cognitive tasks that require abstract-level constructs such as executive functions. This is a multi-task control problem.</p></li>
</ul>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># @title Install dependencies
!pip install gymnasium stable-baselines3[extra] matplotlib --quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    <span class=" -Color -Color-Green">965.4/965.4 kB</span> <span class=" -Color -Color-Red">13.1 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">363.4/363.4 MB</span> <span class=" -Color -Color-Red">4.0 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">13.8/13.8 MB</span> <span class=" -Color -Color-Red">132.7 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">24.6/24.6 MB</span> <span class=" -Color -Color-Red">98.3 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">883.7/883.7 kB</span> <span class=" -Color -Color-Red">54.2 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">664.8/664.8 MB</span> <span class=" -Color -Color-Red">2.9 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">211.5/211.5 MB</span> <span class=" -Color -Color-Red">5.7 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">56.3/56.3 MB</span> <span class=" -Color -Color-Red">16.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">127.9/127.9 MB</span> <span class=" -Color -Color-Red">8.0 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">207.5/207.5 MB</span> <span class=" -Color -Color-Red">5.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">21.1/21.1 MB</span> <span class=" -Color -Color-Red">43.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
    <span class=" -Color -Color-Green">184.5/184.5 kB</span> <span class=" -Color -Color-Red">15.5 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Imports</span>
<span class="c1"># Standard Library Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Third-Party Library Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Specific Submodule Imports</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_output</span><span class="p">,</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3</span><span class="w"> </span><span class="kn">import</span> <span class="n">DQN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.monitor</span><span class="w"> </span><span class="kn">import</span> <span class="n">Monitor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.results_plotter</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_results</span><span class="p">,</span> <span class="n">ts2xy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3</span><span class="w"> </span><span class="kn">import</span> <span class="n">DQN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.env_checker</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_env</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure configs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_output</span><span class="p">,</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Make directories</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="s2">&quot;./tmp/gym/&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotter function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_training_results</span><span class="p">(</span><span class="n">log_folder</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Learning Curve&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the training results from a Monitor log file.</span>
<span class="sd">    :param log_folder: (str) the save location of the results to plot</span>
<span class="sd">    :param title: (str) the title of the task to plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ts2xy</span><span class="p">(</span><span class="n">load_results</span><span class="p">(</span><span class="n">log_folder</span><span class="p">),</span> <span class="s1">&#39;timesteps&#39;</span><span class="p">)</span>

    <span class="c1"># The reward in our env is max 32 (1 per step)</span>
    <span class="c1"># We can calculate accuracy from this</span>
    <span class="n">y_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">32.0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Plot 1: Episode Rewards</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Episode Reward&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Plot a rolling average for rewards</span>
    <span class="n">y_rolling</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_rolling</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Rolling Avg (50 episodes)&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># Plot 2: Episode Accuracy</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_acc</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Episode Accuracy (%)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Timesteps&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Plot a rolling average for accuracy</span>
    <span class="n">y_acc_rolling</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_acc</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_acc_rolling</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Rolling Avg (50 episodes)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="background">
<h1>Background<a class="headerlink" href="#background" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Cognitive scientists use standard lab tests to tap into specific processes in the brain and behavior. Some examples of those tests are Stroop, N-back, Digit Span, TMT (Trail making tests), and WCST (Wisconsin Card Sorting Tests).</p></li>
<li><p>Despite an extensive body of research that explains human performance using descriptive what-models, we still need a more sophisticated approach to gain a better understanding of the underlying processes (i.e., a how-model).</p></li>
<li><p>Interestingly, many of such tests can be thought of as a continuous stream of stimuli and corresponding actions, that is in consonant with the RL formulation. In fact, RL itself is in part motivated by how the brain enables goal-directed behaviors using reward systems, making it a good choice to explain human performance.</p></li>
<li><p>One behavioral test example would be the N-back task.</p>
<ul>
<li><p>In the N-back, participants view a sequence of stimuli, one by one, and are asked to categorize each stimulus as being either match or non-match. Stimuli are usually numbers, and feedback is given at both timestep and trajectory levels.</p></li>
<li><p>The agent is rewarded when its response matches the stimulus that was shown N steps back in the episode. A simpler version of the N-back uses two-choice action schema, that is match vs non-match. Once the present stimulus matches the one presented N step back, then the agent is expected to respond to it as being a <code class="docutils literal notranslate"><span class="pre">match</span></code>.</p></li>
</ul>
</li>
<li><p>Given a trained RL agent, we then find correlates of its fitted parameters with the brain mechanisms. The most straightforward composition could be the correlation of model parameters with the brain activities.</p></li>
</ul>
<section id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>HCP WM task (<a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master/projects/fMRI">NMA-CN HCP notebooks</a>)</p></li>
</ul>
<p>Any dataset that used cognitive tests would work.
Question: limit to behavioral data vs fMRI?
Question: Which stimuli and actions to use?
classic tests can be modeled using 1) bounded symbolic stimuli/actions (e.g., A, B, C), but more sophisticated one would require texts or images (e.g., face vs neutral images in social stroop dataset)
The HCP dataset from NMA-CN contains behavioral and imaging data for 7 cognitive tests including various versions of N-back.</p>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="cognitive-tests-environment">
<h1>Cognitive Tests Environment<a class="headerlink" href="#cognitive-tests-environment" title="Permalink to this heading">#</a></h1>
<p>First we develop an environment in that agents perform a cognitive test, here the N-back.</p>
<section id="human-dataset">
<h2>Human dataset<a class="headerlink" href="#human-dataset" title="Permalink to this heading">#</a></h2>
<p>We need a dataset of human perfoming a N-back test, with the following features:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">participant_id</span></code>: following the BIDS format, it contains a unique identifier for each participant.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trial_index</span></code>: same as <code class="docutils literal notranslate"><span class="pre">time_step</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stimulus</span></code>: same as <code class="docutils literal notranslate"><span class="pre">observation</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">response</span></code>: same as <code class="docutils literal notranslate"><span class="pre">action</span></code>, recorded response by the human subject.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">expected_response</span></code>: correct response.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_correct</span></code>: same as <code class="docutils literal notranslate"><span class="pre">reward</span></code>, whether the human subject responded correctly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">response_time</span></code>: wont be used here.</p></li>
</ul>
<p>Here we generate a mock dataset with those features, but remember to <strong>replace this with real human data.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_mock_nback_dataset</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">n_participants</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">n_trials</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                <span class="n">stimulus_choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCDEF&#39;</span><span class="p">),</span>
                                <span class="n">response_choices</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;match&#39;</span><span class="p">,</span> <span class="s1">&#39;non-match&#39;</span><span class="p">]):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Generate a mock dataset for the N-back task.&quot;&quot;&quot;</span>
  <span class="n">n_rows</span> <span class="o">=</span> <span class="n">n_participants</span> <span class="o">*</span> <span class="n">n_trials</span>
  <span class="n">participant_ids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;sub-</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">pid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_participants</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">*</span> <span class="n">n_trials</span><span class="p">)</span>
  <span class="n">trial_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">n_participants</span>
  <span class="n">stimulus_sequence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">stimulus_choices</span><span class="p">,</span> <span class="n">n_rows</span><span class="p">)</span>
  <span class="n">responses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">response_choices</span><span class="p">,</span> <span class="n">n_rows</span><span class="p">)</span>
  <span class="n">response_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_rows</span><span class="p">)</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
      <span class="s1">&#39;participant_id&#39;</span><span class="p">:</span> <span class="n">participant_ids</span><span class="p">,</span>
      <span class="s1">&#39;trial_index&#39;</span><span class="p">:</span> <span class="n">trial_indices</span><span class="p">,</span>
      <span class="s1">&#39;stimulus&#39;</span><span class="p">:</span> <span class="n">stimulus_sequence</span><span class="p">,</span>
      <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="n">responses</span><span class="p">,</span>
      <span class="s1">&#39;response_time&#39;</span><span class="p">:</span> <span class="n">response_times</span>
  <span class="p">})</span>
  <span class="c1"># Mark matching stimuli</span>
  <span class="n">nbackstim</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;stimulus&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;expected_response&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;stimulus&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">nbackstim</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s1">&#39;match&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s1">&#39;non-match&#39;</span><span class="p">})</span>
  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_correct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;expected_response&#39;</span><span class="p">])</span>
  <span class="c1"># We don&#39;t care about burn-in trials (trial &lt; N)</span>
  <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial_index&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">,</span> <span class="s1">&#39;is_correct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial_index&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">,</span> <span class="s1">&#39;response_time&#39;</span><span class="p">,</span> <span class="s1">&#39;expected_response&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ========</span>
<span class="c1"># Generate the actual data with the provided function and plot some of its features</span>
<span class="n">mock_nback_data</span> <span class="o">=</span> <span class="n">generate_mock_nback_dataset</span><span class="p">()</span>
<span class="n">mock_nback_data</span><span class="p">[</span><span class="s1">&#39;is_correct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mock_nback_data</span><span class="p">[</span><span class="s1">&#39;is_correct&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Plot response time distribution</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">mock_nback_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;response_time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Response Time Distribution of the Mock N-back Dataset&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.01</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot accuracy distribution</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">mock_nback_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_correct&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Accuracy Distribution of the Mock N-back Dataset&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.06</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot accuracy by participant</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">mock_nback_data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;is_correct&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;participant_id&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Accuracy Distribution by Participant&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1999e77f1f6b01021c3d8a3d6fa661e8e03447b5ef84c594b65fa4d8c5e563c1.png" src="../../_images/1999e77f1f6b01021c3d8a3d6fa661e8e03447b5ef84c594b65fa4d8c5e563c1.png" />
<img alt="../../_images/4969319ee25e0f019233a1417c131892b4a7b05c10a86a2d3b28de9ea12e6503.png" src="../../_images/4969319ee25e0f019233a1417c131892b4a7b05c10a86a2d3b28de9ea12e6503.png" />
<img alt="../../_images/2d11ff2fac2b0d8dfb378259aed3a108faec9bc634be8303e7adb7b285a28849.png" src="../../_images/2d11ff2fac2b0d8dfb378259aed3a108faec9bc634be8303e7adb7b285a28849.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display the first few rows of the dataframe</span>
<span class="n">mock_nback_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-3ffaf8f8-eada-4c65-85f6-3b7ac158e1da" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>participant_id</th>
      <th>trial_index</th>
      <th>stimulus</th>
      <th>response</th>
      <th>response_time</th>
      <th>expected_response</th>
      <th>is_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>sub-1</td>
      <td>1</td>
      <td>D</td>
      <td>None</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>sub-1</td>
      <td>2</td>
      <td>C</td>
      <td>None</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>sub-1</td>
      <td>3</td>
      <td>F</td>
      <td>match</td>
      <td>0.081122</td>
      <td>non-match</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>sub-1</td>
      <td>4</td>
      <td>E</td>
      <td>match</td>
      <td>1.267059</td>
      <td>non-match</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>sub-1</td>
      <td>5</td>
      <td>B</td>
      <td>non-match</td>
      <td>0.432648</td>
      <td>non-match</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-3ffaf8f8-eada-4c65-85f6-3b7ac158e1da')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-3ffaf8f8-eada-4c65-85f6-3b7ac158e1da button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3ffaf8f8-eada-4c65-85f6-3b7ac158e1da');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-75ba3b95-2449-4227-92c0-461dc4e3dbc2">
      <button class="colab-df-quickchart" onclick="quickchart('df-75ba3b95-2449-4227-92c0-461dc4e3dbc2')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-75ba3b95-2449-4227-92c0-461dc4e3dbc2 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div></div>
</div>
<section id="environment">
<h3>Environment<a class="headerlink" href="#environment" title="Permalink to this heading">#</a></h3>
<p>The following cell implments N-back envinronment, that we later use to train a RL agent on human data. It is capable of performing two kinds of simulation:</p>
<ul class="simple">
<li><p>rewards the agent once the action was correct (i.e., a normative model of the environment).</p></li>
<li><p>receives human data (or mock data if you prefer), and returns what participants performed as the observation. This is more useful for preference-based RL.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">NBack</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An N-Back task environment compatible with the Gymnasium API.</span>

<span class="sd">    The agent&#39;s goal is to determine if the current stimulus matches the one</span>
<span class="sd">    presented N steps ago.</span>

<span class="sd">    Observation:</span>
<span class="sd">        A numpy array of size (episode_steps,), containing the stimuli</span>
<span class="sd">        presented up to the current step, padded with zeros for future steps.</span>
<span class="sd">        Stimuli are encoded as integers.</span>

<span class="sd">    Actions:</span>
<span class="sd">        0: &#39;non-match&#39;</span>
<span class="sd">        1: &#39;match&#39;</span>

<span class="sd">    Reward:</span>
<span class="sd">        +1 for each correct action.</span>
<span class="sd">        0 for each incorrect action.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;render_modes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;human&#39;</span><span class="p">]}</span>
    <span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;non-match&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;match&#39;</span><span class="p">}</span> <span class="c1"># Flipped for easier indexing</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">episode_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">stimuli_choices</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="c1"># Number of distinct stimuli, e.g., 6 for &#39;A&#39;-&#39;F&#39;</span>
                 <span class="n">human_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            N (int): The &#39;N&#39; in N-back. Number of steps to look back.</span>
<span class="sd">            episode_steps (int): The total number of trials in an episode.</span>
<span class="sd">            stimuli_choices (int): The number of unique stimuli.</span>
<span class="sd">            human_data (pd.DataFrame, optional): A DataFrame with human performance</span>
<span class="sd">                data. If provided, the environment can run in imitation mode.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            seed (int, optional): Seed for the random number generator. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_steps</span> <span class="o">=</span> <span class="n">episode_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_stimuli</span> <span class="o">=</span> <span class="n">stimuli_choices</span>

        <span class="c1"># --- Define action and observation spaces ---</span>
        <span class="c1"># Action space: 0 for &#39;non-match&#39;, 1 for &#39;match&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">))</span>

        <span class="c1"># Observation space: The sequence of stimuli seen so far.</span>
        <span class="c1"># We use a Box space, where each element is an integer representing a stimulus.</span>
        <span class="c1"># The shape is the full episode length.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_stimuli</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">episode_steps</span><span class="p">,),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_action_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># --- Human imitation logic (optional) ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_imitate_human</span> <span class="o">=</span> <span class="n">human_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_data</span> <span class="o">=</span> <span class="n">human_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_subject_data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Seed the random number generator</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_np_random</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">seeding</span><span class="o">.</span><span class="n">np_random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_np_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environment to the beginning of a new episode.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_action_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Generate a new sequence of stimuli for the episode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_np_random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_stimuli</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_steps</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># TODO: The human imitation logic from the original code can be ported here</span>
        <span class="c1"># if you need it. For now, it&#39;s simplified to generating random sequences.</span>

        <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_observation</span><span class="p">()</span>
        <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_info</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">observation</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Processes one step of the environment.&quot;&quot;&quot;</span>
        <span class="c1"># Determine the expected correct action</span>
        <span class="n">is_match</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]:</span>
                <span class="n">is_match</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">expected_action</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">is_match</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="c1"># The first N trials don&#39;t have a correct answer, so any action is &quot;correct&quot;</span>
        <span class="c1"># to avoid penalizing the agent.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="n">expected_action</span> <span class="k">else</span> <span class="mf">0.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_action_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">[</span><span class="n">action</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Check for episode termination</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_steps</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Not using truncation here</span>

        <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_observation</span><span class="p">()</span>
        <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_info</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_observation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the current observation for the agent.&quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span><span class="p">)</span>
        <span class="c1"># Agent observes stimuli up to the current trial</span>
        <span class="n">obs</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns auxiliary diagnostic information.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="p">,</span>
            <span class="s2">&quot;stimuli_sequence&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Renders the current state of the environment for visualization.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;human&#39;</span><span class="p">:</span>
            <span class="n">stimuli_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stimuli</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="p">])))</span>
            <span class="n">actions_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;M&#39;</span> <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="s1">&#39;match&#39;</span> <span class="k">else</span> <span class="s1">&#39;.&#39;</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_action_history</span><span class="p">])</span>

            <span class="n">html_content</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;&lt;b&gt;Environment (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="si">}</span><span class="s1">-back) | Step: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_step</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_steps</span><span class="si">}</span><span class="s1">&lt;/b&gt;&lt;br /&gt;&#39;</span>
                <span class="sa">f</span><span class="s1">&#39;&lt;pre style=&quot;font-family: monospace; font-size: 16px;&quot;&gt;&lt;b&gt;Stimuli:&lt;/b&gt; </span><span class="si">{</span><span class="n">stimuli_str</span><span class="si">}</span><span class="s1">&lt;/pre&gt;&#39;</span>
                <span class="sa">f</span><span class="s1">&#39;&lt;pre style=&quot;font-family: monospace; font-size: 16px;&quot;&gt;&lt;b&gt;Actions:&lt;/b&gt; </span><span class="si">{</span><span class="n">actions_str</span><span class="si">}</span><span class="s1">&lt;/pre&gt;&#39;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">HTML</span><span class="p">(</span><span class="n">html_content</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example of how to create and test the environment</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing the NBack Gymnasium Environment...&quot;</span><span class="p">)</span>

<span class="c1"># Create the environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">NBack</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">episode_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Reset the environment</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial Observation Shape: </span><span class="si">{</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Action Space: </span><span class="si">{</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Run one episode with random actions</span>
<span class="k">while</span> <span class="ow">not</span> <span class="n">terminated</span><span class="p">:</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="c1"># Take a random action</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="n">step_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step_count</span><span class="si">}</span><span class="s2">: Action=</span><span class="si">{</span><span class="n">NBack</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="si">}</span><span class="s2">, Reward=</span><span class="si">{</span><span class="n">reward</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Episode Finished.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Steps: </span><span class="si">{</span><span class="n">step_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Display final state</span>
<span class="n">display</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing the NBack Gymnasium Environment...
Initial Observation Shape: (10,)
Action Space: Discrete(2)
Step 1: Action=non-match, Reward=1.0
Step 2: Action=match, Reward=1.0
Step 3: Action=match, Reward=1.0
Step 4: Action=non-match, Reward=1.0
Step 5: Action=non-match, Reward=1.0
Step 6: Action=match, Reward=0.0
Step 7: Action=non-match, Reward=1.0
Step 8: Action=non-match, Reward=0.0
Step 9: Action=non-match, Reward=1.0
Step 10: Action=non-match, Reward=1.0

Episode Finished.
Total Steps: 10
Total Reward: 8.0
</pre></div>
</div>
<div class="output text_html"><b>Environment (2-back) | Step: 10/10</b><br /><pre style="font-family: monospace; font-size: 16px;"><b>Stimuli:</b> 2024013113</pre><pre style="font-family: monospace; font-size: 16px;"><b>Actions:</b> .MM..M....</pre></div></div>
</div>
</section>
<section id="define-a-random-agent">
<h3>Define a random agent<a class="headerlink" href="#define-a-random-agent" title="Permalink to this heading">#</a></h3>
<p>For more information you can refer to NMA-DL W3D2 Basic Reinforcement learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_random_agent_episode</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">render</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs a single episode in the given Gymnasium environment using random actions.</span>

<span class="sd">    Args:</span>
<span class="sd">        env (gym.Env): The Gymnasium environment to run.</span>
<span class="sd">        render (bool): If True, renders the environment state at each step.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing the total reward and the number of steps.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Starting new episode with Random Agent...&quot;</span><span class="p">)</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">terminated</span><span class="p">:</span>
        <span class="c1"># The core of the random agent: sample a random action!</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

        <span class="c1"># Take the action in the environment</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="k">if</span> <span class="n">render</span><span class="p">:</span>
            <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">display</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">())</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Pause for visibility</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Episode finished in </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> steps.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_reward</span><span class="p">,</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>

<span class="c1"># --- Let&#39;s run it! ---</span>
<span class="c1"># Create the NBack environment</span>
<span class="n">nback_env</span> <span class="o">=</span> <span class="n">NBack</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">episode_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Run one full episode with our random agent</span>
<span class="n">run_random_agent_episode</span><span class="p">(</span><span class="n">nback_env</span><span class="p">,</span> <span class="n">render</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Environment (2-back) | Step: 32/32</b><br /><pre style="font-family: monospace; font-size: 16px;"><b>Stimuli:</b> 13443143523400243433200225254031</pre><pre style="font-family: monospace; font-size: 16px;"><b>Actions:</b> M..M.M.MM.M.MMMM.M..MM....MM.MMM</pre></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Episode finished in 32 steps.
 Total Reward: 17.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(17.0, 32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="initialize-the-environment">
<h3>Initialize the environment<a class="headerlink" href="#initialize-the-environment" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an instance of the N-Back environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">NBack</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">episode_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># The &#39;agent&#39; is now just the logic that interacts with the environment,</span>
<span class="c1"># not a separate class instance.</span>

<span class="c1"># Print the environment&#39;s specifications</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Action Space:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Observation Space:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Action Space:
Discrete(2)

Observation Space:
Box(0.0, 5.0, (32,), float32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-the-loop">
<h3>Run the loop<a class="headerlink" href="#run-the-loop" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training parameters</span>
<span class="n">n_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">all_returns</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">total_steps</span> <span class="o">=</span> <span class="mi">0</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">n_episodes</span><span class="si">}</span><span class="s2"> episodes with a Random Agent...&quot;</span><span class="p">)</span>

<span class="c1"># --- Main Loop ---</span>
<span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>
    <span class="n">episode_return</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Reset the environment for a new episode</span>
    <span class="n">observation</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Run the episode</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">terminated</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="c1"># 1. Select a random action (our &quot;Random Agent&quot;)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

        <span class="c1"># 2. Step the environment with the action</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="c1"># 3. Book-keeping</span>
        <span class="n">episode_return</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">total_steps</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># --- End of Episode ---</span>
    <span class="n">all_returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_return</span><span class="p">)</span>

    <span class="c1"># Log results every 100 episodes to avoid too much output</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">episode</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Episode: </span><span class="si">{</span><span class="n">episode</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_episodes</span><span class="si">}</span><span class="s2"> | Return: </span><span class="si">{</span><span class="n">episode_return</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> | Total Steps: </span><span class="si">{</span><span class="n">total_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; All episodes completed.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total steps taken: </span><span class="si">{</span><span class="n">total_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average return per episode: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_returns</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="c1"># --- Final Plot ---</span>
<span class="c1"># Histogram of all returns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">all_returns</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Episode Returns (Random Agent)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Return&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Also show a rolling average of returns to see if there was any learning</span>
<span class="c1"># (There won&#39;t be for a random agent, but this is good practice)</span>
<span class="n">rolling_avg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">all_returns</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rolling_avg</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Rolling Average of Episode Returns (Window=50)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Episode&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Average Return&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> All episodes completed.
Total steps taken: 32000
Average return per episode: 17.10
</pre></div>
</div>
<img alt="../../_images/842664eafb4ee607c22cbd03b0ff797618f5a8cf90996ae6d43256188586ff81.png" src="../../_images/842664eafb4ee607c22cbd03b0ff797618f5a8cf90996ae6d43256188586ff81.png" />
<img alt="../../_images/ea771c7f4db5e033c01bfcd417aa843fc4740a1bf83416932385878d83163755.png" src="../../_images/ea771c7f4db5e033c01bfcd417aa843fc4740a1bf83416932385878d83163755.png" />
</div>
</div>
<p><strong>Note:</strong> You can simplify the environment loop using <a class="reference external" href="https://stable-baselines3.readthedocs.io/en/master/index.html">Stable-Baselines3</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">NBack</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">episode_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">monitored_env</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Define the network architecture</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">net_arch</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>  <span class="c1"># Two hidden layers with 50 neurons each</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Construct the DQN agent</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># - &#39;MlpPolicy&#39;: Use a standard Multi-Layer Perceptron policy.</span>
<span class="c1"># - env: The environment instance for the agent to learn in.</span>
<span class="c1"># - policy_kwargs: Our custom network architecture.</span>
<span class="c1"># - learning_rate: The step size for the optimizer.</span>
<span class="c1"># - buffer_size: The size of the replay buffer.</span>
<span class="c1"># - exploration_initial_eps/exploration_final_eps: To mimic the original</span>
<span class="c1">#   constant epsilon=0.5, we set both to 0.5. For real training, you would</span>
<span class="c1">#   typically anneal this from 1.0 down to a small value.</span>
<span class="c1"># - verbose=1: To print training information.</span>
<span class="c1"># - tensorboard_log: Directory for saving TensorBoard logs.</span>
<span class="c1">#</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span>
    <span class="n">policy</span><span class="o">=</span><span class="s1">&#39;MlpPolicy&#39;</span><span class="p">,</span>
    <span class="n">env</span><span class="o">=</span><span class="n">monitored_env</span><span class="p">,</span>
    <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
    <span class="n">learning_starts</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># Number of steps to collect before training starts</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">train_freq</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">),</span>
    <span class="n">target_update_interval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
    <span class="n">exploration_fraction</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="c1"># Not very relevant if initial and final eps are the same</span>
    <span class="n">exploration_initial_eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">exploration_final_eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;./nback_dqn_tensorboard/&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using cpu device
Wrapping the env in a DummyVecEnv.
</pre></div>
</div>
</div>
</div>
<p>Inspect the agent</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Agent&#39;s Network Architecture ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">policy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Agent created successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Agent&#39;s Network Architecture ---
DQNPolicy(
  (q_net): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): Linear(in_features=32, out_features=50, bias=True)
      (1): ReLU()
      (2): Linear(in_features=50, out_features=50, bias=True)
      (3): ReLU()
      (4): Linear(in_features=50, out_features=2, bias=True)
    )
  )
  (q_net_target): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): Linear(in_features=32, out_features=50, bias=True)
      (1): ReLU()
      (2): Linear(in_features=50, out_features=50, bias=True)
      (3): ReLU()
      (4): Linear(in_features=50, out_features=2, bias=True)
    )
  )
)

Agent created successfully!
</pre></div>
</div>
</div>
</div>
<p>Train the agent</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">episode_steps</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">total_timesteps</span> <span class="o">=</span> <span class="n">n_episodes</span> <span class="o">*</span> <span class="n">episode_steps</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Starting training for </span><span class="si">{</span><span class="n">total_timesteps</span><span class="si">}</span><span class="s2"> timesteps...&quot;</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="n">total_timesteps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Training complete.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Starting training for 32000 timesteps...
Logging to ./nback_dqn_tensorboard/DQN_1
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 15.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 4        |
|    fps              | 567      |
|    time_elapsed     | 0        |
|    total_timesteps  | 128      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.259    |
|    n_updates        | 27       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 17.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 8        |
|    fps              | 480      |
|    time_elapsed     | 0        |
|    total_timesteps  | 256      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.305    |
|    n_updates        | 155      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 19.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 12       |
|    fps              | 491      |
|    time_elapsed     | 0        |
|    total_timesteps  | 384      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0962   |
|    n_updates        | 283      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 16       |
|    fps              | 490      |
|    time_elapsed     | 1        |
|    total_timesteps  | 512      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.272    |
|    n_updates        | 411      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 20       |
|    fps              | 496      |
|    time_elapsed     | 1        |
|    total_timesteps  | 640      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.198    |
|    n_updates        | 539      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 24       |
|    fps              | 508      |
|    time_elapsed     | 1        |
|    total_timesteps  | 768      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.188    |
|    n_updates        | 667      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 28       |
|    fps              | 513      |
|    time_elapsed     | 1        |
|    total_timesteps  | 896      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.221    |
|    n_updates        | 795      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 32       |
|    fps              | 516      |
|    time_elapsed     | 1        |
|    total_timesteps  | 1024     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.212    |
|    n_updates        | 923      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 36       |
|    fps              | 522      |
|    time_elapsed     | 2        |
|    total_timesteps  | 1152     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.111    |
|    n_updates        | 1051     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 40       |
|    fps              | 526      |
|    time_elapsed     | 2        |
|    total_timesteps  | 1280     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.401    |
|    n_updates        | 1179     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.5     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 44       |
|    fps              | 531      |
|    time_elapsed     | 2        |
|    total_timesteps  | 1408     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.208    |
|    n_updates        | 1307     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 48       |
|    fps              | 534      |
|    time_elapsed     | 2        |
|    total_timesteps  | 1536     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.189    |
|    n_updates        | 1435     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 52       |
|    fps              | 532      |
|    time_elapsed     | 3        |
|    total_timesteps  | 1664     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.251    |
|    n_updates        | 1563     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 56       |
|    fps              | 535      |
|    time_elapsed     | 3        |
|    total_timesteps  | 1792     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.145    |
|    n_updates        | 1691     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 60       |
|    fps              | 528      |
|    time_elapsed     | 3        |
|    total_timesteps  | 1920     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.183    |
|    n_updates        | 1819     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 64       |
|    fps              | 521      |
|    time_elapsed     | 3        |
|    total_timesteps  | 2048     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.325    |
|    n_updates        | 1947     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 68       |
|    fps              | 510      |
|    time_elapsed     | 4        |
|    total_timesteps  | 2176     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.11     |
|    n_updates        | 2075     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 72       |
|    fps              | 494      |
|    time_elapsed     | 4        |
|    total_timesteps  | 2304     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.211    |
|    n_updates        | 2203     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 76       |
|    fps              | 482      |
|    time_elapsed     | 5        |
|    total_timesteps  | 2432     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.186    |
|    n_updates        | 2331     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 80       |
|    fps              | 484      |
|    time_elapsed     | 5        |
|    total_timesteps  | 2560     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.272    |
|    n_updates        | 2459     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 20.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 84       |
|    fps              | 487      |
|    time_elapsed     | 5        |
|    total_timesteps  | 2688     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.524    |
|    n_updates        | 2587     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 88       |
|    fps              | 488      |
|    time_elapsed     | 5        |
|    total_timesteps  | 2816     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.2      |
|    n_updates        | 2715     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 92       |
|    fps              | 491      |
|    time_elapsed     | 5        |
|    total_timesteps  | 2944     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.106    |
|    n_updates        | 2843     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 96       |
|    fps              | 492      |
|    time_elapsed     | 6        |
|    total_timesteps  | 3072     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.545    |
|    n_updates        | 2971     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 100      |
|    fps              | 493      |
|    time_elapsed     | 6        |
|    total_timesteps  | 3200     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.233    |
|    n_updates        | 3099     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 104      |
|    fps              | 495      |
|    time_elapsed     | 6        |
|    total_timesteps  | 3328     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.256    |
|    n_updates        | 3227     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 108      |
|    fps              | 497      |
|    time_elapsed     | 6        |
|    total_timesteps  | 3456     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.47     |
|    n_updates        | 3355     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 112      |
|    fps              | 496      |
|    time_elapsed     | 7        |
|    total_timesteps  | 3584     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.225    |
|    n_updates        | 3483     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 116      |
|    fps              | 498      |
|    time_elapsed     | 7        |
|    total_timesteps  | 3712     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.241    |
|    n_updates        | 3611     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 120      |
|    fps              | 501      |
|    time_elapsed     | 7        |
|    total_timesteps  | 3840     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.185    |
|    n_updates        | 3739     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 124      |
|    fps              | 504      |
|    time_elapsed     | 7        |
|    total_timesteps  | 3968     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.48     |
|    n_updates        | 3867     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 128      |
|    fps              | 505      |
|    time_elapsed     | 8        |
|    total_timesteps  | 4096     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.325    |
|    n_updates        | 3995     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 132      |
|    fps              | 507      |
|    time_elapsed     | 8        |
|    total_timesteps  | 4224     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.362    |
|    n_updates        | 4123     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 136      |
|    fps              | 507      |
|    time_elapsed     | 8        |
|    total_timesteps  | 4352     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.266    |
|    n_updates        | 4251     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 140      |
|    fps              | 504      |
|    time_elapsed     | 8        |
|    total_timesteps  | 4480     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.319    |
|    n_updates        | 4379     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 144      |
|    fps              | 504      |
|    time_elapsed     | 9        |
|    total_timesteps  | 4608     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.192    |
|    n_updates        | 4507     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 148      |
|    fps              | 505      |
|    time_elapsed     | 9        |
|    total_timesteps  | 4736     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.207    |
|    n_updates        | 4635     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 152      |
|    fps              | 506      |
|    time_elapsed     | 9        |
|    total_timesteps  | 4864     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.624    |
|    n_updates        | 4763     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.5     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 156      |
|    fps              | 508      |
|    time_elapsed     | 9        |
|    total_timesteps  | 4992     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.183    |
|    n_updates        | 4891     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 160      |
|    fps              | 510      |
|    time_elapsed     | 10       |
|    total_timesteps  | 5120     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.255    |
|    n_updates        | 5019     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 164      |
|    fps              | 510      |
|    time_elapsed     | 10       |
|    total_timesteps  | 5248     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.478    |
|    n_updates        | 5147     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 168      |
|    fps              | 509      |
|    time_elapsed     | 10       |
|    total_timesteps  | 5376     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.191    |
|    n_updates        | 5275     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 172      |
|    fps              | 510      |
|    time_elapsed     | 10       |
|    total_timesteps  | 5504     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.32     |
|    n_updates        | 5403     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 176      |
|    fps              | 511      |
|    time_elapsed     | 11       |
|    total_timesteps  | 5632     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.264    |
|    n_updates        | 5531     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 180      |
|    fps              | 512      |
|    time_elapsed     | 11       |
|    total_timesteps  | 5760     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.305    |
|    n_updates        | 5659     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 184      |
|    fps              | 512      |
|    time_elapsed     | 11       |
|    total_timesteps  | 5888     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.252    |
|    n_updates        | 5787     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 188      |
|    fps              | 512      |
|    time_elapsed     | 11       |
|    total_timesteps  | 6016     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.531    |
|    n_updates        | 5915     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 192      |
|    fps              | 513      |
|    time_elapsed     | 11       |
|    total_timesteps  | 6144     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 6043     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 196      |
|    fps              | 514      |
|    time_elapsed     | 12       |
|    total_timesteps  | 6272     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.476    |
|    n_updates        | 6171     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 200      |
|    fps              | 513      |
|    time_elapsed     | 12       |
|    total_timesteps  | 6400     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.164    |
|    n_updates        | 6299     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 204      |
|    fps              | 512      |
|    time_elapsed     | 12       |
|    total_timesteps  | 6528     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.209    |
|    n_updates        | 6427     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.5     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 208      |
|    fps              | 513      |
|    time_elapsed     | 12       |
|    total_timesteps  | 6656     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.242    |
|    n_updates        | 6555     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 212      |
|    fps              | 513      |
|    time_elapsed     | 13       |
|    total_timesteps  | 6784     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.424    |
|    n_updates        | 6683     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 216      |
|    fps              | 513      |
|    time_elapsed     | 13       |
|    total_timesteps  | 6912     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.234    |
|    n_updates        | 6811     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 220      |
|    fps              | 514      |
|    time_elapsed     | 13       |
|    total_timesteps  | 7040     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.329    |
|    n_updates        | 6939     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 224      |
|    fps              | 514      |
|    time_elapsed     | 13       |
|    total_timesteps  | 7168     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.338    |
|    n_updates        | 7067     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 228      |
|    fps              | 515      |
|    time_elapsed     | 14       |
|    total_timesteps  | 7296     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.389    |
|    n_updates        | 7195     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 232      |
|    fps              | 516      |
|    time_elapsed     | 14       |
|    total_timesteps  | 7424     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.287    |
|    n_updates        | 7323     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 236      |
|    fps              | 517      |
|    time_elapsed     | 14       |
|    total_timesteps  | 7552     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 7451     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 240      |
|    fps              | 518      |
|    time_elapsed     | 14       |
|    total_timesteps  | 7680     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.216    |
|    n_updates        | 7579     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 244      |
|    fps              | 517      |
|    time_elapsed     | 15       |
|    total_timesteps  | 7808     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.284    |
|    n_updates        | 7707     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 248      |
|    fps              | 515      |
|    time_elapsed     | 15       |
|    total_timesteps  | 7936     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.291    |
|    n_updates        | 7835     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 252      |
|    fps              | 514      |
|    time_elapsed     | 15       |
|    total_timesteps  | 8064     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.278    |
|    n_updates        | 7963     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 256      |
|    fps              | 512      |
|    time_elapsed     | 15       |
|    total_timesteps  | 8192     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.181    |
|    n_updates        | 8091     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 260      |
|    fps              | 508      |
|    time_elapsed     | 16       |
|    total_timesteps  | 8320     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.321    |
|    n_updates        | 8219     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 264      |
|    fps              | 508      |
|    time_elapsed     | 16       |
|    total_timesteps  | 8448     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.313    |
|    n_updates        | 8347     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 268      |
|    fps              | 509      |
|    time_elapsed     | 16       |
|    total_timesteps  | 8576     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.275    |
|    n_updates        | 8475     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 272      |
|    fps              | 510      |
|    time_elapsed     | 17       |
|    total_timesteps  | 8704     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.279    |
|    n_updates        | 8603     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 276      |
|    fps              | 511      |
|    time_elapsed     | 17       |
|    total_timesteps  | 8832     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.157    |
|    n_updates        | 8731     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 280      |
|    fps              | 512      |
|    time_elapsed     | 17       |
|    total_timesteps  | 8960     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.355    |
|    n_updates        | 8859     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 284      |
|    fps              | 512      |
|    time_elapsed     | 17       |
|    total_timesteps  | 9088     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.246    |
|    n_updates        | 8987     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 288      |
|    fps              | 513      |
|    time_elapsed     | 17       |
|    total_timesteps  | 9216     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.262    |
|    n_updates        | 9115     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 292      |
|    fps              | 513      |
|    time_elapsed     | 18       |
|    total_timesteps  | 9344     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.461    |
|    n_updates        | 9243     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 296      |
|    fps              | 513      |
|    time_elapsed     | 18       |
|    total_timesteps  | 9472     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.353    |
|    n_updates        | 9371     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 300      |
|    fps              | 512      |
|    time_elapsed     | 18       |
|    total_timesteps  | 9600     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.346    |
|    n_updates        | 9499     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 304      |
|    fps              | 513      |
|    time_elapsed     | 18       |
|    total_timesteps  | 9728     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.281    |
|    n_updates        | 9627     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 308      |
|    fps              | 514      |
|    time_elapsed     | 19       |
|    total_timesteps  | 9856     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.299    |
|    n_updates        | 9755     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 312      |
|    fps              | 513      |
|    time_elapsed     | 19       |
|    total_timesteps  | 9984     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.181    |
|    n_updates        | 9883     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 316      |
|    fps              | 513      |
|    time_elapsed     | 19       |
|    total_timesteps  | 10112    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.386    |
|    n_updates        | 10011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 320      |
|    fps              | 514      |
|    time_elapsed     | 19       |
|    total_timesteps  | 10240    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.269    |
|    n_updates        | 10139    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 324      |
|    fps              | 515      |
|    time_elapsed     | 20       |
|    total_timesteps  | 10368    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.402    |
|    n_updates        | 10267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 328      |
|    fps              | 515      |
|    time_elapsed     | 20       |
|    total_timesteps  | 10496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.268    |
|    n_updates        | 10395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 332      |
|    fps              | 516      |
|    time_elapsed     | 20       |
|    total_timesteps  | 10624    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.266    |
|    n_updates        | 10523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 336      |
|    fps              | 516      |
|    time_elapsed     | 20       |
|    total_timesteps  | 10752    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.219    |
|    n_updates        | 10651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 340      |
|    fps              | 516      |
|    time_elapsed     | 21       |
|    total_timesteps  | 10880    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.37     |
|    n_updates        | 10779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 344      |
|    fps              | 516      |
|    time_elapsed     | 21       |
|    total_timesteps  | 11008    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.241    |
|    n_updates        | 10907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 348      |
|    fps              | 516      |
|    time_elapsed     | 21       |
|    total_timesteps  | 11136    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.299    |
|    n_updates        | 11035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 352      |
|    fps              | 516      |
|    time_elapsed     | 21       |
|    total_timesteps  | 11264    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.311    |
|    n_updates        | 11163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 356      |
|    fps              | 517      |
|    time_elapsed     | 22       |
|    total_timesteps  | 11392    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0982   |
|    n_updates        | 11291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 360      |
|    fps              | 517      |
|    time_elapsed     | 22       |
|    total_timesteps  | 11520    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 11419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 364      |
|    fps              | 518      |
|    time_elapsed     | 22       |
|    total_timesteps  | 11648    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.287    |
|    n_updates        | 11547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 368      |
|    fps              | 517      |
|    time_elapsed     | 22       |
|    total_timesteps  | 11776    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.311    |
|    n_updates        | 11675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 372      |
|    fps              | 518      |
|    time_elapsed     | 22       |
|    total_timesteps  | 11904    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.259    |
|    n_updates        | 11803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 376      |
|    fps              | 518      |
|    time_elapsed     | 23       |
|    total_timesteps  | 12032    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.249    |
|    n_updates        | 11931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 380      |
|    fps              | 519      |
|    time_elapsed     | 23       |
|    total_timesteps  | 12160    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.302    |
|    n_updates        | 12059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 384      |
|    fps              | 519      |
|    time_elapsed     | 23       |
|    total_timesteps  | 12288    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.31     |
|    n_updates        | 12187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 388      |
|    fps              | 520      |
|    time_elapsed     | 23       |
|    total_timesteps  | 12416    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.248    |
|    n_updates        | 12315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 392      |
|    fps              | 520      |
|    time_elapsed     | 24       |
|    total_timesteps  | 12544    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.152    |
|    n_updates        | 12443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 396      |
|    fps              | 520      |
|    time_elapsed     | 24       |
|    total_timesteps  | 12672    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.2      |
|    n_updates        | 12571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 400      |
|    fps              | 520      |
|    time_elapsed     | 24       |
|    total_timesteps  | 12800    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.139    |
|    n_updates        | 12699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 404      |
|    fps              | 520      |
|    time_elapsed     | 24       |
|    total_timesteps  | 12928    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.289    |
|    n_updates        | 12827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 408      |
|    fps              | 521      |
|    time_elapsed     | 25       |
|    total_timesteps  | 13056    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.357    |
|    n_updates        | 12955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 412      |
|    fps              | 521      |
|    time_elapsed     | 25       |
|    total_timesteps  | 13184    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.33     |
|    n_updates        | 13083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 416      |
|    fps              | 521      |
|    time_elapsed     | 25       |
|    total_timesteps  | 13312    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.377    |
|    n_updates        | 13211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 420      |
|    fps              | 522      |
|    time_elapsed     | 25       |
|    total_timesteps  | 13440    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.217    |
|    n_updates        | 13339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 424      |
|    fps              | 522      |
|    time_elapsed     | 25       |
|    total_timesteps  | 13568    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.333    |
|    n_updates        | 13467    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 428      |
|    fps              | 523      |
|    time_elapsed     | 26       |
|    total_timesteps  | 13696    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.183    |
|    n_updates        | 13595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 432      |
|    fps              | 522      |
|    time_elapsed     | 26       |
|    total_timesteps  | 13824    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.216    |
|    n_updates        | 13723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 436      |
|    fps              | 521      |
|    time_elapsed     | 26       |
|    total_timesteps  | 13952    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.33     |
|    n_updates        | 13851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 440      |
|    fps              | 521      |
|    time_elapsed     | 27       |
|    total_timesteps  | 14080    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.231    |
|    n_updates        | 13979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 444      |
|    fps              | 520      |
|    time_elapsed     | 27       |
|    total_timesteps  | 14208    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.387    |
|    n_updates        | 14107    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 448      |
|    fps              | 518      |
|    time_elapsed     | 27       |
|    total_timesteps  | 14336    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.294    |
|    n_updates        | 14235    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 452      |
|    fps              | 518      |
|    time_elapsed     | 27       |
|    total_timesteps  | 14464    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 14363    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 456      |
|    fps              | 518      |
|    time_elapsed     | 28       |
|    total_timesteps  | 14592    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.392    |
|    n_updates        | 14491    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 460      |
|    fps              | 519      |
|    time_elapsed     | 28       |
|    total_timesteps  | 14720    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.185    |
|    n_updates        | 14619    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 464      |
|    fps              | 519      |
|    time_elapsed     | 28       |
|    total_timesteps  | 14848    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.177    |
|    n_updates        | 14747    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 468      |
|    fps              | 519      |
|    time_elapsed     | 28       |
|    total_timesteps  | 14976    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.261    |
|    n_updates        | 14875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 472      |
|    fps              | 519      |
|    time_elapsed     | 29       |
|    total_timesteps  | 15104    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.254    |
|    n_updates        | 15003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 476      |
|    fps              | 519      |
|    time_elapsed     | 29       |
|    total_timesteps  | 15232    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.225    |
|    n_updates        | 15131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 480      |
|    fps              | 520      |
|    time_elapsed     | 29       |
|    total_timesteps  | 15360    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.204    |
|    n_updates        | 15259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 484      |
|    fps              | 519      |
|    time_elapsed     | 29       |
|    total_timesteps  | 15488    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.248    |
|    n_updates        | 15387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 488      |
|    fps              | 519      |
|    time_elapsed     | 30       |
|    total_timesteps  | 15616    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 15515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 492      |
|    fps              | 519      |
|    time_elapsed     | 30       |
|    total_timesteps  | 15744    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.191    |
|    n_updates        | 15643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 496      |
|    fps              | 518      |
|    time_elapsed     | 30       |
|    total_timesteps  | 15872    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.176    |
|    n_updates        | 15771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 500      |
|    fps              | 519      |
|    time_elapsed     | 30       |
|    total_timesteps  | 16000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.246    |
|    n_updates        | 15899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 504      |
|    fps              | 519      |
|    time_elapsed     | 31       |
|    total_timesteps  | 16128    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.23     |
|    n_updates        | 16027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 508      |
|    fps              | 519      |
|    time_elapsed     | 31       |
|    total_timesteps  | 16256    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.305    |
|    n_updates        | 16155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 512      |
|    fps              | 519      |
|    time_elapsed     | 31       |
|    total_timesteps  | 16384    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.294    |
|    n_updates        | 16283    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 516      |
|    fps              | 520      |
|    time_elapsed     | 31       |
|    total_timesteps  | 16512    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.235    |
|    n_updates        | 16411    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 520      |
|    fps              | 520      |
|    time_elapsed     | 31       |
|    total_timesteps  | 16640    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.273    |
|    n_updates        | 16539    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 524      |
|    fps              | 521      |
|    time_elapsed     | 32       |
|    total_timesteps  | 16768    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.264    |
|    n_updates        | 16667    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 528      |
|    fps              | 521      |
|    time_elapsed     | 32       |
|    total_timesteps  | 16896    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.254    |
|    n_updates        | 16795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 532      |
|    fps              | 522      |
|    time_elapsed     | 32       |
|    total_timesteps  | 17024    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.253    |
|    n_updates        | 16923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 536      |
|    fps              | 517      |
|    time_elapsed     | 33       |
|    total_timesteps  | 17152    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.237    |
|    n_updates        | 17051    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 540      |
|    fps              | 518      |
|    time_elapsed     | 33       |
|    total_timesteps  | 17280    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.236    |
|    n_updates        | 17179    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 544      |
|    fps              | 514      |
|    time_elapsed     | 33       |
|    total_timesteps  | 17408    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.301    |
|    n_updates        | 17307    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 548      |
|    fps              | 514      |
|    time_elapsed     | 34       |
|    total_timesteps  | 17536    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.237    |
|    n_updates        | 17435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 552      |
|    fps              | 514      |
|    time_elapsed     | 34       |
|    total_timesteps  | 17664    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.303    |
|    n_updates        | 17563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 556      |
|    fps              | 511      |
|    time_elapsed     | 34       |
|    total_timesteps  | 17792    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.411    |
|    n_updates        | 17691    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 560      |
|    fps              | 511      |
|    time_elapsed     | 35       |
|    total_timesteps  | 17920    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.352    |
|    n_updates        | 17819    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 564      |
|    fps              | 511      |
|    time_elapsed     | 35       |
|    total_timesteps  | 18048    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.345    |
|    n_updates        | 17947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 568      |
|    fps              | 512      |
|    time_elapsed     | 35       |
|    total_timesteps  | 18176    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.327    |
|    n_updates        | 18075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 572      |
|    fps              | 512      |
|    time_elapsed     | 35       |
|    total_timesteps  | 18304    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.255    |
|    n_updates        | 18203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 576      |
|    fps              | 512      |
|    time_elapsed     | 35       |
|    total_timesteps  | 18432    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.233    |
|    n_updates        | 18331    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 580      |
|    fps              | 512      |
|    time_elapsed     | 36       |
|    total_timesteps  | 18560    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.173    |
|    n_updates        | 18459    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 584      |
|    fps              | 513      |
|    time_elapsed     | 36       |
|    total_timesteps  | 18688    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.297    |
|    n_updates        | 18587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 588      |
|    fps              | 513      |
|    time_elapsed     | 36       |
|    total_timesteps  | 18816    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.176    |
|    n_updates        | 18715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 592      |
|    fps              | 513      |
|    time_elapsed     | 36       |
|    total_timesteps  | 18944    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.273    |
|    n_updates        | 18843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 596      |
|    fps              | 512      |
|    time_elapsed     | 37       |
|    total_timesteps  | 19072    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.33     |
|    n_updates        | 18971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 600      |
|    fps              | 512      |
|    time_elapsed     | 37       |
|    total_timesteps  | 19200    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.231    |
|    n_updates        | 19099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 604      |
|    fps              | 510      |
|    time_elapsed     | 37       |
|    total_timesteps  | 19328    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.235    |
|    n_updates        | 19227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 608      |
|    fps              | 508      |
|    time_elapsed     | 38       |
|    total_timesteps  | 19456    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.255    |
|    n_updates        | 19355    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 612      |
|    fps              | 507      |
|    time_elapsed     | 38       |
|    total_timesteps  | 19584    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.287    |
|    n_updates        | 19483    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 616      |
|    fps              | 505      |
|    time_elapsed     | 39       |
|    total_timesteps  | 19712    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.192    |
|    n_updates        | 19611    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 620      |
|    fps              | 503      |
|    time_elapsed     | 39       |
|    total_timesteps  | 19840    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.227    |
|    n_updates        | 19739    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 624      |
|    fps              | 503      |
|    time_elapsed     | 39       |
|    total_timesteps  | 19968    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.292    |
|    n_updates        | 19867    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 628      |
|    fps              | 503      |
|    time_elapsed     | 39       |
|    total_timesteps  | 20096    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.313    |
|    n_updates        | 19995    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 632      |
|    fps              | 504      |
|    time_elapsed     | 40       |
|    total_timesteps  | 20224    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.202    |
|    n_updates        | 20123    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 636      |
|    fps              | 504      |
|    time_elapsed     | 40       |
|    total_timesteps  | 20352    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.238    |
|    n_updates        | 20251    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 640      |
|    fps              | 504      |
|    time_elapsed     | 40       |
|    total_timesteps  | 20480    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.328    |
|    n_updates        | 20379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 644      |
|    fps              | 504      |
|    time_elapsed     | 40       |
|    total_timesteps  | 20608    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.299    |
|    n_updates        | 20507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 648      |
|    fps              | 505      |
|    time_elapsed     | 41       |
|    total_timesteps  | 20736    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.246    |
|    n_updates        | 20635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 652      |
|    fps              | 505      |
|    time_elapsed     | 41       |
|    total_timesteps  | 20864    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.24     |
|    n_updates        | 20763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 656      |
|    fps              | 506      |
|    time_elapsed     | 41       |
|    total_timesteps  | 20992    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.301    |
|    n_updates        | 20891    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 660      |
|    fps              | 506      |
|    time_elapsed     | 41       |
|    total_timesteps  | 21120    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.275    |
|    n_updates        | 21019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 664      |
|    fps              | 506      |
|    time_elapsed     | 41       |
|    total_timesteps  | 21248    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.322    |
|    n_updates        | 21147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 668      |
|    fps              | 506      |
|    time_elapsed     | 42       |
|    total_timesteps  | 21376    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.167    |
|    n_updates        | 21275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 672      |
|    fps              | 506      |
|    time_elapsed     | 42       |
|    total_timesteps  | 21504    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.21     |
|    n_updates        | 21403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 676      |
|    fps              | 506      |
|    time_elapsed     | 42       |
|    total_timesteps  | 21632    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.21     |
|    n_updates        | 21531    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 680      |
|    fps              | 507      |
|    time_elapsed     | 42       |
|    total_timesteps  | 21760    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.227    |
|    n_updates        | 21659    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 684      |
|    fps              | 507      |
|    time_elapsed     | 43       |
|    total_timesteps  | 21888    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.172    |
|    n_updates        | 21787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 688      |
|    fps              | 507      |
|    time_elapsed     | 43       |
|    total_timesteps  | 22016    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.321    |
|    n_updates        | 21915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 692      |
|    fps              | 507      |
|    time_elapsed     | 43       |
|    total_timesteps  | 22144    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.185    |
|    n_updates        | 22043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 696      |
|    fps              | 507      |
|    time_elapsed     | 43       |
|    total_timesteps  | 22272    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.292    |
|    n_updates        | 22171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 700      |
|    fps              | 507      |
|    time_elapsed     | 44       |
|    total_timesteps  | 22400    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.452    |
|    n_updates        | 22299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 704      |
|    fps              | 508      |
|    time_elapsed     | 44       |
|    total_timesteps  | 22528    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.389    |
|    n_updates        | 22427    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 708      |
|    fps              | 508      |
|    time_elapsed     | 44       |
|    total_timesteps  | 22656    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.256    |
|    n_updates        | 22555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 712      |
|    fps              | 508      |
|    time_elapsed     | 44       |
|    total_timesteps  | 22784    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.312    |
|    n_updates        | 22683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 716      |
|    fps              | 508      |
|    time_elapsed     | 45       |
|    total_timesteps  | 22912    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.317    |
|    n_updates        | 22811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 720      |
|    fps              | 508      |
|    time_elapsed     | 45       |
|    total_timesteps  | 23040    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.307    |
|    n_updates        | 22939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 724      |
|    fps              | 509      |
|    time_elapsed     | 45       |
|    total_timesteps  | 23168    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.289    |
|    n_updates        | 23067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 728      |
|    fps              | 509      |
|    time_elapsed     | 45       |
|    total_timesteps  | 23296    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.233    |
|    n_updates        | 23195    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 732      |
|    fps              | 509      |
|    time_elapsed     | 45       |
|    total_timesteps  | 23424    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.269    |
|    n_updates        | 23323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 736      |
|    fps              | 509      |
|    time_elapsed     | 46       |
|    total_timesteps  | 23552    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.389    |
|    n_updates        | 23451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 740      |
|    fps              | 509      |
|    time_elapsed     | 46       |
|    total_timesteps  | 23680    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.198    |
|    n_updates        | 23579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 744      |
|    fps              | 509      |
|    time_elapsed     | 46       |
|    total_timesteps  | 23808    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.184    |
|    n_updates        | 23707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 748      |
|    fps              | 510      |
|    time_elapsed     | 46       |
|    total_timesteps  | 23936    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.204    |
|    n_updates        | 23835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 752      |
|    fps              | 510      |
|    time_elapsed     | 47       |
|    total_timesteps  | 24064    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.336    |
|    n_updates        | 23963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 756      |
|    fps              | 511      |
|    time_elapsed     | 47       |
|    total_timesteps  | 24192    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.231    |
|    n_updates        | 24091    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 760      |
|    fps              | 511      |
|    time_elapsed     | 47       |
|    total_timesteps  | 24320    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.308    |
|    n_updates        | 24219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 764      |
|    fps              | 511      |
|    time_elapsed     | 47       |
|    total_timesteps  | 24448    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.36     |
|    n_updates        | 24347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 768      |
|    fps              | 511      |
|    time_elapsed     | 48       |
|    total_timesteps  | 24576    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.269    |
|    n_updates        | 24475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 772      |
|    fps              | 512      |
|    time_elapsed     | 48       |
|    total_timesteps  | 24704    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.294    |
|    n_updates        | 24603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 776      |
|    fps              | 512      |
|    time_elapsed     | 48       |
|    total_timesteps  | 24832    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.319    |
|    n_updates        | 24731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.4     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 780      |
|    fps              | 511      |
|    time_elapsed     | 48       |
|    total_timesteps  | 24960    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.229    |
|    n_updates        | 24859    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 784      |
|    fps              | 511      |
|    time_elapsed     | 49       |
|    total_timesteps  | 25088    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.319    |
|    n_updates        | 24987    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.3     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 788      |
|    fps              | 510      |
|    time_elapsed     | 49       |
|    total_timesteps  | 25216    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.301    |
|    n_updates        | 25115    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 792      |
|    fps              | 508      |
|    time_elapsed     | 49       |
|    total_timesteps  | 25344    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.282    |
|    n_updates        | 25243    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 796      |
|    fps              | 508      |
|    time_elapsed     | 50       |
|    total_timesteps  | 25472    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.203    |
|    n_updates        | 25371    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 800      |
|    fps              | 507      |
|    time_elapsed     | 50       |
|    total_timesteps  | 25600    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.284    |
|    n_updates        | 25499    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 804      |
|    fps              | 506      |
|    time_elapsed     | 50       |
|    total_timesteps  | 25728    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.225    |
|    n_updates        | 25627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 808      |
|    fps              | 506      |
|    time_elapsed     | 51       |
|    total_timesteps  | 25856    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.168    |
|    n_updates        | 25755    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 812      |
|    fps              | 507      |
|    time_elapsed     | 51       |
|    total_timesteps  | 25984    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.352    |
|    n_updates        | 25883    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.2     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 816      |
|    fps              | 507      |
|    time_elapsed     | 51       |
|    total_timesteps  | 26112    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.309    |
|    n_updates        | 26011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 820      |
|    fps              | 507      |
|    time_elapsed     | 51       |
|    total_timesteps  | 26240    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.213    |
|    n_updates        | 26139    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22.1     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 824      |
|    fps              | 507      |
|    time_elapsed     | 51       |
|    total_timesteps  | 26368    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.217    |
|    n_updates        | 26267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 828      |
|    fps              | 507      |
|    time_elapsed     | 52       |
|    total_timesteps  | 26496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.269    |
|    n_updates        | 26395    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 832      |
|    fps              | 508      |
|    time_elapsed     | 52       |
|    total_timesteps  | 26624    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.29     |
|    n_updates        | 26523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 836      |
|    fps              | 508      |
|    time_elapsed     | 52       |
|    total_timesteps  | 26752    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.235    |
|    n_updates        | 26651    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 22       |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 840      |
|    fps              | 508      |
|    time_elapsed     | 52       |
|    total_timesteps  | 26880    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.334    |
|    n_updates        | 26779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 844      |
|    fps              | 508      |
|    time_elapsed     | 53       |
|    total_timesteps  | 27008    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.324    |
|    n_updates        | 26907    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 848      |
|    fps              | 509      |
|    time_elapsed     | 53       |
|    total_timesteps  | 27136    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.256    |
|    n_updates        | 27035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 852      |
|    fps              | 508      |
|    time_elapsed     | 53       |
|    total_timesteps  | 27264    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.256    |
|    n_updates        | 27163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 856      |
|    fps              | 508      |
|    time_elapsed     | 53       |
|    total_timesteps  | 27392    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.326    |
|    n_updates        | 27291    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 860      |
|    fps              | 508      |
|    time_elapsed     | 54       |
|    total_timesteps  | 27520    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.166    |
|    n_updates        | 27419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 864      |
|    fps              | 508      |
|    time_elapsed     | 54       |
|    total_timesteps  | 27648    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.322    |
|    n_updates        | 27547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 868      |
|    fps              | 508      |
|    time_elapsed     | 54       |
|    total_timesteps  | 27776    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.258    |
|    n_updates        | 27675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 872      |
|    fps              | 508      |
|    time_elapsed     | 54       |
|    total_timesteps  | 27904    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.413    |
|    n_updates        | 27803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 876      |
|    fps              | 508      |
|    time_elapsed     | 55       |
|    total_timesteps  | 28032    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.228    |
|    n_updates        | 27931    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.9     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 880      |
|    fps              | 508      |
|    time_elapsed     | 55       |
|    total_timesteps  | 28160    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.302    |
|    n_updates        | 28059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 884      |
|    fps              | 508      |
|    time_elapsed     | 55       |
|    total_timesteps  | 28288    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.415    |
|    n_updates        | 28187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 888      |
|    fps              | 508      |
|    time_elapsed     | 55       |
|    total_timesteps  | 28416    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.284    |
|    n_updates        | 28315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 892      |
|    fps              | 508      |
|    time_elapsed     | 56       |
|    total_timesteps  | 28544    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.308    |
|    n_updates        | 28443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 896      |
|    fps              | 508      |
|    time_elapsed     | 56       |
|    total_timesteps  | 28672    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.28     |
|    n_updates        | 28571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 900      |
|    fps              | 508      |
|    time_elapsed     | 56       |
|    total_timesteps  | 28800    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.208    |
|    n_updates        | 28699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 904      |
|    fps              | 507      |
|    time_elapsed     | 56       |
|    total_timesteps  | 28928    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.165    |
|    n_updates        | 28827    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 908      |
|    fps              | 507      |
|    time_elapsed     | 57       |
|    total_timesteps  | 29056    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.268    |
|    n_updates        | 28955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 912      |
|    fps              | 507      |
|    time_elapsed     | 57       |
|    total_timesteps  | 29184    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.221    |
|    n_updates        | 29083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 916      |
|    fps              | 508      |
|    time_elapsed     | 57       |
|    total_timesteps  | 29312    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.356    |
|    n_updates        | 29211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 920      |
|    fps              | 507      |
|    time_elapsed     | 57       |
|    total_timesteps  | 29440    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.343    |
|    n_updates        | 29339    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 924      |
|    fps              | 507      |
|    time_elapsed     | 58       |
|    total_timesteps  | 29568    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.208    |
|    n_updates        | 29467    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 928      |
|    fps              | 507      |
|    time_elapsed     | 58       |
|    total_timesteps  | 29696    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.305    |
|    n_updates        | 29595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 932      |
|    fps              | 507      |
|    time_elapsed     | 58       |
|    total_timesteps  | 29824    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.323    |
|    n_updates        | 29723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 936      |
|    fps              | 507      |
|    time_elapsed     | 59       |
|    total_timesteps  | 29952    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.397    |
|    n_updates        | 29851    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 940      |
|    fps              | 507      |
|    time_elapsed     | 59       |
|    total_timesteps  | 30080    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.506    |
|    n_updates        | 29979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 944      |
|    fps              | 507      |
|    time_elapsed     | 59       |
|    total_timesteps  | 30208    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.308    |
|    n_updates        | 30107    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 948      |
|    fps              | 507      |
|    time_elapsed     | 59       |
|    total_timesteps  | 30336    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.351    |
|    n_updates        | 30235    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 952      |
|    fps              | 507      |
|    time_elapsed     | 59       |
|    total_timesteps  | 30464    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.192    |
|    n_updates        | 30363    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.8     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 956      |
|    fps              | 508      |
|    time_elapsed     | 60       |
|    total_timesteps  | 30592    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.179    |
|    n_updates        | 30491    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 960      |
|    fps              | 508      |
|    time_elapsed     | 60       |
|    total_timesteps  | 30720    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.192    |
|    n_updates        | 30619    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 964      |
|    fps              | 507      |
|    time_elapsed     | 60       |
|    total_timesteps  | 30848    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.273    |
|    n_updates        | 30747    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 968      |
|    fps              | 506      |
|    time_elapsed     | 61       |
|    total_timesteps  | 30976    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.176    |
|    n_updates        | 30875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 972      |
|    fps              | 505      |
|    time_elapsed     | 61       |
|    total_timesteps  | 31104    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.217    |
|    n_updates        | 31003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 976      |
|    fps              | 504      |
|    time_elapsed     | 61       |
|    total_timesteps  | 31232    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.267    |
|    n_updates        | 31131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.5     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 980      |
|    fps              | 504      |
|    time_elapsed     | 62       |
|    total_timesteps  | 31360    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.212    |
|    n_updates        | 31259    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 984      |
|    fps              | 504      |
|    time_elapsed     | 62       |
|    total_timesteps  | 31488    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.247    |
|    n_updates        | 31387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.5     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 988      |
|    fps              | 503      |
|    time_elapsed     | 62       |
|    total_timesteps  | 31616    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.336    |
|    n_updates        | 31515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 992      |
|    fps              | 504      |
|    time_elapsed     | 62       |
|    total_timesteps  | 31744    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.411    |
|    n_updates        | 31643    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.6     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 996      |
|    fps              | 503      |
|    time_elapsed     | 63       |
|    total_timesteps  | 31872    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.327    |
|    n_updates        | 31771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 21.7     |
|    exploration_rate | 0.5      |
| time/               |          |
|    episodes         | 1000     |
|    fps              | 504      |
|    time_elapsed     | 63       |
|    total_timesteps  | 32000    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.19     |
|    n_updates        | 31899    |
----------------------------------
 Training complete.
</pre></div>
</div>
</div>
</div>
<p>Plot agents result</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_training_results</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s2">&quot;DQN Training on N-Back Task&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/913e97b42d110246f9e3460e6d4e4157ea00a0adcc2fdbe33adbf6f7c2518359.png" src="../../_images/913e97b42d110246f9e3460e6d4e4157ea00a0adcc2fdbe33adbf6f7c2518359.png" />
</div>
</div>
<p>Inspect logs as dataframe</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">log_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s2">&quot;monitor.csv&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">log_file_path</span><span class="p">):</span>
    <span class="n">logs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">log_file_path</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Skip the header row</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Training Logs (last 5 episodes) ---&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">logs_df</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Could not find the monitor log file.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Training Logs (last 5 episodes) ---
        r   l          t
995  21.0  32  73.091478
996  23.0  32  73.160453
997  24.0  32  73.219404
998  22.0  32  73.273850
999  23.0  32  73.332403
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./projects/ReinforcementLearning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="lunar_lander.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Performance Analysis of DQN Algorithm on the Lunar Lander task</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="../NaturalLanguageProcessing/README.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Natural Language Processing</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Using RL to Model Cognitive Tasks
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objective">
   Objective
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cognitive-tests-environment">
   Cognitive Tests Environment
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#human-dataset">
     Human dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#environment">
       Environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-a-random-agent">
       Define a random agent
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#initialize-the-environment">
       Initialize the environment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-the-loop">
       Run the loop
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Neuromatch
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>

</div>
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>