{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f7f86654b2b4bd3b13f0f88816c0727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5c36dd45d1d4cae87596d92c91599d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1db01cbf7a3b4912adef0bc2427761f5",
              "IPY_MODEL_45caa2849d3c4f4b82ba93d19fe98685"
            ]
          }
        },
        "c5c36dd45d1d4cae87596d92c91599d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1db01cbf7a3b4912adef0bc2427761f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bdf05b823e1a46c19d60844ffb82a949",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97d834f46c304593b2141364e1ef0b6a"
          }
        },
        "45caa2849d3c4f4b82ba93d19fe98685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a2563bba82642a8accb139d3b40873c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:55&lt;00:00, 3019908.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4998e0b9581042eaa87f8910e908772e"
          }
        },
        "bdf05b823e1a46c19d60844ffb82a949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97d834f46c304593b2141364e1ef0b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a2563bba82642a8accb139d3b40873c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4998e0b9581042eaa87f8910e908772e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "061aeb49a97a44f0a8e844852e535ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b1fa6fbd29542c781d1302fbb51ce58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7eedeab6745746398ae84566eee4d1a3",
              "IPY_MODEL_6e3d9b4937de4364b1ce1abe93d977af"
            ]
          }
        },
        "4b1fa6fbd29542c781d1302fbb51ce58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eedeab6745746398ae84566eee4d1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_442e5135cf304e70bbd39dbb6b8e56e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8f498014b95403f946c5776b91cefa3"
          }
        },
        "6e3d9b4937de4364b1ce1abe93d977af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef5482b131a840aa92ab1942448a1c41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [01:25&lt;00:00, 1984513.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1eb405b5bc646d29cbe9b99ad0bbeab"
          }
        },
        "442e5135cf304e70bbd39dbb6b8e56e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8f498014b95403f946c5776b91cefa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef5482b131a840aa92ab1942448a1c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1eb405b5bc646d29cbe9b99ad0bbeab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/waxing_projects/projects/ComputerVision/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kpc_IPHzR1V"
      },
      "source": [
        "# Transfer Learning \n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ [Jama Hussein Mohamud](https://engmubarak48.github.io/jmohamud/index.html) & [Alex Hernandez-Garcia](https://alexhernandezgarcia.github.io/)\n",
        "\n",
        "__Production editors:__ Spiros Chavlis, Saeed Salehi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHCbTQtzrH_"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSN-hSJnzrKt"
      },
      "source": [
        "---\n",
        "# Project Objective:\n",
        "One desired capability for machines is the ability to transfer the knowledge (features) learned on one domain to another This can potentially save compute time, enable training when data is scarce, and even improve performance. Unfortunately, there is no single recipe for transfer learning and instead multiple options are possible and much remains to be well understood. In this project, you will explore how transfer learning works in different scenarios. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa_E2XkS8sWx"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0j_oZr-Eqe"
      },
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import csv\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import multiprocessing\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KpScrhdFcnQj"
      },
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "V_qpraYscnDm"
      },
      "source": [
        "# @title Set device (GPU or CPU)\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARMgoLftc6ff",
        "outputId": "f530c316-2656-4011-a411-914b6f5055af"
      },
      "source": [
        "set_seed(seed=2021)\n",
        "device = set_device()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKGP9RSStzs7"
      },
      "source": [
        "### Training hyperparameters\n",
        "\n",
        "Here we set some general training hyperparameters such as the learning rate, batch size, etc. as well as other training options such as including data augmentation (`torchvision_transforms`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sM6oz9kwBIO"
      },
      "source": [
        "**Note:** We have reduced the number of epochs, `max_epochs`. The value was set to 200. Please, change it back and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y008jb7WnKwA"
      },
      "source": [
        "# hyper-parameters\n",
        "use_cuda = torch.cuda.is_available()\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "batch_size = 128\n",
        "max_epochs = 15  # Please change this to 200\n",
        "max_epochs_target = 10\n",
        "base_learning_rate = 0.1\n",
        "torchvision_transforms = True  # True/False if you want use torchvision augmentations"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2EdCTsTeGsd"
      },
      "source": [
        "---\n",
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrxmPY3gsal0"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We will train the source model using CIFAR-100 data set from PyTorch, but with small tweaks we can get any other data we are interested in.\n",
        "\n",
        "Note that the data set is normalised by substracted the mean and dividing by the standard deviation (pre-computed) of the training set. Also, if `torchvision_transforms` is `True`, data augmentation will be applied during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DqmzceI-hPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "4f7f86654b2b4bd3b13f0f88816c0727",
            "c5c36dd45d1d4cae87596d92c91599d5",
            "1db01cbf7a3b4912adef0bc2427761f5",
            "45caa2849d3c4f4b82ba93d19fe98685",
            "bdf05b823e1a46c19d60844ffb82a949",
            "97d834f46c304593b2141364e1ef0b6a",
            "5a2563bba82642a8accb139d3b40873c",
            "4998e0b9581042eaa87f8910e908772e"
          ]
        },
        "cellView": "form",
        "outputId": "297cad46-7bf7-402d-8935-bee0050ba446"
      },
      "source": [
        "# @markdown Download and prepare Data\n",
        "print('==> Preparing data..')\n",
        "def percentageSplit(full_dataset, percent = 0.0):\n",
        "    set1_size = int(percent * len(full_dataset))\n",
        "    set2_size = len(full_dataset) - set1_size\n",
        "    final_dataset, _ = torch.utils.data.random_split(full_dataset, [set1_size, set2_size])\n",
        "    return final_dataset\n",
        "\n",
        "\n",
        "# CIFAR100 normalizing\n",
        "mean = [0.5071, 0.4866, 0.4409]\n",
        "std = [0.2673, 0.2564, 0.2762]\n",
        "\n",
        "# CIFAR10 normalizing\n",
        "# mean = (0.4914, 0.4822, 0.4465)\n",
        "# std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# torchvision transforms\n",
        "transform_train = transforms.Compose([])\n",
        "if torchvision_transforms:\n",
        "  transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "  transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "transform_train.transforms.append(transforms.ToTensor())\n",
        "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "  root='./CIFAR100', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(\n",
        "  root='./CIFAR100', train=False, download=True, transform=transform_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./CIFAR100/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f7f86654b2b4bd3b13f0f88816c0727",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./CIFAR100/cifar-100-python.tar.gz to ./CIFAR100\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0UfAEfEuxfY"
      },
      "source": [
        "#### CIFAR-100\n",
        "\n",
        "CIFAR-100 is a data set of 50,000 colour (RGB) training images and 10,000 test images, of size 32 x 32 pixels. Each image is labelled as 1 of 100 possible classes. \n",
        "\n",
        "The data set is stored as a custom `torchvision.datasets.cifar.CIFAR` object. You can check some of its properties with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC1S_Gepuzv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddd0f96-7f7b-41ba-ae9e-1abd2a14cae5"
      },
      "source": [
        "print(f\"Object type: {type(trainset)}\")\n",
        "print(f\"Training data shape: {trainset.data.shape}\")\n",
        "print(f\"Test data shape: {testset.data.shape}\")\n",
        "print(f\"Number of classes: {np.unique(trainset.targets).shape[0]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object type: <class 'torchvision.datasets.cifar.CIFAR100'>\n",
            "Training data shape: (50000, 32, 32, 3)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Number of classes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuliovENvJDb"
      },
      "source": [
        "## Data loaders\n",
        "\n",
        "A dataloader is an optimized data iterator that provides functionality for efficient shuffling, transformation and batching of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYUN7mzI-hRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e650898-5af1-423f-b80c-d081e506134c"
      },
      "source": [
        "# Dataloader \n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "print(f'----> number of workers: {num_workers}')\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----> number of workers: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhyHrN6fenLw"
      },
      "source": [
        "---\n",
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSbuFuYLvR9K"
      },
      "source": [
        "### Architecture: ResNet\n",
        "\n",
        "ResNet is a family of network architectures whose main property is that the network is organised as a stack of _residual blocks_. Residual blocks consist of a stack of layers whose output is added the input, making a _shortcut connection_.\n",
        "\n",
        "See the [original paper](https://arxiv.org/abs/1512.03385) for more details.\n",
        "\n",
        "ResNet is just a popular choice out of many others, but data augmentation works well in general. We just picked ResNet for illustration purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v59Q5-D6k6We",
        "cellView": "form"
      },
      "source": [
        "#@title ResNet model in PyTorch\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  \"\"\"ResNet in PyTorch.\n",
        "      Reference:\n",
        "      [1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "        Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "  \"\"\"\n",
        "\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion*planes)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion*planes)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = F.relu(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=100):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "  return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "  return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "  return ResNet(Bottleneck, [3,4,6,3])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3JPo--uvZkK"
      },
      "source": [
        "## Model setup and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWP4VtlVN-9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5591392-3399-45ae-854a-025c559a5160"
      },
      "source": [
        "# load the Model\n",
        "net = ResNet18()\n",
        "print('-----> verify if model is run on random data')\n",
        "y = net(Variable(torch.randn(1, 3, 32, 32)))\n",
        "print('model loaded')\n",
        "\n",
        "result_folder = './results/'\n",
        "if not os.path.exists(result_folder):\n",
        "    os.makedirs(result_folder)\n",
        "\n",
        "logname = result_folder + net.__class__.__name__ + '_pretrain' + '.csv'\n",
        "\n",
        "if use_cuda:\n",
        "  net.cuda()\n",
        "  net = torch.nn.DataParallel(net)\n",
        "  print('Using', torch.cuda.device_count(), 'GPUs.')\n",
        "  cudnn.benchmark = True\n",
        "  print('Using CUDA..')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----> verify if model is run on random data\n",
            "model loaded\n",
            "Using 1 GPUs.\n",
            "Using CUDA..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-3YStW0xF4J"
      },
      "source": [
        "---\n",
        "# Section 3: Set up training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlSjgU3xvjYh"
      },
      "source": [
        "### Set loss function and optimizer\n",
        "\n",
        "We use the cross entropy loss, commonly used for classification, and stochastic gradient descent (SGD) as optimizer, with momentum and weight decay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5xQAAwDN_DT"
      },
      "source": [
        "# optimizer and criterion \n",
        "criterion = nn.CrossEntropyLoss()   \n",
        "optimizer = optim.SGD(net.parameters(), lr=base_learning_rate,\n",
        "                      momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chCKez5VvoS9"
      },
      "source": [
        "### Train and test loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ZQY61fN_Gw"
      },
      "source": [
        "# Training & Test functions\n",
        "\n",
        "def train(net, epoch, use_cuda=False):\n",
        "  print(f'\\nEpoch: {epoch}')\n",
        "  net.train()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "    if use_cuda:\n",
        "      inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = Variable(inputs), Variable(targets)\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets.data).cpu().sum()\n",
        "    \n",
        "    if batch_idx % 500 == 0:\n",
        "      print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "  return (train_loss/batch_idx, 100.*correct/total)\n",
        "\n",
        "\n",
        "def test(net, epoch, outModelName, use_cuda=False):\n",
        "  global best_acc\n",
        "  net.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "      if use_cuda:\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "      if batch_idx % 200 == 0:\n",
        "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "  # Save checkpoint.\n",
        "  acc = 100.*correct/total\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    checkpoint(net, acc, epoch, outModelName)\n",
        "  return (test_loss/batch_idx, 100.*correct/total)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzWOT71xKVw"
      },
      "source": [
        "## Auxiliary functions\n",
        "\n",
        "* `checkpoint()`: Store checkpoints of the model\n",
        "* `adjust_learning_rate()`: Decreases the learning rate (learning rate decay) at certain epochs of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo3YfXEcN_Ji",
        "cellView": "form"
      },
      "source": [
        "# @markdown `checkpoint` and `adjust_learning_rate` functions\n",
        "def checkpoint(model, acc, epoch, outModelName):\n",
        "  # Save checkpoint.\n",
        "  print('Saving..')\n",
        "  state = {\n",
        "      'state_dict': model.state_dict(),\n",
        "      'acc': acc,\n",
        "      'epoch': epoch,\n",
        "      'rng_state': torch.get_rng_state()\n",
        "  }\n",
        "  if not os.path.isdir('checkpoint'):\n",
        "      os.mkdir('checkpoint')\n",
        "  torch.save(state, f'./checkpoint/{outModelName}.t7')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "  \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
        "  lr = base_learning_rate\n",
        "  if epoch <= 9 and lr > 0.1:\n",
        "    # warm-up training for large minibatch\n",
        "    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
        "  if epoch >= 100:\n",
        "    lr /= 10\n",
        "  if epoch >= 150:\n",
        "    lr /= 10\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr6sX2IHyHS0"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "This is the loop where the model is trained for `max_epochs` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5pPpHB1N_NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16908da-a8ed-472f-ba52-047746d43e6b"
      },
      "source": [
        "# training\n",
        "outModelName = 'pretrain'\n",
        "if not os.path.exists(logname):\n",
        "  with open(logname, 'w') as logfile:\n",
        "    logwriter = csv.writer(logfile, delimiter=',')\n",
        "    logwriter.writerow(['epoch', 'train loss',\n",
        "                        'train acc', 'test loss', 'test acc'])\n",
        "\n",
        "for epoch in range(start_epoch, max_epochs):\n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "  train_loss, train_acc = train(net, epoch, use_cuda=use_cuda)\n",
        "  test_loss, test_acc = test(net, epoch, outModelName, use_cuda=use_cuda)\n",
        "  with open(logname, 'a') as logfile:\n",
        "    logwriter = csv.writer(logfile, delimiter=',')\n",
        "    logwriter.writerow([epoch, train_loss, train_acc.item(),\n",
        "                        test_loss, test_acc.item()])\n",
        "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0 391 Loss: 4.748 | Acc: 0.781% (1/128)\n",
            "0 79 Loss: 3.494 | Acc: 16.406% (21/128)\n",
            "Saving..\n",
            "Epoch: 0 | train acc: 8.630000114440918 | test acc: 14.930000305175781\n",
            "\n",
            "Epoch: 1\n",
            "0 391 Loss: 3.535 | Acc: 10.938% (14/128)\n",
            "0 79 Loss: 3.038 | Acc: 22.656% (29/128)\n",
            "Saving..\n",
            "Epoch: 1 | train acc: 17.74799919128418 | test acc: 22.780000686645508\n",
            "\n",
            "Epoch: 2\n",
            "0 391 Loss: 3.079 | Acc: 28.125% (36/128)\n",
            "0 79 Loss: 2.524 | Acc: 30.469% (39/128)\n",
            "Saving..\n",
            "Epoch: 2 | train acc: 26.323999404907227 | test acc: 30.18000030517578\n",
            "\n",
            "Epoch: 3\n",
            "0 391 Loss: 2.728 | Acc: 28.125% (36/128)\n",
            "0 79 Loss: 2.417 | Acc: 40.625% (52/128)\n",
            "Saving..\n",
            "Epoch: 3 | train acc: 34.67399978637695 | test acc: 35.560001373291016\n",
            "\n",
            "Epoch: 4\n",
            "0 391 Loss: 2.174 | Acc: 42.188% (54/128)\n",
            "0 79 Loss: 2.177 | Acc: 45.312% (58/128)\n",
            "Saving..\n",
            "Epoch: 4 | train acc: 41.7760009765625 | test acc: 41.349998474121094\n",
            "\n",
            "Epoch: 5\n",
            "0 391 Loss: 1.806 | Acc: 50.781% (65/128)\n",
            "0 79 Loss: 2.302 | Acc: 41.406% (53/128)\n",
            "Epoch: 5 | train acc: 47.85599899291992 | test acc: 41.0\n",
            "\n",
            "Epoch: 6\n",
            "0 391 Loss: 1.773 | Acc: 52.344% (67/128)\n",
            "0 79 Loss: 1.980 | Acc: 50.781% (65/128)\n",
            "Saving..\n",
            "Epoch: 6 | train acc: 52.73400115966797 | test acc: 47.63999938964844\n",
            "\n",
            "Epoch: 7\n",
            "0 391 Loss: 1.541 | Acc: 53.906% (69/128)\n",
            "0 79 Loss: 1.641 | Acc: 53.125% (68/128)\n",
            "Saving..\n",
            "Epoch: 7 | train acc: 57.07600021362305 | test acc: 55.099998474121094\n",
            "\n",
            "Epoch: 8\n",
            "0 391 Loss: 1.347 | Acc: 61.719% (79/128)\n",
            "0 79 Loss: 1.482 | Acc: 60.156% (77/128)\n",
            "Saving..\n",
            "Epoch: 8 | train acc: 60.15399932861328 | test acc: 57.619998931884766\n",
            "\n",
            "Epoch: 9\n",
            "0 391 Loss: 1.075 | Acc: 65.625% (84/128)\n",
            "0 79 Loss: 1.572 | Acc: 57.031% (73/128)\n",
            "Epoch: 9 | train acc: 62.667999267578125 | test acc: 56.220001220703125\n",
            "\n",
            "Epoch: 10\n",
            "0 391 Loss: 0.981 | Acc: 72.656% (93/128)\n",
            "0 79 Loss: 1.373 | Acc: 64.062% (82/128)\n",
            "Epoch: 10 | train acc: 65.48999786376953 | test acc: 55.75\n",
            "\n",
            "Epoch: 11\n",
            "0 391 Loss: 0.940 | Acc: 72.656% (93/128)\n",
            "0 79 Loss: 1.475 | Acc: 58.594% (75/128)\n",
            "Epoch: 11 | train acc: 67.69999694824219 | test acc: 57.290000915527344\n",
            "\n",
            "Epoch: 12\n",
            "0 391 Loss: 0.934 | Acc: 73.438% (94/128)\n",
            "0 79 Loss: 1.361 | Acc: 63.281% (81/128)\n",
            "Saving..\n",
            "Epoch: 12 | train acc: 69.58599853515625 | test acc: 58.959999084472656\n",
            "\n",
            "Epoch: 13\n",
            "0 391 Loss: 0.839 | Acc: 75.000% (96/128)\n",
            "0 79 Loss: 1.302 | Acc: 63.281% (81/128)\n",
            "Saving..\n",
            "Epoch: 13 | train acc: 71.39199829101562 | test acc: 60.16999816894531\n",
            "\n",
            "Epoch: 14\n",
            "0 391 Loss: 0.716 | Acc: 78.906% (101/128)\n",
            "0 79 Loss: 1.191 | Acc: 67.188% (86/128)\n",
            "Saving..\n",
            "Epoch: 14 | train acc: 73.08399963378906 | test acc: 62.040000915527344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycQ-Rj4A3Psh"
      },
      "source": [
        "---\n",
        "# Section 4: Transfer learning\n",
        "\n",
        "Re-use the trained model to improve training on a different data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ZwOyXdzBfI"
      },
      "source": [
        "### Delete variables from the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaCrHRB2IqsG"
      },
      "source": [
        "# delete the backbone network\n",
        "delete = True\n",
        "if delete:\n",
        "  del net\n",
        "  del trainset\n",
        "  del testset\n",
        "  del trainloader\n",
        "  del testloader\n",
        "  gc.collect()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wATyF1Z533su"
      },
      "source": [
        "#### Target dataset\n",
        "\n",
        "We will now use CIFAR-10 as _target_ data set. Again, with small tweaks we can get any other data we are interested in.\n",
        "\n",
        "CIFAR-10 is very similar to CIFAR-100, but it contains only 10 classes instead of 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR0Cyk1ScnlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "061aeb49a97a44f0a8e844852e535ff0",
            "4b1fa6fbd29542c781d1302fbb51ce58",
            "7eedeab6745746398ae84566eee4d1a3",
            "6e3d9b4937de4364b1ce1abe93d977af",
            "442e5135cf304e70bbd39dbb6b8e56e6",
            "c8f498014b95403f946c5776b91cefa3",
            "ef5482b131a840aa92ab1942448a1c41",
            "c1eb405b5bc646d29cbe9b99ad0bbeab"
          ]
        },
        "cellView": "form",
        "outputId": "f097c790-1fdb-4af7-f3f5-4f226e65e675"
      },
      "source": [
        "# @markdown Download and prepare target domain Data\n",
        "print('==> Preparing target domain data...')\n",
        "\n",
        "# CIFAR10 normalizing\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2023, 0.1994, 0.2010)\n",
        "num_classes = 10\n",
        "lr = 0.0001\n",
        "\n",
        "# torchvision transforms\n",
        "transform_train = transforms.Compose([])\n",
        "if torchvision_transforms:\n",
        "  transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "  transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "transform_train.transforms.append(transforms.ToTensor())\n",
        "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "  root='./CIFAR10', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "  root='./CIFAR10', train=False, download=True, transform=transform_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing target domain data...\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "061aeb49a97a44f0a8e844852e535ff0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./CIFAR10/cifar-10-python.tar.gz to ./CIFAR10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0IxAl4t0m3x"
      },
      "source": [
        "#### Select a subset of the data\n",
        "\n",
        "To simulate a lower data regime, where transfer learning can be useful.\n",
        "\n",
        "Choose percentage from the trainset. Set `percent = 1.0` to use the whole train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiJP1xc7x-oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81061b1a-91fb-4262-dd76-ef8b5939e268"
      },
      "source": [
        "percent = 0.6\n",
        "\n",
        "trainset = percentageSplit(trainset, percent = percent)\n",
        "print('size of the new trainset: ', len(trainset))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of the new trainset:  30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt599IWd58OU"
      },
      "source": [
        "#### Dataloaders\n",
        "\n",
        "As before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpvbV7lQNKt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce1fc05-10be-4760-cb1f-c7aec1ff5de4"
      },
      "source": [
        "# Dataloader \n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "print(f'----> number of workers: {num_workers}')\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=num_workers)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size,\n",
        "    shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----> number of workers: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmcPmeEO6GcZ"
      },
      "source": [
        "### Load pre-trained model\n",
        "\n",
        "Load the checkpoint of the model previously trained on CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFpux8rtcno6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcdfa36-0986-491f-9c37-576a58af70bf"
      },
      "source": [
        "model = ResNet18()\n",
        "\n",
        "checkpointPath = '/content/checkpoint/pretrain.t7'\n",
        "\n",
        "print(f' ===> loading pretrained model from: {checkpointPath}')\n",
        "if os.path.isfile(checkpointPath):\n",
        "  state_dict = torch.load(checkpointPath)\n",
        "  best_acc = state_dict['acc']\n",
        "  print('Best Accuracy:', best_acc)\n",
        "  if \"state_dict\" in state_dict:\n",
        "    state_dict = state_dict[\"state_dict\"]\n",
        "  # remove prefixe \"module.\"\n",
        "  state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "  for k, v in model.state_dict().items():\n",
        "    if k not in list(state_dict):\n",
        "      print('key \"{}\" could not be found in provided state dict'.format(k))\n",
        "    elif state_dict[k].shape != v.shape:\n",
        "      print('key \"{}\" is of different shape in model and provided state dict'.format(k))\n",
        "      state_dict[k] = v\n",
        "  msg = model.load_state_dict(state_dict, strict=False)\n",
        "  print(\"Load pretrained model with msg: {}\".format(msg))\n",
        "else:\n",
        "  raise Exception('No pretrained weights found')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ===> loading pretrained model from: /content/checkpoint/pretrain.t7\n",
            "Best Accuracy: tensor(62.0400)\n",
            "Load pretrained model with msg: <All keys matched successfully>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fkhzTjv6Tvh"
      },
      "source": [
        "### Freeze model parameters\n",
        "\n",
        "In transfer learning, we usually do not re-train all the weights of the model, but only a subset of them, for instance the last layer. Here we first _freeze_ all the parameters of the model, and we will _unfreeze_ one layer below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bpCQ4gZcnsC"
      },
      "source": [
        "# Freeze the model parameters, you can also freeze some layers only\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTQUMH-W6yaS"
      },
      "source": [
        "### Loss function, optimizer and _unfreeze_ last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gENJ9MRKCnRp"
      },
      "source": [
        "num_ftrs = model.linear.in_features\n",
        "model.linear = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "if use_cuda:\n",
        "  model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(\n",
        "    model.linear.parameters(),\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4,\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfGPk9lU7m9_"
      },
      "source": [
        "#### Check number of parameters\n",
        "\n",
        "We can calculate the number of total parameters and the number of trainable parameters, that is those that will be updated during training. Since we have freezed most of the parameters, the number of training parameters should be much smaller."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE8WJgXRLWD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d632ba54-60df-4a29-b314-d9ba90bdb9f8"
      },
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Total Parameters: {total_params}, Trainable parameters: {trainable_total_params}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Parameters: 11173962, Trainable parameters: 5130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrmLb-gNF2d2"
      },
      "source": [
        "### Train the target model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9gN4sv2CnUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10d9580-e370-4ad5-e5e1-50a996bc5838"
      },
      "source": [
        "outModelName = 'finetuned'\n",
        "logname = result_folder + model.__class__.__name__ + f'_{outModelName}.csv'\n",
        "\n",
        "if not os.path.exists(logname):\n",
        "  with open(logname, 'w') as logfile:\n",
        "    logwriter = csv.writer(logfile, delimiter=',')\n",
        "    logwriter.writerow(['epoch', 'train loss',\n",
        "                        'train acc', 'test loss', 'test acc'])\n",
        "\n",
        "for epoch in range(start_epoch, max_epochs_target):\n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "  train_loss, train_acc = train(model, epoch, use_cuda=use_cuda)\n",
        "  test_loss, test_acc = test(model, epoch, outModelName, use_cuda=use_cuda)\n",
        "  with open(logname, 'a') as logfile:\n",
        "    logwriter = csv.writer(logfile, delimiter=',')\n",
        "    logwriter.writerow([epoch, train_loss, train_acc.item(),\n",
        "                        test_loss, test_acc.item()])\n",
        "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0 235 Loss: 2.377 | Acc: 10.156% (13/128)\n",
            "0 79 Loss: 0.587 | Acc: 82.031% (105/128)\n",
            "Saving..\n",
            "Epoch: 0 | train acc: 71.1866683959961 | test acc: 75.12000274658203\n",
            "\n",
            "Epoch: 1\n",
            "0 235 Loss: 0.771 | Acc: 73.438% (94/128)\n",
            "0 79 Loss: 0.603 | Acc: 77.344% (99/128)\n",
            "Saving..\n",
            "Epoch: 1 | train acc: 76.1500015258789 | test acc: 76.80000305175781\n",
            "\n",
            "Epoch: 2\n",
            "0 235 Loss: 0.706 | Acc: 75.000% (96/128)\n",
            "0 79 Loss: 0.582 | Acc: 80.469% (103/128)\n",
            "Saving..\n",
            "Epoch: 2 | train acc: 76.78666687011719 | test acc: 76.86000061035156\n",
            "\n",
            "Epoch: 3\n",
            "0 235 Loss: 0.683 | Acc: 75.000% (96/128)\n",
            "0 79 Loss: 0.594 | Acc: 81.250% (104/128)\n",
            "Saving..\n",
            "Epoch: 3 | train acc: 77.28333282470703 | test acc: 77.05000305175781\n",
            "\n",
            "Epoch: 4\n",
            "0 235 Loss: 0.615 | Acc: 79.688% (102/128)\n",
            "0 79 Loss: 0.547 | Acc: 82.031% (105/128)\n",
            "Saving..\n",
            "Epoch: 4 | train acc: 77.66999816894531 | test acc: 77.69999694824219\n",
            "\n",
            "Epoch: 5\n",
            "0 235 Loss: 0.604 | Acc: 80.469% (103/128)\n",
            "0 79 Loss: 0.599 | Acc: 75.000% (96/128)\n",
            "Epoch: 5 | train acc: 78.163330078125 | test acc: 77.47000122070312\n",
            "\n",
            "Epoch: 6\n",
            "0 235 Loss: 0.600 | Acc: 81.250% (104/128)\n",
            "0 79 Loss: 0.541 | Acc: 82.031% (105/128)\n",
            "Saving..\n",
            "Epoch: 6 | train acc: 78.00666809082031 | test acc: 77.86000061035156\n",
            "\n",
            "Epoch: 7\n",
            "0 235 Loss: 0.542 | Acc: 80.469% (103/128)\n",
            "0 79 Loss: 0.539 | Acc: 84.375% (108/128)\n",
            "Epoch: 7 | train acc: 78.41000366210938 | test acc: 77.5199966430664\n",
            "\n",
            "Epoch: 8\n",
            "0 235 Loss: 0.589 | Acc: 82.031% (105/128)\n",
            "0 79 Loss: 0.510 | Acc: 84.375% (108/128)\n",
            "Epoch: 8 | train acc: 78.53333282470703 | test acc: 77.51000213623047\n",
            "\n",
            "Epoch: 9\n",
            "0 235 Loss: 0.518 | Acc: 84.375% (108/128)\n",
            "0 79 Loss: 0.542 | Acc: 85.156% (109/128)\n",
            "Epoch: 9 | train acc: 78.42666625976562 | test acc: 77.58999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PveZei3PF9Y_"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HruWfXDjEALw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eadd388b-0f10-40dc-c170-c7a450425e1a"
      },
      "source": [
        "# plot results\n",
        "results = pd.read_csv(f'/content/results/ResNet_{outModelName}.csv', sep=',')\n",
        "results.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train loss</th>\n",
              "      <th>train acc</th>\n",
              "      <th>test loss</th>\n",
              "      <th>test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.817970</td>\n",
              "      <td>71.186668</td>\n",
              "      <td>0.700331</td>\n",
              "      <td>75.120003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.680546</td>\n",
              "      <td>76.150002</td>\n",
              "      <td>0.667680</td>\n",
              "      <td>76.800003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.654361</td>\n",
              "      <td>76.786667</td>\n",
              "      <td>0.658118</td>\n",
              "      <td>76.860001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.641357</td>\n",
              "      <td>77.283333</td>\n",
              "      <td>0.662270</td>\n",
              "      <td>77.050003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.635105</td>\n",
              "      <td>77.669998</td>\n",
              "      <td>0.650834</td>\n",
              "      <td>77.699997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  train loss  train acc  test loss   test acc\n",
              "0      0    0.817970  71.186668   0.700331  75.120003\n",
              "1      1    0.680546  76.150002   0.667680  76.800003\n",
              "2      2    0.654361  76.786667   0.658118  76.860001\n",
              "3      3    0.641357  77.283333   0.662270  77.050003\n",
              "4      4    0.635105  77.669998   0.650834  77.699997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qMnN7yXOsF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c3a7d6-589f-4ae7-88c1-f224fa93b40e"
      },
      "source": [
        "train_accuracy = results['train acc'].values\n",
        "test_accuracy = results['test acc'].values\n",
        "\n",
        "print(f'Average Accuracy over {max_epochs_target} epochs: {sum(test_accuracy)//len(test_accuracy)}')\n",
        "print(f'best accuraccy over {max_epochs_target} epochs: {max(test_accuracy)}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Accuracy over 10 epochs: 77.0\n",
            "best accuraccy over 10 epochs: 77.86000061035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3myL2_sUO7nw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "54d35309-f522-49ad-bbb6-73bb68c674f0"
      },
      "source": [
        "figureName = 'figure' # change figure name\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(results['epoch'].values, train_accuracy, label='train')\n",
        "plt.plot(results['epoch'].values, test_accuracy, label='test')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'Train/Test Accuracy curve for {max_epochs} epochs')\n",
        "plt.savefig(f'/content/results/{figureName}.png')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}