{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Augmentation_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MHZXiV5ZsWXq"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/ComputerVision/data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kpc_IPHzR1V"
      },
      "source": [
        "# Data Augmentation in image classification models\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Jama Hussein Mohamud, Alex Hernandez-Garcia\n",
        "\n",
        "__Production editors:__ \n",
        "\n",
        "*Contact info:* [engmubarak48.github.io/jmohamud/index.html](https://engmubarak48.github.io/jmohamud/index.html), [alexhernandezgarcia.github.io/](https://alexhernandezgarcia.github.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHCbTQtzrH_"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSN-hSJnzrKt"
      },
      "source": [
        "Data augmentation refers to synthetically increasing the amount of training data by transforming the existing training examples. Data augmentation has been shown to be a very useful technique, especially in computer vision applications. However, there are multiple ways of performing data augmentation and it is yet to be understood which transformations are more effective and why, and how data augmentation interacts with other techniques. In fact, it is common to see different augmentation schemes and setups in different papers. For example, there are perceptually possible image transformations ( related to human visual perception), simple synthetic transformations such as cutout, more artificial transformations such as mixup that even transform the class labels, among many others.  \n",
        "\n",
        "In this notebook, we will show how to train deep neural networks for image classification with data augmentation and analyse the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa_E2XkS8sWx"
      },
      "source": [
        "---\n",
        "# Setup\n",
        "\n",
        "First of all, let's make sure that there is a GPU available to run this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uPyIdUE8DsT"
      },
      "source": [
        "# check if your GPU, if you don't get the window, please go to Runtime > change runtime > and change to GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYFnjZJ5fPda"
      },
      "source": [
        "#### Imports\n",
        "\n",
        "Import the necessary Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0j_oZr-Eqe"
      },
      "source": [
        "# Necessary imports\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import multiprocessing\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVnEQp0Vele9"
      },
      "source": [
        "### Alternative / Complementary GPU check-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gQxqd9Pe0gv"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "print(\"Torch version: \", torch.__version__)\n",
        "print(\"GPU Available: {}\".format(use_gpu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkzkfyCtlrnq"
      },
      "source": [
        "### Random seeds\n",
        "\n",
        "If you want to obtain reproducible results, it is a good practice to set seeds for the random number generators of the various libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChPfH5dXl8DO"
      },
      "source": [
        "seed = 3971\n",
        "np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1RlI06soMNE"
      },
      "source": [
        "### Training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y008jb7WnKwA"
      },
      "source": [
        "## @title hyper-parameters\n",
        "use_cuda = torch.cuda.is_available()\n",
        "alpha = 1       # alpha for mixup augmentation \n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "batch_size = 128\n",
        "end_apochs = 200\n",
        "base_learning_rate = 0.1\n",
        "cutout = True      # True/False if you want to use cutout augmentation\n",
        "mixup = False        # True/False if you want to use mixup augmentation\n",
        "n_holes = 1         # number of holes to cut out from image for cutout\n",
        "length = 16         # length of the holes for cutout augmentation\n",
        "torchvision_transforms = False # True/False if you want use torchvision augmentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ifQN3Fcru-e"
      },
      "source": [
        "### Cutout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63-CexUOrsma",
        "cellView": "form"
      },
      "source": [
        "# @title cutout Augmentation\n",
        "\n",
        "class Cutout(object):\n",
        "    \"\"\"\n",
        "    code from: https://github.com/uoguelph-mlrg/Cutout\n",
        "\n",
        "    Randomly mask out one or more patches from an image.\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52jhgp7mpBke"
      },
      "source": [
        "### Mixup\n",
        "\n",
        "Mixup is a data augmentation technique that combines pairs of examples via a convex combination of the images and the labels. Given images $x_i$ and $x_j$ with labels $y_i$ and $y_j$, respectively, and $\\lambda \\in [0, 1]$, mixup creates a new image $\\hat{x}$ with label $\\hat{y}$ the following way:\n",
        "\n",
        "$$\n",
        "\\hat{x} = \\lambda x_i + (1 - \\lambda) x_j \\\\\n",
        "\\hat{y} = \\lambda y_i + (1 - \\lambda) y_j\n",
        "$$\n",
        "\n",
        "You may check the [original paper](https://arxiv.org/abs/1710.09412) and [code repository](https://github.com/hongyi-zhang/mixup)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhssRYWwkN_A",
        "cellView": "form"
      },
      "source": [
        "# @title Mixup Augmentation\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\n",
        "        - https://github.com/hongyi-zhang/mixup\n",
        "    '''\n",
        "    if alpha > 0.:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index,:]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V5v075K-mdm"
      },
      "source": [
        "#### Datasets\n",
        "\n",
        "We will start using CIFAR-10 data set from PyTorch, but with small tweaks we can get any other data we are interested in. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DqmzceI-hPM",
        "cellView": "form"
      },
      "source": [
        "# @title Data\n",
        "print('==> Preparing data..')\n",
        "def percentageSplit(full_dataset, percent = 0.0):\n",
        "    set1_size = int(percent * len(full_dataset))\n",
        "    set2_size = len(full_dataset) - set1_size\n",
        "    final_dataset, _ = torch.utils.data.random_split(full_dataset, [set1_size, set2_size])\n",
        "    return final_dataset\n",
        "\n",
        "# CIFAR100 normalizing\n",
        "# mean = [0.5071, 0.4866, 0.4409]\n",
        "# std = [0.2673, 0.2564, 0.2762]\n",
        "\n",
        "# CIFAR10 normalizing\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# torchvision transforms\n",
        "transform_train = transforms.Compose([])\n",
        "if torchvision_transforms:\n",
        "    transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "    transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "transform_train.transforms.append(transforms.ToTensor())\n",
        "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
        "if cutout:\n",
        "    transform_train.transforms.append(Cutout(n_holes=n_holes, length=length))\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./CIFAR10', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./CIFAR10', train=False, download=True, transform=transform_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7TylRu5lKrt"
      },
      "source": [
        "#### CIFAR-10\n",
        "\n",
        "CIFAR-10 is a data set of 50,000 colour (RGB) training images and 10,000 test images, of size 32 x 32 pixels. Each image is labelled as 1 of 10 possible classes: \n",
        "```\n",
        "'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "```\n",
        "The data set is stored as a custom `torchvision.datasets.cifar.CIFAR` object. You can check some of its properties with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwSfiyFskf6N"
      },
      "source": [
        "print(f\"Object type: {type(trainset)}\")\n",
        "print(f\"Training data shape: {trainset.data.shape}\")\n",
        "print(f\"Test data shape: {testset.data.shape}\")\n",
        "print(f\"Number of classes: {np.unique(trainset.targets).shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UEQ5znbzgg4"
      },
      "source": [
        "# choose percentage from the trainset. set percent = 1.0 to use the whole train data\n",
        "percent = 1.0\n",
        "trainset = percentageSplit(trainset, percent = percent)\n",
        "print('size of the new trainset: ', len(trainset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLmLkCUxoYnB"
      },
      "source": [
        "### Data loaders\n",
        "\n",
        "A dataloader is an optimized data iterator that provides functionality for efficient shuffling, transformation and batching of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYUN7mzI-hRe"
      },
      "source": [
        "# Dataloader \n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "print(f'----> number of workers: {num_workers}')\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHZXiV5ZsWXq"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "To visualize some of the augmentations, make sure you set to ```True``` their corresponding flags in the hyperparameters section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiMUcyuzwy4J"
      },
      "source": [
        "# get batch of data\n",
        "batch_X, batch_Y =  next(iter(trainloader))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydHZVS0Mv47g"
      },
      "source": [
        "def plot_mixed_images(images):\n",
        "    inv_normalize = transforms.Normalize(\n",
        "                        mean= [-m/s for m, s in zip(mean, std)],\n",
        "                        std= [1/s for s in std]\n",
        "                        )\n",
        "    inv_PIL = transforms.ToPILImage()\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    for i in range(1, len(images) + 1):\n",
        "        image = images[i-1]\n",
        "        ax = fig.add_subplot(1, 4, i)\n",
        "        inv_tensor = inv_normalize(image).cpu()\n",
        "        ax.imshow(inv_PIL(inv_tensor))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5oyb5NZvwg2"
      },
      "source": [
        "#### Mixup Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBpfboGFsVG9"
      },
      "source": [
        "if mixup:\n",
        "    alpha = 0.9\n",
        "    mixed_x, y_a, y_b, lam = mixup_data(batch_X, batch_Y, alpha=alpha, use_cuda=True)\n",
        "    plot_mixed_images(mixed_x[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOMkos4v905"
      },
      "source": [
        "#### Cutout Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZKCAehywEys"
      },
      "source": [
        "if cutout:\n",
        "    plot_mixed_images(batch_X[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFHeBqkrwFsS"
      },
      "source": [
        "#### Torchvision Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wiZ-rJGwM5c"
      },
      "source": [
        "if torchvision_transforms:\n",
        "    plot_mixed_images(batch_X[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTKauVBir2BB"
      },
      "source": [
        "### Architecture: ResNet\n",
        "\n",
        "ResNet is a family of network architectures whose main property is that the network is organised as a stack of _residual blocks_. Residual blocks consist of a stack of layers whose output is added the input, making a _shortcut connection_.\n",
        "\n",
        "See the [original paper](https://arxiv.org/abs/1512.03385) for more details.\n",
        "\n",
        "ResNet is just a popular choice out of many others, but data augmentation works well in general. We just picked ResNet for illustration purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v59Q5-D6k6We"
      },
      "source": [
        "# title model\n",
        "'''ResNet in PyTorch.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtl2TFPi_YO0"
      },
      "source": [
        "### Test on random data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWP4VtlVN-9G"
      },
      "source": [
        "# load the Model\n",
        "net = ResNet18()\n",
        "print('-----> verify if model is run on random data')\n",
        "y = net(Variable(torch.randn(1,3,32,32)))\n",
        "print('model loaded')\n",
        "\n",
        "result_folder = './results/'\n",
        "if not os.path.exists(result_folder):\n",
        "    os.makedirs(result_folder)\n",
        "\n",
        "logname = result_folder + net.__class__.__name__ + '_' + '.csv'\n",
        "\n",
        "if use_cuda:\n",
        "    net.cuda()\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    print('Using', torch.cuda.device_count(), 'GPUs.')\n",
        "    cudnn.benchmark = True\n",
        "    print('Using CUDA..')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDU9ujE_fLK"
      },
      "source": [
        "### Set loss function and optimizer\n",
        "\n",
        "We use the cross entropy loss, commonly used for classification, and stochastic gradient descent (SGD) as optimizer, with momentum and weight decay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5xQAAwDN_DT"
      },
      "source": [
        "# optimizer and criterion \n",
        "\n",
        "def mixup_criterion(y_a, y_b, lam):\n",
        "    '''\n",
        "     - Mixup criterion\n",
        "     - https://github.com/hongyi-zhang/mixup\n",
        "    '''\n",
        "    return lambda criterion, pred: lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()       # only for test data\n",
        "optimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYmC3sWw_66D"
      },
      "source": [
        "### Train and test loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ZQY61fN_Gw"
      },
      "source": [
        "# Training & Test functions\n",
        "def train(epoch, alpha):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        if mixup:\n",
        "            # generate mixed inputs, two one-hot label vectors and mixing coefficient\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha, use_cuda)\n",
        "            inputs, targets_a, targets_b = Variable(inputs), Variable(targets_a), Variable(targets_b)\n",
        "            outputs = net(inputs)\n",
        "            loss_func = mixup_criterion(targets_a, targets_b, lam)\n",
        "            loss = loss_func(criterion, outputs)\n",
        "        else:\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        if mixup:\n",
        "            correct += lam * predicted.eq(targets_a.data).cpu().sum() + (1 - lam) * predicted.eq(targets_b.data).cpu().sum()\n",
        "        else:\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "        \n",
        "        if batch_idx % 500 == 0:\n",
        "            print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    return (train_loss/batch_idx, 100.*correct/total)\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            # inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "            if batch_idx % 200 == 0:\n",
        "                print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                    % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        checkpoint(acc, epoch)\n",
        "    return (test_loss/batch_idx, 100.*correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo3YfXEcN_Ji"
      },
      "source": [
        "# checkpoint & adjust_learning_rate\n",
        "def checkpoint(acc, epoch):\n",
        "    # Save checkpoint.\n",
        "    print('Saving..')\n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'acc': acc,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/ckpt.t7')\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
        "    lr = base_learning_rate\n",
        "    if epoch <= 9 and lr > 0.1:\n",
        "        # warm-up training for large minibatch\n",
        "        lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5pPpHB1N_NH"
      },
      "source": [
        "##@title start training\n",
        "if not os.path.exists(logname):\n",
        "    with open(logname, 'w') as logfile:\n",
        "        logwriter = csv.writer(logfile, delimiter=',')\n",
        "        logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
        "\n",
        "for epoch in range(start_epoch, end_apochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_loss, train_acc = train(epoch, alpha)\n",
        "    test_loss, test_acc = test(epoch)\n",
        "    with open(logname, 'a') as logfile:\n",
        "        logwriter = csv.writer(logfile, delimiter=',')\n",
        "        logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n",
        "    print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSZEUr8wvUbO"
      },
      "source": [
        "# plot results\n",
        "results = pd.read_csv('/content/results/ResNet_.csv', sep =',')\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PemzbmfRyJHj"
      },
      "source": [
        "train_accuracy = results['train acc'].values\n",
        "test_accuracy = results['test acc'].values\n",
        "\n",
        "print(f'Average test Accuracy over {end_apochs} epochs:', sum(test_accuracy)//len(test_accuracy))\n",
        "print(f'best test accuraccy over {end_apochs} epochs:', max(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X36AGN5vyJLa"
      },
      "source": [
        "figureName = 'WithMixUp' # change figure name\n",
        "\n",
        "plt.plot(results['epoch'].values, train_accuracy, label='train')\n",
        "plt.plot(results['epoch'].values, test_accuracy, label='test')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'Train/Test Accuracy curve for {end_apochs} epochs')\n",
        "plt.savefig(f'/content/results/{figureName}.png')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
