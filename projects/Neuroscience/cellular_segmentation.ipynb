{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/Neuroscience/cellular_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Segmentation and Denoising\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Carsen Stringer\n",
    "\n",
    "__Produtction editors:__ Spiros Chavlis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Objective\n",
    "\n",
    "This notebook will give you starting points to perform\n",
    "* cellular segmentation using cultured neurons (outside the brain)\n",
    "* analysis of neuronal activity in calcium imaging experiments such as finding cells, denoising data and predicting activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install opencv-python --quiet\n",
    "!pip install numba --quiet\n",
    "!pip install tifffile --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import hashlib\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import find_objects, binary_fill_holes\n",
    "from scipy.ndimage import generate_binary_structure, label\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Intro to segmentation + denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Segmentation\n",
    "\n",
    "To answer many biological questions, it is necessary to segment the individual cells in images. Segmentation allows \n",
    "* computation of number of cells in an image, useful for instance to compare the effects of drugs on cell survival\n",
    "* accurate estimation of cell shapes, also useful for the same reasons\n",
    "* temporal measurements of cellular dynamics such as cell division, cellular movements or calcium influx\n",
    "* quantification of protein or RNA expresssion\n",
    "\n",
    "The first part of this notebook will set up a basic [U-net](https://arxiv.org/abs/1505.04597) convolutional network to do cellular segmentation using a curated version of this [dataset](http://www.cellimagelibrary.org/images/CCDB_6843), which the first cell of the notebook will download for you. These are images with a cytoplasm stain (whole cell stained) and a nuclear stain (channels 1 and 2 of the images). The segmentation masks provided are for the cytoplasm (whole cell segmentation). There is code to train and test the network with a simple cost function.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/static/cellular_segmentation_image.png\">\n",
    "\n",
    "\n",
    "Can you do transfer learning with this network on new images? There are image labels for other [datasets](https://bbbc.broadinstitute.org/image_sets) for instance provided by Anne Carpenter's lab at the Broad. Maybe your cellular segmenter can work on [worms](https://bbbc.broadinstitute.org/BBBC010) or a herd of bison! Note that the network is learning the approximate sizes of objects, so you may need to rescale other images accordingly. To label new images you may need to use a tool like [napari](https://www.napari.org).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/static/bison.3.600.jpg\">\n",
    "\n",
    "\n",
    "**Note**: The data provided consists of both a training and a test set. It is important to not overfit to the test set, and only use it for a final evaluation. This code splits the training set into a training and a validation data set. Use this split data for testing out different algorithms. Then, after you finish developing your algorithm you can evaluate it on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Analysis of neural activity data\n",
    "\n",
    "Often in neuroscience we have temporal data which consists of a movie of neuronal activity recorded using a microscope. Processing these movies can require several steps. We will focus on the neural detection step because that is a problem that we can use convolutional networks to help us with. The second part of this notebook therefore applies the model from the first part to the maximum image of the neural movie. This detects some neurons in the recording. Could we detect more neurons though if we denoise the movie first? Also what happens if we use more information across frames to detect cells? You may also want to explore denoising neural data from other sources (see other curated datasets in the NMA projects folder). None of these approaches are implemented here so this is a more open-ended project. \n",
    "\n",
    "* imaging data loaded in [suite2p](https://github.com/mouseland/suite2p)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/static/multiselect_cellular.gif\">\n",
    "\n",
    "\n",
    "Acknowledgments:\n",
    "This Notebook was developed by Carsen Stringer. It borrows from:\n",
    "* [cellpose](https://github.com/mouseland/cellpose) (written by Carsen Stringer and Marius Pachitariu)\n",
    "* Kristin Branson's PoseEstimation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Segmenting neurons in a dish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Download and normalize data\n",
    "filenames = [\"cells_train.npz\",\n",
    "             \"cells_test.npz\"]\n",
    "urls = [\"https://osf.io/z3h78/download\",\n",
    "        \"https://osf.io/ft5p3/download\"]\n",
    "expected_md5s = [\"85e1fe2ee8d936c1083d62563d79d958\",\n",
    "                 \"e8f789abe20a7efde806d9ba03d20fd7\"]\n",
    "\n",
    "for fname, url, expected_md5 in zip(filenames, urls, expected_md5s):\n",
    "  if not os.path.isfile(fname):\n",
    "    try:\n",
    "      r = requests.get(url)\n",
    "    except requests.ConnectionError:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      if r.status_code != requests.codes.ok:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "      elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
    "        print(\"!!! Data download appears corrupted !!!\")\n",
    "      else:\n",
    "        with open(fname, \"wb\") as fid:\n",
    "          fid.write(r.content)\n",
    "\n",
    "cells_train = np.load('cells_train.npz', allow_pickle=True)['arr_0'].item()\n",
    "cells_test = np.load('cells_test.npz', allow_pickle=True)['arr_0'].item()\n",
    "imgs_train = np.array(cells_train['imgs']).transpose(0, 3, 1, 2)\n",
    "masks_train = np.array(cells_train['masks'])\n",
    "imgs_test = np.array(cells_test['imgs']).transpose(0, 3, 1, 2)\n",
    "masks_test = np.array(cells_test['masks'])\n",
    "\n",
    "# we are going to normalize the images so their pixel values mostly fall between 0 and 1\n",
    "# this is helpful if you have images on a variety of scales\n",
    "# we will also return the images as float32 <- the data type that is fast for GPU computation\n",
    "def normalize99(img):\n",
    "  \"\"\" normalize image so 0.0 is 1st percentile and 1.0 is 99th percentile \"\"\"\n",
    "  X = img.copy()\n",
    "  x01 = np.percentile(X, 1)\n",
    "  x99 = np.percentile(X, 99)\n",
    "  X = (X - x01) / (x99 - x01)\n",
    "  return X.astype(np.float32)\n",
    "\n",
    "\n",
    "imgs_train = np.array([normalize99(img) for img in imgs_train])\n",
    "imgs_test = np.array([normalize99(img) for img in imgs_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Plot a random training image and its masks. Note the masks are labels from 1, ... to the number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "irand = np.random.randint(len(imgs_train))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(imgs_train[irand][0])\n",
    "plt.title('channel 1 - cytoplasm')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(imgs_train[irand][1])\n",
    "plt.title('channel 2 - nuclei')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(masks_train[irand])\n",
    "plt.title('cell masks')\n",
    "print(f'there are {masks_train[irand].max()} cells in this image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What labels will we use? We can't use numbers like masks.\n",
    "The standard approach is to create a \"not-cell\" and a \"cell\" probability map for the network to learn. Then this map is thresholded (the threshold is found with a validation set) to find cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "labels_train = np.zeros((len(masks_train), 2,\n",
    "                         masks_train.shape[-2],\n",
    "                         masks_train.shape[-1]),\n",
    "                        np.long)\n",
    "labels_train[:, 0] = masks_train == 0\n",
    "labels_train[:, 1] = masks_train > 0\n",
    "\n",
    "labels_test = np.zeros((len(masks_test), 2,\n",
    "                        masks_test.shape[-2],\n",
    "                        masks_test.shape[-1]),\n",
    "                       np.long)\n",
    "labels_test[:, 0] = masks_test == 0\n",
    "labels_test[:, 1] = masks_test > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Create transform function for augmentations\n",
    "\n",
    "adapted from [cellpose/transforms.py](https://github.com/MouseLand/cellpose/blob/master/cellpose/transforms.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def random_rotate_and_resize(X, Y=None, scale_range=0.5, xy=(224, 224),\n",
    "                             do_flip=True):\n",
    "  \"\"\"\n",
    "  Augmentation by random rotation and resizing\n",
    "\n",
    "  X and Y are lists or arrays of length nimg, with dims channels x Ly x Lx (channels optional)\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  X: ND-array, float\n",
    "    list of IMAGE arrays of size [nchan x Ly x Lx] or [Ly x Lx]\n",
    "\n",
    "  Y: ND-array, float or int (optional, default None)\n",
    "    list of MASK arrays of size [nlabels x Ly x Lx] or [Ly x Lx].\n",
    "    ** These labels are nearest neighbor interpolated\n",
    "    ** CHANGE IF USING FLOAT LABELS\n",
    "\n",
    "  scale_range: float (optional, default 1.0)\n",
    "    Range of resizing of images for augmentation. Images are resized by\n",
    "    (1-scale_range/2) + scale_range * np.random.rand()\n",
    "\n",
    "  xy: tuple, int (optional, default (224,224))\n",
    "    size of transformed images to return\n",
    "\n",
    "  do_flip: bool (optional, default True)\n",
    "    whether or not to flip images horizontally\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  imgi: ND-array, float\n",
    "    transformed images in array [nimg x nchan x xy[0] x xy[1]]\n",
    "\n",
    "  lbl: ND-array, float\n",
    "    transformed labels in array [nimg x nchan x xy[0] x xy[1]]\n",
    "\n",
    "  scale: array, float\n",
    "    amount each image was resized by\n",
    "  \"\"\"\n",
    "\n",
    "  scale_range = max(0, min(2, float(scale_range)))\n",
    "  nimg = len(X)\n",
    "  if X[0].ndim > 2:\n",
    "    nchan = X[0].shape[0]\n",
    "  else:\n",
    "    nchan = 1\n",
    "  imgi  = np.zeros((nimg, nchan, xy[0], xy[1]), np.float32)\n",
    "\n",
    "  lbl = []\n",
    "  if Y is not None:\n",
    "    if Y[0].ndim > 2:\n",
    "      nt = Y[0].shape[0]\n",
    "    else:\n",
    "      nt = 1\n",
    "    lbl = np.zeros((nimg, nt, xy[0], xy[1]), Y.dtype)\n",
    "\n",
    "  scale = np.zeros(nimg, np.float32)\n",
    "  for n in range(nimg):\n",
    "    Ly, Lx = X[n].shape[-2:]\n",
    "\n",
    "    # generate random augmentation parameters\n",
    "    flip = np.random.rand() > .5\n",
    "    theta = np.random.rand() * np.pi * 2\n",
    "    scale[n] = (1 - scale_range / 2) + scale_range * np.random.rand()\n",
    "    dxy = np.maximum(0, np.array([Lx*scale[n] - xy[1], Ly * scale[n] - xy[0]]))\n",
    "    dxy = (np.random.rand(2,) - .5) * dxy\n",
    "\n",
    "    # create affine transform\n",
    "    cc = np.array([Lx / 2, Ly / 2])\n",
    "    cc1 = cc - np.array([Lx - xy[1], Ly - xy[0]]) / 2 + dxy\n",
    "    pts1 = np.float32([cc, cc + np.array([1, 0]), cc + np.array([0, 1])])\n",
    "    pts2 = np.float32([cc1,\n",
    "            cc1 + scale[n]*np.array([np.cos(theta), np.sin(theta)]),\n",
    "            cc1 + scale[n]*np.array([np.cos(np.pi/2 + theta),\n",
    "                                     np.sin(np.pi/2 + theta)])])\n",
    "\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    img = X[n].copy()\n",
    "    if Y is not None:\n",
    "      labels = Y[n].copy()\n",
    "      if labels.ndim < 3:\n",
    "        labels = labels[np.newaxis, :, :]\n",
    "\n",
    "    if flip and do_flip:\n",
    "      img = img[..., ::-1]\n",
    "      if Y is not None:\n",
    "        labels = labels[..., ::-1]\n",
    "\n",
    "    for k in range(nchan):\n",
    "      I = cv2.warpAffine(img[k], M, (xy[1], xy[0]), flags=cv2.INTER_LINEAR)\n",
    "      imgi[n,k] = I\n",
    "\n",
    "    if Y is not None:\n",
    "      for k in range(nt):\n",
    "        # ** nearest neighbor interpolation **\n",
    "        # may need to change for float labels\n",
    "        lbl[n,k] = cv2.warpAffine(labels[k], M, (xy[1], xy[0]),\n",
    "                                  flags=cv2.INTER_NEAREST)\n",
    "\n",
    "  return imgi, lbl, scale\n",
    "\n",
    "\n",
    "img_batch, lbl_batch, scale = random_rotate_and_resize(imgs_train[:8],\n",
    "                                                       masks_train[:8])\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for j in range(8):\n",
    "  plt.subplot(8, 3, 3*j + 1)\n",
    "  plt.imshow(img_batch[j, 0])\n",
    "  plt.title('channel 1 - cytoplasm')\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.subplot(8, 3, 3*j + 2)\n",
    "  plt.imshow(img_batch[j, 1])\n",
    "  plt.title('channel 2 - nuclei')\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.subplot(8, 3, 3*j + 3)\n",
    "  plt.imshow(lbl_batch[j, 0])\n",
    "  plt.title('cell masks')\n",
    "  plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Model architecture (u-net)\n",
    "\n",
    "A u-net is commonly used for biological image segmentation because its shape allows for local and global features to be combined to create highly-precise segmentations.\n",
    "\n",
    "A u-net is shaped like an autoencoder, it has:\n",
    "1. a standard convolutional network with downsampling, like one used for imagenet\n",
    "2. upsampling layers that ultimately return an image at the same size as the input image\n",
    "In addition to these downsampling and upsampling blocks, it has skip connections from the downsampling blocks TO the upsampling blocks, which allows it to propagate more precise local information to the later layers.\n",
    "\n",
    "adapted from [cellpose/resnet_torch.py](https://github.com/MouseLand/cellpose/blob/master/cellpose/resnet_torch.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def convbatchrelu(in_channels, out_channels, sz):\n",
    "  return nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, sz, padding=sz//2),\n",
    "      nn.BatchNorm2d(out_channels, eps=1e-5),\n",
    "      nn.ReLU(inplace=True),\n",
    "      )\n",
    "\n",
    "\n",
    "class convdown(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Sequential()\n",
    "    for t in range(2):\n",
    "      if t == 0:\n",
    "        self.conv.add_module('conv_%d'%t,\n",
    "                             convbatchrelu(in_channels,\n",
    "                                           out_channels,\n",
    "                                           kernel_size))\n",
    "      else:\n",
    "        self.conv.add_module('conv_%d'%t,\n",
    "                             convbatchrelu(out_channels,\n",
    "                                           out_channels,\n",
    "                                           kernel_size))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv[0](x)\n",
    "    x = self.conv[1](x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class downsample(nn.Module):\n",
    "  def __init__(self, nbase, kernel_size):\n",
    "    super().__init__()\n",
    "    self.down = nn.Sequential()\n",
    "    self.maxpool = nn.MaxPool2d(2, 2)\n",
    "    for n in range(len(nbase) - 1):\n",
    "      self.down.add_module('conv_down_%d'%n,\n",
    "                           convdown(nbase[n],\n",
    "                                    nbase[n + 1],\n",
    "                                    kernel_size))\n",
    "\n",
    "  def forward(self, x):\n",
    "    xd = []\n",
    "    for n in range(len(self.down)):\n",
    "      if n > 0:\n",
    "        y = self.maxpool(xd[n - 1])\n",
    "      else:\n",
    "        y = x\n",
    "      xd.append(self.down[n](y))\n",
    "    return xd\n",
    "\n",
    "\n",
    "class convup(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Sequential()\n",
    "    self.conv.add_module('conv_0', convbatchrelu(in_channels,\n",
    "                                                 out_channels,\n",
    "                                                 kernel_size))\n",
    "    self.conv.add_module('conv_1', convbatchrelu(out_channels,\n",
    "                                                 out_channels,\n",
    "                                                 kernel_size))\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    x = self.conv[0](x)\n",
    "    x = self.conv[1](x + y)\n",
    "    return x\n",
    "\n",
    "\n",
    "class upsample(nn.Module):\n",
    "  def __init__(self, nbase, kernel_size):\n",
    "    super().__init__()\n",
    "    self.upsampling = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "    self.up = nn.Sequential()\n",
    "    for n in range(len(nbase) - 1 , 0, -1):\n",
    "      self.up.add_module('conv_up_%d'%(n - 1),\n",
    "              convup(nbase[n], nbase[n - 1], kernel_size))\n",
    "\n",
    "  def forward(self, xd):\n",
    "    x = xd[-1]\n",
    "    for n in range(0, len(self.up)):\n",
    "      if n > 0:\n",
    "        x = self.upsampling(x)\n",
    "      x = self.up[n](x, xd[len(xd) - 1 - n])\n",
    "    return x\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "  def __init__(self, nbase, nout, kernel_size):\n",
    "    super(Unet, self).__init__()\n",
    "    self.nbase = nbase\n",
    "    self.nout = nout\n",
    "    self.kernel_size = kernel_size\n",
    "    self.downsample = downsample(nbase, kernel_size)\n",
    "    nbaseup = nbase[1:]\n",
    "    nbaseup.append(nbase[-1])\n",
    "    self.upsample = upsample(nbaseup, kernel_size)\n",
    "    self.output = nn.Conv2d(nbase[1], self.nout, kernel_size,\n",
    "                            padding=kernel_size//2)\n",
    "\n",
    "  def forward(self, data):\n",
    "    T0 = self.downsample(data)\n",
    "    T0 = self.upsample(T0)\n",
    "    T0 = self.output(T0)\n",
    "    return T0\n",
    "\n",
    "  def save_model(self, filename):\n",
    "    torch.save(self.state_dict(), filename)\n",
    "\n",
    "  def load_model(self, filename, cpu=False):\n",
    "    if not cpu:\n",
    "      self.load_state_dict(torch.load(filename))\n",
    "    else:\n",
    "      self.__init__(self.nbase,\n",
    "                    self.nout,\n",
    "                    self.kernel_size,\n",
    "                    self.concatenation)\n",
    "\n",
    "      self.load_state_dict(torch.load(filename,\n",
    "                                      map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "nbase = [2, 32, 64, 128, 256]  # number of channels per layer\n",
    "nout = 2  # number of outputs\n",
    "\n",
    "net = Unet(nbase, nout, kernel_size)\n",
    "# put on GPU here if you have it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device);  # remove semi-colon to see net structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Train the network\n",
    "\n",
    "Here we've implemented code to train the network.\n",
    "\n",
    "Note we probably should be evaluating test performance throughout training -- implement that yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# train the network\n",
    "# parameters related to training the network\n",
    "batch_size = 8 # number of images per batch -- amount of required memory\n",
    "              # for training will increase linearly in batchsize\n",
    "### you will want to increase n_epochs!\n",
    "n_epochs = 50  # number of times to cycle through all the data during training\n",
    "learning_rate = 0.1 # initial learning rate\n",
    "weight_decay = 1e-5 # L2 regularization of weights\n",
    "momentum = 0.9 # how much to use previous gradient direction\n",
    "n_epochs_per_save = 25 # how often to save the network\n",
    "val_frac = 0.05 # what fraction of data to use for validation\n",
    "\n",
    "# where to save the network\n",
    "# make sure to clean these out every now and then, as you will run out of space\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "# split into train and validation datasets\n",
    "n_val = int(len(imgs_train) * val_frac)\n",
    "n_train = len(imgs_train) - n_val\n",
    "np.random.seed(0)\n",
    "iperm = np.random.permutation(len(imgs_train))\n",
    "train_data, val_data = imgs_train[iperm[:n_train]], imgs_train[iperm[n_train:]]\n",
    "train_labels, val_labels = labels_train[iperm[:n_train]], labels_train[iperm[n_train:]]\n",
    "train_masks, val_masks = masks_train[iperm[:n_train]], masks_train[iperm[n_train:]]\n",
    "\n",
    "\n",
    "# gradient descent flavor\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=learning_rate,\n",
    "                            weight_decay=weight_decay,\n",
    "                            momentum=0.9)\n",
    "# set learning rate schedule\n",
    "LR = np.linspace(0, learning_rate, 10)\n",
    "if n_epochs > 250:\n",
    "    LR = np.append(LR, learning_rate*np.ones(n_epochs-100))\n",
    "    for i in range(10):\n",
    "        LR = np.append(LR, LR[-1]/2 * np.ones(10))\n",
    "else:\n",
    "    LR = np.append(LR, learning_rate * np.ones(max(0, n_epochs - 10)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# store loss per epoch\n",
    "epoch_losses = np.zeros(n_epochs)\n",
    "epoch_losses[:] = np.nan\n",
    "\n",
    "# when we last saved the network\n",
    "saveepoch = None\n",
    "\n",
    "# loop through entire training data set nepochs times\n",
    "for epoch in range(n_epochs):\n",
    "  net.train() # put in train mode (affects batchnorm)\n",
    "  epoch_loss = 0\n",
    "  iters = 0\n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = LR[epoch]\n",
    "  with tqdm.tqdm(total=n_train, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit='img') as pbar:\n",
    "    # loop through each batch in the training data\n",
    "    for ibatch in np.arange(0, n_train, batch_size):\n",
    "      # augment the data\n",
    "      inds = np.arange(ibatch, min(n_train, ibatch+batch_size))\n",
    "      imgs, lbls, _ = random_rotate_and_resize(train_data[inds],\n",
    "                                               train_labels[inds])\n",
    "\n",
    "      # transfer to torch + GPU\n",
    "      imgs = torch.from_numpy(imgs).to(device=device)\n",
    "      lbls = torch.from_numpy(lbls).to(device=device)\n",
    "\n",
    "      # compute the loss\n",
    "      y = net(imgs)\n",
    "      loss = criterion(y, lbls[:, 1])\n",
    "      epoch_loss += loss.item()\n",
    "      pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "      # gradient descent\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      #nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "      optimizer.step()\n",
    "      iters+=1\n",
    "      pbar.update(imgs.shape[0])\n",
    "\n",
    "    epoch_losses[epoch] = epoch_loss\n",
    "    pbar.set_postfix(**{'loss (epoch)': epoch_loss})  #.update('loss (epoch) = %f'%epoch_loss)\n",
    "\n",
    "  # save checkpoint networks every now and then\n",
    "  if epoch % n_epochs_per_save == 0:\n",
    "    print(f\"\\nSaving network state at epoch {epoch+1}\")\n",
    "    saveepoch = epoch\n",
    "    savefile = f\"unet_epoch{saveepoch+1}.pth\"\n",
    "    net.save_model(savefile)\n",
    "print(f\"\\nSaving network state at epoch {epoch+1}\")\n",
    "net.save_model(f\"unet_epoch{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Test performance\n",
    "\n",
    "Let's see how the network performs on a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Padding code for test images\n",
    "\n",
    "def pad_image_ND(img0, div=16, extra=1):\n",
    "  \"\"\" pad image for test-time so that its dimensions are a multiple of 16 (2D or 3D)\n",
    "\n",
    "  Parameters\n",
    "  -------------\n",
    "  img0: ND-array\n",
    "      image of size [nchan (x Lz) x Ly x Lx]\n",
    "  div: int (optional, default 16)\n",
    "\n",
    "  Returns\n",
    "  --------------\n",
    "  I: ND-array\n",
    "      padded image\n",
    "  slices: tuple, int\n",
    "      range of pixels in I corresponding to img0\n",
    "  \"\"\"\n",
    "  Lpad = int(div * np.ceil(img0.shape[-2] / div) - img0.shape[-2])\n",
    "  xpad1 = extra * div//2 + Lpad//2\n",
    "  xpad2 = extra * div//2 + Lpad - Lpad//2\n",
    "  Lpad = int(div * np.ceil(img0.shape[-1] / div) - img0.shape[-1])\n",
    "  ypad1 = extra * div//2 + Lpad//2\n",
    "  ypad2 = extra * div//2 + Lpad - Lpad//2\n",
    "\n",
    "  if img0.ndim > 3:\n",
    "    pads = np.array([[0, 0], [0, 0], [xpad1, xpad2], [ypad1, ypad2]])\n",
    "  else:\n",
    "    pads = np.array([[0, 0], [xpad1, xpad2], [ypad1, ypad2]])\n",
    "\n",
    "  I = np.pad(img0, pads, mode='constant')\n",
    "\n",
    "  Ly, Lx = img0.shape[-2:]\n",
    "  ysub = np.arange(xpad1, xpad1 + Ly)\n",
    "  xsub = np.arange(ypad1, ypad1 + Lx)\n",
    "  slc = [slice(0, img0.shape[n] + 1) for n in range(img0.ndim)]\n",
    "  slc[-3] = slice(0, imgs.shape[-3] + 1)\n",
    "  slc[-2] = slice(ysub[0], ysub[-1] + 1)\n",
    "  slc[-1] = slice(xsub[0], xsub[-1] + 1)\n",
    "  slc = tuple(slc)\n",
    "\n",
    "  return I, slc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# compute results on test images\n",
    "# (note for unet to run correctly we need to pad images to be divisible by 2**(number of layers))\n",
    "\n",
    "net.eval()\n",
    "img_padded, slices = pad_image_ND(imgs_test[0], 8)\n",
    "img_torch = torch.from_numpy(img_padded).to(device).unsqueeze(0)  # also need to add a first dimension\n",
    "out = net(img_torch)\n",
    "labels = out[0][slices].detach().cpu()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(imgs_test[0][0], vmin=0, vmax=1)\n",
    "plt.title('channel 1 - cytoplasm')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(imgs_test[0][1], vmin=0, vmax=1)\n",
    "plt.title('channel 2 - nuclei')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(labels[0])\n",
    "plt.title('not cell prediction')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(labels[1])\n",
    "plt.title('cell prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Setting threshold for finding cells\n",
    "\n",
    "We have found areas of \"not cell\" and \"cell\". To create an instance segmentation we need to assign each pixel in a cell to a specific cell rather than a general class. To do this, we will need to find a threshold that produces the best segmentations on our validation set. How do we define a good segmentation? We can use a measure called intersection-over-union (IoU) and call a cell a good cell if it overlaps with a ground-truth cell with an IoU greater than some value. We have taken code from [cellpose/metrics.py] to do this. These functions are based on functions from [stardist], another neat algorithm I recommend checking out!\n",
    "\n",
    "This code below computes the average precision (which you want to maximize) for a given threshold. You'll want to try several thresholds and choose one (probably coding up a loop over reasonable thresholds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# @markdown `fill_holes_and_remove_small_masks` function\n",
    "def fill_holes_and_remove_small_masks(masks, min_size=15):\n",
    "  \"\"\" fill holes in masks (2D/3D) and discard masks smaller than min_size (2D)\n",
    "\n",
    "  fill holes in each mask using scipy.ndimage.morphology.binary_fill_holes\n",
    "\n",
    "  Parameters\n",
    "  ----------------\n",
    "  masks: int, 2D or 3D array\n",
    "      labelled masks, 0=NO masks; 1,2,...=mask labels,\n",
    "      size [Ly x Lx] or [Lz x Ly x Lx]\n",
    "  min_size: int (optional, default 15)\n",
    "      minimum number of pixels per mask, can turn off with -1\n",
    "\n",
    "  Returns\n",
    "  ---------------\n",
    "  masks: int, 2D or 3D array\n",
    "      masks with holes filled and masks smaller than min_size removed,\n",
    "      0=NO masks; 1,2,...=mask labels,\n",
    "      size [Ly x Lx] or [Lz x Ly x Lx]\n",
    "  \"\"\"\n",
    "  slices = find_objects(masks)\n",
    "  j = 0\n",
    "  for i,slc in enumerate(slices):\n",
    "    if slc is not None:\n",
    "      msk = masks[slc] == (i + 1)\n",
    "      npix = msk.sum()\n",
    "      if min_size > 0 and npix < min_size:\n",
    "        masks[slc][msk] = 0\n",
    "      else:\n",
    "        if msk.ndim==3:\n",
    "          for k in range(msk.shape[0]):\n",
    "            msk[k] = binary_fill_holes(msk[k])\n",
    "        else:\n",
    "          msk = binary_fill_holes(msk)\n",
    "        masks[slc][msk] = (j + 1)\n",
    "        j += 1\n",
    "\n",
    "  return masks\n",
    "\n",
    "\n",
    "# @markdown `average_precision` function\n",
    "def average_precision(masks_true, masks_pred, threshold=[0.5, 0.75, 0.9]):\n",
    "  \"\"\" average precision estimation: AP = TP / (TP + FP + FN)\n",
    "\n",
    "  This function is based heavily on the *fast* stardist matching functions\n",
    "  (https://github.com/mpicbg-csbd/stardist/blob/master/stardist/matching.py)\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  masks_true: list of ND-arrays (int)\n",
    "      where 0=NO masks; 1,2... are mask labels\n",
    "  masks_pred: list of ND-arrays (int)\n",
    "      ND-array (int) where 0=NO masks; 1,2... are mask labels\n",
    "\n",
    "  Returns\n",
    "  ------------\n",
    "  ap: array [len(masks_true) x len(threshold)]\n",
    "      average precision at thresholds\n",
    "  tp: array [len(masks_true) x len(threshold)]\n",
    "      number of true positives at thresholds\n",
    "  fp: array [len(masks_true) x len(threshold)]\n",
    "      number of false positives at thresholds\n",
    "  fn: array [len(masks_true) x len(threshold)]\n",
    "      number of false negatives at thresholds\n",
    "  \"\"\"\n",
    "  if not isinstance(threshold, list) and not isinstance(threshold, np.ndarray):\n",
    "    threshold = [threshold]\n",
    "  ap  = np.zeros((len(masks_true), len(threshold)), np.float32)\n",
    "  tp  = np.zeros((len(masks_true), len(threshold)), np.float32)\n",
    "  fp  = np.zeros((len(masks_true), len(threshold)), np.float32)\n",
    "  fn  = np.zeros((len(masks_true), len(threshold)), np.float32)\n",
    "  n_true = np.array(list(map(np.max, masks_true)))\n",
    "  n_pred = np.array(list(map(np.max, masks_pred)))\n",
    "  for n in range(len(masks_true)):\n",
    "    #_,mt = np.reshape(np.unique(masks_true[n], return_index=True), masks_pred[n].shape)\n",
    "    if n_pred[n] > 0:\n",
    "      iou = _intersection_over_union(masks_true[n], masks_pred[n])[1:, 1:]\n",
    "      for k,th in enumerate(threshold):\n",
    "        tp[n,k] = _true_positive(iou, th)\n",
    "    fp[n] = n_pred[n] - tp[n]\n",
    "    fn[n] = n_true[n] - tp[n]\n",
    "    ap[n] = tp[n] / (tp[n] + fp[n] + fn[n])\n",
    "\n",
    "  return ap, tp, fp, fn\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _label_overlap(x, y):\n",
    "  \"\"\" fast function to get pixel overlaps between masks in x and y\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  x: ND-array, int\n",
    "      where 0=NO masks; 1,2... are mask labels\n",
    "  y: ND-array, int\n",
    "      where 0=NO masks; 1,2... are mask labels\n",
    "\n",
    "  Returns\n",
    "  ------------\n",
    "  overlap: ND-array, int\n",
    "      matrix of pixel overlaps of size [x.max()+1, y.max()+1]\n",
    "  \"\"\"\n",
    "  x = x.ravel()\n",
    "  y = y.ravel()\n",
    "  overlap = np.zeros((1 + x.max(), 1 + y.max()), dtype=np.uint)\n",
    "  for i in range(len(x)):\n",
    "    overlap[x[i], y[i]] += 1\n",
    "\n",
    "  return overlap\n",
    "\n",
    "\n",
    "def _intersection_over_union(masks_true, masks_pred):\n",
    "  \"\"\" intersection over union of all mask pairs\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  masks_true: ND-array, int\n",
    "      ground truth masks, where 0=NO masks; 1,2... are mask labels\n",
    "  masks_pred: ND-array, int\n",
    "      predicted masks, where 0=NO masks; 1,2... are mask labels\n",
    "\n",
    "  Returns\n",
    "  ------------\n",
    "  iou: ND-array, float\n",
    "      matrix of IOU pairs of size [x.max()+1, y.max()+1]\n",
    "  \"\"\"\n",
    "  overlap = _label_overlap(masks_true, masks_pred)\n",
    "  n_pixels_pred = np.sum(overlap, axis=0, keepdims=True)\n",
    "  n_pixels_true = np.sum(overlap, axis=1, keepdims=True)\n",
    "  iou = overlap / (n_pixels_pred + n_pixels_true - overlap)\n",
    "  iou[np.isnan(iou)] = 0.0\n",
    "\n",
    "  return iou\n",
    "\n",
    "\n",
    "def _true_positive(iou, th):\n",
    "  \"\"\" true positive at threshold th\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  iou: float, ND-array\n",
    "      array of IOU pairs\n",
    "  th: float\n",
    "      threshold on IOU for positive label\n",
    "\n",
    "  Returns\n",
    "  ------------\n",
    "  tp: float\n",
    "      number of true positives at threshold\n",
    "  \"\"\"\n",
    "  n_min = min(iou.shape[0], iou.shape[1])\n",
    "  costs = -(iou >= th).astype(float) - iou / (2 * n_min)\n",
    "  true_ind, pred_ind = linear_sum_assignment(costs)\n",
    "  match_ok = iou[true_ind, pred_ind] >= th\n",
    "  tp = match_ok.sum()\n",
    "\n",
    "  return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def get_masks_unet(output, cell_threshold=0, min_size=30):\n",
    "  \"\"\" create masks using NOT CELL probability and CELL probability\n",
    "\n",
    "  min_size: minimum number of pixels in the masks\n",
    "  \"\"\"\n",
    "\n",
    "  cells = (output[1] - output[0]) > cell_threshold\n",
    "  selem = generate_binary_structure(cells.ndim, connectivity=1)\n",
    "  masks, nlabels = label(cells, selem)\n",
    "  shape0 = masks.shape\n",
    "  _,masks = np.unique(masks, return_inverse=True)\n",
    "  masks = np.reshape(masks, shape0)\n",
    "  # fill holes and remove small masks\n",
    "  masks = fill_holes_and_remove_small_masks(masks, min_size=min_size)\n",
    "\n",
    "  return masks.astype(np.uint16)\n",
    "\n",
    "\n",
    "# Run the model\n",
    "net.eval()\n",
    "# (depending on GPU capacity you may need to run this in a loop)\n",
    "val_padded, slices = pad_image_ND(val_data, 8)\n",
    "val_torch = torch.from_numpy(val_padded).to(device)\n",
    "out = net(val_torch)\n",
    "# compute CELL / NOT CELL probability\n",
    "labels = out[slices].detach().cpu().numpy()\n",
    "\n",
    "# create masks from probabilities\n",
    "cell_threshold = 2.5\n",
    "masks = [get_masks_unet(lbl, cell_threshold=cell_threshold) for lbl in labels]\n",
    "\n",
    "# (note this function expects multiple masks)\n",
    "iou_threshold = np.arange(0.5, 1, 0.1)\n",
    "ap = average_precision(val_masks, masks, threshold=iou_threshold)[0]\n",
    "\n",
    "# plot results\n",
    "print(ap[:, 0].mean(axis=0))\n",
    "plt.plot(iou_threshold, ap.mean(axis=0))\n",
    "plt.xlabel('IoU threshold')\n",
    "plt.ylabel('average precision')\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Once you choose a threshold, you'll want to use it on your test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "# (depending on GPU capacity you may need to run this in a loop)\n",
    "test_padded, slices = pad_image_ND(imgs_test, 8)\n",
    "test_torch = torch.from_numpy(test_padded).to(device)\n",
    "out = net(test_torch)\n",
    "# compute CELL / NOT CELL probability\n",
    "labels = out[slices].detach().cpu().numpy()\n",
    "\n",
    "# create masks from probabilities\n",
    "masks = [get_masks_unet(lbl, cell_threshold=cell_threshold) for lbl in labels]\n",
    "\n",
    "# (note this function expects multiple masks)\n",
    "iou_threshold = np.arange(0.5, 1, 0.1)\n",
    "ap = average_precision(masks_test, masks, threshold=iou_threshold)[0]\n",
    "\n",
    "# plot results\n",
    "print(ap[:,0].mean(axis=0))\n",
    "plt.plot(iou_threshold, ap.mean(axis=0))\n",
    "plt.xlabel('IoU threshold')\n",
    "plt.ylabel('average precision')\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What kinds of errors is the network making?\n",
    "\n",
    "U-nets with this type of prediction (CELL/NOT CELL) typically overmerge cells. You may see some examples below. In the text at the beginning, ways to avoid this problem are discussed and also one instance (distance to boundary) is implemented in the cellpose repository. \n",
    "\n",
    "You can also compare your results to cellpose using the web interface at [www.cellpose.org](https://www.cellpose.org).\n",
    "\n",
    "Below you can see that we are plotting the ground truth masks (the true masks) and the masks that the algorithm predicted. It may be sort of hard to compare the masks in a jupyter-notebook. One useful tool to visualize imaging data is [napari](https://www.napari.org). You can try running it on your local computer and visualizing your predictions overlaid on the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 15))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(masks_test[0])\n",
    "plt.title('ground truth masks')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(masks[0])\n",
    "plt.title('predicted masks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Analysis of neuronal activity in the brain\n",
    "\n",
    "This is a calcium imaging recording in mouse visual cortex taken at an imaging rate of 10Hz. There are 4500 frames of size 325 x 556 pixels each.\n",
    "\n",
    "Let's load the data and try to find some cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Download and load the data.\n",
    "from tifffile import imread\n",
    "\n",
    "fname = \"gt1.tif\"\n",
    "url = \"https://www.suite2p.org/test_data/gt1.tif\"\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"!!! Failed to download data !!!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)\n",
    "\n",
    "data = imread(fname)\n",
    "print(f\"imaging data of shape: {data.shape}\")\n",
    "n_time, Ly, Lx = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Finding cells\n",
    "\n",
    "This process can be improved by adding training data to the model and/or improving the type of filtering done by the image and/or by finding cells using temporal information. We've used our previously trained network to find some cells as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# plot max image across time\n",
    "max_img = normalize99(data.max(axis=0))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(max_img, vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# normalize intensity across image\n",
    "max_img_filtered = max_img.copy() / gaussian_filter(max_img, 100)\n",
    "# high pass filter\n",
    "max_img_filtered = max_img_filtered - gaussian_filter(max_img, 10)\n",
    "max_img_filtered = normalize99(max_img_filtered)\n",
    "## take threshold of image to find cells\n",
    "# masks = get_masks_unet(np.stack((1 - max_img, max_img), axis=0), cell_threshold=0.3)\n",
    "\n",
    "### can try running network trained above (on unfiltered or filtered)\n",
    "net.eval()\n",
    "# resize larger because cells are smaller here\n",
    "max_img_large = cv2.resize(max_img_filtered, (Lx*2, Ly*2))\n",
    "max_img_2chan = np.stack((max_img_large, np.zeros_like(max_img_large)), axis=0)\n",
    "# run network\n",
    "img_padded, slices = pad_image_ND(max_img_2chan, 8)\n",
    "img_torch = torch.from_numpy(img_padded).to(device).unsqueeze(0)  # also need to add a first dimension\n",
    "out = net(img_torch)\n",
    "labels = out[0][slices].detach().cpu()\n",
    "\n",
    "# THIS CELL_THRESHOLD NEEDS TO BE SET BY HAND! IT VARIES FROM NETWORK TO NETWORK\n",
    "masks = get_masks_unet(labels, cell_threshold=3.5, min_size=30)\n",
    "masks = cv2.resize(masks, (Lx, Ly), cv2.INTER_NEAREST)\n",
    "\n",
    "plt.figure(figsize=(12, 20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(max_img_filtered, vmin=0, vmax=1)\n",
    "plt.title('max img filtered')\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(masks > 0)\n",
    "plt.title('masks > 0')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(masks)\n",
    "plt.title('masks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Neural activity\n",
    "\n",
    "We can use these masks to find neural activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "n_cells = masks.max()\n",
    "fluorescence = np.zeros((n_cells, n_time), np.float32)\n",
    "for n in range(n_cells):\n",
    "  fluorescence[n] = data[:, masks==(n + 1)].sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(fluorescence[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Denoising\n",
    "\n",
    "There may be some noise in the imaging trace, can we correct it by building a denoising network?\n",
    "\n",
    "Take the u-net architecture from above and modify it to take as inputs multiple sequential frames with the middle frame left out, and predict the middle frame. Check out this [paper](https://www.biorxiv.org/content/10.1101/2020.10.15.341602v2.full) from the Allen Institute for more guidance.\n",
    "\n",
    "Note you can use this strategy on a variety of datasets with spatial and temporal structure, such as movies taken in low light conditions.\n",
    "\n",
    "You could also try this approach on neural data without spatial structure (but you would have to replace the convolutions with fully connected layers)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cellular_segmentation",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
