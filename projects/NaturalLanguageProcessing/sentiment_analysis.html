
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Twitter Sentiment Analysis &#8212; Neuromatch Academy: Deep Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'projects/NaturalLanguageProcessing/sentiment_analysis';</script>
    <link rel="shortcut icon" href="../../_static/nma-dl-logo-square-4xp.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Machine Translation" href="machine_translation.html" />
    <link rel="prev" title="Ideas" href="ideas_and_datasets.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">
                        Optimization (W1D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">
                        Optimization (W1D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorials/intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/TechnicalHelp/Discord.html">Using Discord</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../prereqs/DeepLearning.html">Prerequisites and preparatory materials for NMA Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics Module</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">Basics And Pytorch (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">Tutorial 1: PyTorch</a></li>









</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">Linear Deep Learning (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">Tutorial 1: Gradient Descent and AutoGrad</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">Tutorial 2: Learning Hyperparameters</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">Tutorial 3: Deep linear neural networks</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">Bonus Lecture: Yoshua Bengio</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">Multi Layer Perceptrons (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">Tutorial 1: Biological vs. Artificial Neural Networks</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">Tutorial 2: Deep MLPs</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Fine Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">Optimization (W1D4)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D4_Optimization/student/W1D4_Tutorial1.html">Tutorial 1: Optimization techniques</a></li>













</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">Regularization (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial1.html">Tutorial 1: Regularization techniques part 1</a></li>









<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial2.html">Tutorial 2: Regularization techniques part 2</a></li>










</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/FineTuning.html">Deep Learning: The Basics and Fine Tuning Wrap-up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ConvNets and Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">Convnets And Dl Thinking (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">Tutorial 1: Introduction to CNNs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">Tutorial 2: Deep Learning Thinking 1: Cost Functions</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">Bonus Lecture: Kyunghyun Cho</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">Modern Convnets (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial1.html">Tutorial 1: Learn how to use modern convnets</a></li>












<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial2.html">Bonus Tutorial: Facial recognition using modern convnets</a></li>






</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">Generative Models (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.html">Tutorial 1: Variational Autoencoders (VAEs)</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial2.html">Tutorial 2: Diffusion models</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial3.html">Tutorial 3: Image, Conditional Diffusion and Beyond</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_BonusLecture.html">Bonus Lecture: Geoffrey Hinton</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">Attention And Transformers (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial1.html">Tutorial 1: Learn how to work with Transformers</a></li>













<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial2.html">Bonus Tutorial: Understanding Pre-training, Fine-tuning and Robustness of Transformers</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">Time Series And Natural Language Processing (W3D1)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial1.html">Tutorial 1: Introduction to processing time series</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial2.html">Tutorial 2: Natural Language Processing and LLMs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial3.html">Bonus Tutorial: Multilingual Embeddings</a></li>



</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">Dl Thinking2 (W3D2)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/student/W3D2_Tutorial1.html">Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking</a></li>








</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">Deep Learning: Convnets and NLP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unsupervised and Reinforcement Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">Unsupervised And Self Supervised Learning (W3D3)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">Tutorial 1: Un/Self-supervised learning methods</a></li>














<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">Bonus Lecture: Melanie Mitchell</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">Basic Reinforcement Learning (W3D4)</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">Tutorial 1: Basic Reinforcement Learning</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">Bonus Lecture: Chealsea Finn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">Reinforcement Learning For Games And Dl Thinking3 (W3D5)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial1.html">Tutorial 1: Reinforcement Learning For Games</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial2.html">Tutorial 2: Deep Learning Thinking 3</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial3.html">Bonus Tutorial: Planning with Monte Carlo Tree Search</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_BonusLecture.html">Bonus Lecture: Amita Kapoor</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deploy Models on the Web</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">Deploy Models (Bonus)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/student/Bonus_Tutorial1.html">Bonus Tutorial: Deploying Neural Networks on the Web</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to projects</a></li>







<li class="toctree-l1"><a class="reference internal" href="../docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modelingsteps/intro.html">Modeling Step-by-Step Guide</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_1through2_DL.html">Modeling Steps 1 - 2</a></li>




<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_3through4_DL.html">Modeling Steps 3 - 4</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_5through6_DL.html">Modeling Steps 5 - 6</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_7through9_DL.html">Modeling Steps 7 - 9</a></li>



<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_10_DL.html">Modeling Steps 10</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionDataProjectDL.html">Example Data Project: the Train Illusion</a></li>













<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionModelingProjectDL.html">Example Model Project: the Train Illusion</a></li>












<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/Example_Deep_Learning_Project.html">Example Deep Learning Project</a></li>












</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../docs/projects_overview.html">Project Templates</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../ComputerVision/README.html">Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/em_synapses.html">Knowledge Extraction from a Convolutional Neural Network</a></li>





<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/spectrogram_analysis.html">Music classification and generation with spectrograms</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/screws.html">Something Screwy - image recognition, detection, and classification of screws</a></li>







<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/data_augmentation.html">Data Augmentation in image classification models</a></li>






<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/transfer_learning.html">Transfer Learning</a></li>



</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../ReinforcementLearning/README.html">Reinforcement Learning</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/ideas_and_datasets.html">Ideas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/robolympics.html">NMA Robolympics: Controlling robots using reinforcement learning</a></li>








<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/lunar_lander.html">Performance Analysis of DQN Algorithm on the Lunar Lander task</a></li>






<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/human_rl.html">Using RL to Model Cognitive Tasks</a></li>




</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="README.html">Natural Language Processing</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3 current active"><a class="current reference internal" href="#">Twitter Sentiment Analysis</a></li>






<li class="toctree-l3"><a class="reference internal" href="machine_translation.html">Machine Translation</a></li>








</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Neuroscience/README.html">Neuroscience</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/pose_estimation.html">Animal Pose Estimation</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/cellular_segmentation.html">Segmentation and Denoising</a></li>





<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/algonauts_videos.html">Load algonauts videos</a></li>



<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/blurry_vision.html">Vision with Lost Glasses: Modelling how the brain deals with noisy input</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/finetuning_fmri.html">Moving beyond Labels: Finetuning CNNs on BOLD response</a></li>




<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/neuro_seq_to_seq.html">Focus on what matters: inferring low-dimensional dynamics from neural recordings</a></li>








</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../docs/datasets_and_models.html">Models and Data sets</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Fprojects/NaturalLanguageProcessing/sentiment_analysis.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../_sources/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Twitter Sentiment Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Twitter Sentiment Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome-to-the-nlp-project-template">
   Welcome to the NLP project template
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-questions-and-goals">
   Step 1: Questions and goals
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-literature-review">
   Step 2: Literature review
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-load-and-explore-the-dataset">
   Step 3: Load and explore the dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     Dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-choose-toolkit">
   Step 4: choose toolkit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explainable-ai">
     Explainable AI
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrent-neural-network-with-pytorch">
     Recurrent Neural Network with Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-s-next">
   What’s Next?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <p><a class="reference external" href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>
<a class="reference external" href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb"><img alt="Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="twitter-sentiment-analysis">
<h1>Twitter Sentiment Analysis<a class="headerlink" href="#twitter-sentiment-analysis" title="Permalink to this heading">#</a></h1>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong>  Juan Manuel Rodriguez, Salomey Osei, Gonzalo Uribarri</p>
<p><strong>Production editors:</strong> Amita Kapoor, Spiros Chavlis</p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="welcome-to-the-nlp-project-template">
<h1>Welcome to the NLP project template<a class="headerlink" href="#welcome-to-the-nlp-project-template" title="Permalink to this heading">#</a></h1>
<img alt="https://imgs.xkcd.com/comics/machine_learning.png" src="https://imgs.xkcd.com/comics/machine_learning.png" />
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-1-questions-and-goals">
<h1>Step 1: Questions and goals<a class="headerlink" href="#step-1-questions-and-goals" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Can we infer emotion from a tweet text?</p></li>
<li><p>How words are distributed accross the dataset?</p></li>
<li><p>Are words related to one kind of emotion?</p></li>
</ul>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-2-literature-review">
<h1>Step 2: Literature review<a class="headerlink" href="#step-2-literature-review" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf">Original Dataset Paper</a></p>
<p><a class="reference external" href="https://paperswithcode.com/dataset/imdb-movie-reviews">Papers with code</a></p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-3-load-and-explore-the-dataset">
<h1>Step 3: Load and explore the dataset<a class="headerlink" href="#step-3-load-and-explore-the-dataset" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas<span class="w"> </span>--quiet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>datasets<span class="w"> </span>--quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">0.0/491.5 kB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">491.5/491.5 kB</span> <span class=" -Color -Color-Red">16.1 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">0.0/193.6 kB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">193.6/193.6 kB</span> <span class=" -Color -Color-Red">17.3 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h<span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.</span>
<span class=" -Color -Color-Red">torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == &quot;Linux&quot; and platform_machine == &quot;x86_64&quot;, but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.</span>

</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We import some libraries to load the dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.notebook</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>
</pre></div>
</div>
</div>
</div>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_patterns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;\&#39;&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\.&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;&lt;br \/&gt;&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\(&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\!&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\?&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\;&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\:&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">]</span>

<span class="n">_replacements</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &#39;  &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot; . &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot; , &quot;</span><span class="p">,</span> <span class="s2">&quot; ( &quot;</span><span class="p">,</span> <span class="s2">&quot; ) &quot;</span><span class="p">,</span> <span class="s2">&quot; ! &quot;</span><span class="p">,</span> <span class="s2">&quot; ? &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">]</span>

<span class="n">_patterns_dict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">((</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">_patterns</span><span class="p">,</span> <span class="n">_replacements</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_basic_english_normalize</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic normalization for a line of text.</span>
<span class="sd">    Normalization includes</span>
<span class="sd">    - lowercasing</span>
<span class="sd">    - complete some basic text normalization for English words as follows:</span>
<span class="sd">        add spaces before and after &#39;\&#39;&#39;</span>
<span class="sd">        remove &#39;\&quot;&#39;,</span>
<span class="sd">        add spaces before and after &#39;.&#39;</span>
<span class="sd">        replace &#39;&lt;br \/&gt;&#39;with single space</span>
<span class="sd">        add spaces before and after &#39;,&#39;</span>
<span class="sd">        add spaces before and after &#39;(&#39;</span>
<span class="sd">        add spaces before and after &#39;)&#39;</span>
<span class="sd">        add spaces before and after &#39;!&#39;</span>
<span class="sd">        add spaces before and after &#39;?&#39;</span>
<span class="sd">        replace &#39;;&#39; with single space</span>
<span class="sd">        replace &#39;:&#39; with single space</span>
<span class="sd">        replace multiple spaces with single space</span>

<span class="sd">    Returns a list of tokens after splitting on whitespace.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">pattern_re</span><span class="p">,</span> <span class="n">replaced_str</span> <span class="ow">in</span> <span class="n">_patterns_dict</span><span class="p">:</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">pattern_re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">replaced_str</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>



<span class="k">def</span><span class="w"> </span><span class="nf">get_tokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate tokenizer function for a string sentence.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        tokenizer: the name of tokenizer function. If None, it returns split()</span>
<span class="sd">            function, which splits the string sentence by space.</span>
<span class="sd">            If basic_english, it returns _basic_english_normalize() function,</span>
<span class="sd">            which normalize the string first and split by space. If a callable</span>
<span class="sd">            function, it will return the function. If a tokenizer library</span>
<span class="sd">            (e.g. spacy, moses, toktok, revtok, subword), it returns the</span>
<span class="sd">            corresponding library.</span>
<span class="sd">        language: Default en</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torchtext</span>
<span class="sd">        &gt;&gt;&gt; from torchtext.data import get_tokenizer</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = get_tokenizer(&quot;basic_english&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokens = tokenizer(&quot;You can now install TorchText using pip!&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokens</span>
<span class="sd">        &gt;&gt;&gt; [&#39;you&#39;, &#39;can&#39;, &#39;now&#39;, &#39;install&#39;, &#39;torchtext&#39;, &#39;using&#39;, &#39;pip&#39;, &#39;!&#39;]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># default tokenizer is string.split(), added as a module function for serialization</span>


    <span class="k">if</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s2">&quot;basic_english&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">language</span> <span class="o">!=</span> <span class="s1">&#39;en&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Basic normalization is only available for Enlish(en)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_basic_english_normalize</span>

    <span class="c1"># simply return if a function is passed</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tokenizer</span>

    <span class="k">if</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s2">&quot;spacy&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>
            <span class="n">spacy</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">language</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">partial</span><span class="p">(</span><span class="n">_spacy_tokenize</span><span class="p">,</span> <span class="n">spacy</span><span class="o">=</span><span class="n">spacy</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install SpaCy. &quot;</span>
                  <span class="s2">&quot;See the docs at https://spacy.io for more information.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install SpaCy and the SpaCy </span><span class="si">{}</span><span class="s2"> tokenizer. &quot;</span>
                  <span class="s2">&quot;See the docs at https://spacy.io for more &quot;</span>
                  <span class="s2">&quot;information.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">language</span><span class="p">))</span>
            <span class="k">raise</span>
    <span class="k">elif</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s2">&quot;moses&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">sacremoses</span><span class="w"> </span><span class="kn">import</span> <span class="n">MosesTokenizer</span>
            <span class="n">moses_tokenizer</span> <span class="o">=</span> <span class="n">MosesTokenizer</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">moses_tokenizer</span><span class="o">.</span><span class="n">tokenize</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install SacreMoses. &quot;</span>
                  <span class="s2">&quot;See the docs at https://github.com/alvations/sacremoses &quot;</span>
                  <span class="s2">&quot;for more information.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">elif</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s2">&quot;toktok&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize.toktok</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToktokTokenizer</span>
            <span class="n">toktok</span> <span class="o">=</span> <span class="n">ToktokTokenizer</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">toktok</span><span class="o">.</span><span class="n">tokenize</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install NLTK. &quot;</span>
                  <span class="s2">&quot;See the docs at https://nltk.org  for more information.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">elif</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s1">&#39;revtok&#39;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">revtok</span>
            <span class="k">return</span> <span class="n">revtok</span><span class="o">.</span><span class="n">tokenize</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install revtok.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">elif</span> <span class="n">tokenizer</span> <span class="o">==</span> <span class="s1">&#39;subword&#39;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">revtok</span>
            <span class="k">return</span> <span class="n">partial</span><span class="p">(</span><span class="n">revtok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">decap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install revtok.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Requested tokenizer </span><span class="si">{}</span><span class="s2">, valid choices are a &quot;</span>
                     <span class="s2">&quot;callable that takes a single string as input, &quot;</span>
                     <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">revtok</span><span class="se">\&quot;</span><span class="s2"> for the revtok reversible tokenizer, &quot;</span>
                     <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">subword</span><span class="se">\&quot;</span><span class="s2"> for the revtok caps-aware tokenizer, &quot;</span>
                     <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">spacy</span><span class="se">\&quot;</span><span class="s2"> for the SpaCy English tokenizer, or &quot;</span>
                     <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">moses</span><span class="se">\&quot;</span><span class="s2"> for the NLTK port of the Moses tokenization &quot;</span>
                     <span class="s2">&quot;script.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this heading">#</a></h2>
<p>You can find the dataset we are going to use in <a class="reference external" href="https://huggingface.co/datasets/stanfordnlp/sentiment140">this website</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stanfordnlp/sentiment140&quot;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "914605f142944a0aba34dfdc7ec8ff38", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "e2b0f97806144114a8aeb861699c04b0", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "3f9fea9e18c2429aacdc99f9682e4010", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "ec0e3821969e41c497f94dcf638598d5", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "24e78e9a23404b48b90d04fed02fb939", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We load the dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sentiment&#39;</span><span class="p">:</span> <span class="s1">&#39;polarity&#39;</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;polarity&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;query&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">DATASET_SIZE</span><span class="o">=</span><span class="mi">10000</span>

<span class="c1"># Limit the dataset size</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="n">DATASET_SIZE</span><span class="p">]</span>

<span class="c1"># Show the first few rows</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-c639ddb1-216a-4295-95bb-2cc6c87944b2" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>polarity</th>
      <th>user</th>
      <th>date</th>
      <th>query</th>
      <th>user</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>_TheSpecialOne_</td>
      <td>Mon Apr 06 22:19:45 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>_TheSpecialOne_</td>
      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>scotthamilton</td>
      <td>Mon Apr 06 22:19:49 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>scotthamilton</td>
      <td>is upset that he can't update his Facebook by ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>mattycus</td>
      <td>Mon Apr 06 22:19:53 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>mattycus</td>
      <td>@Kenichan I dived many times for the ball. Man...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>ElleCTF</td>
      <td>Mon Apr 06 22:19:57 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>ElleCTF</td>
      <td>my whole body feels itchy and like its on fire</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>Karoli</td>
      <td>Mon Apr 06 22:19:57 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>Karoli</td>
      <td>@nationwideclass no, it's not behaving at all....</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-c639ddb1-216a-4295-95bb-2cc6c87944b2')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-c639ddb1-216a-4295-95bb-2cc6c87944b2 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-c639ddb1-216a-4295-95bb-2cc6c87944b2');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-18b9794d-1e35-4d03-aaff-fc9a84221acb">
      <button class="colab-df-quickchart" onclick="quickchart('df-18b9794d-1e35-4d03-aaff-fc9a84221acb')"
                title="Suggest charts"
                style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-18b9794d-1e35-4d03-aaff-fc9a84221acb button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>
    </div>
  </div>
</div></div>
</div>
<p>For this project we will use only the text and the polarity of the tweet. Notice that polarity is 0 for negative tweets and 4 for positive tweet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Changes values from [0,4] to [0,1]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">polarity</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="c1"># Split the data into train and test</span>
<span class="n">x_train_text</span><span class="p">,</span> <span class="n">x_test_text</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first thing we have to do before working on the models is to familiarize ourselves with the dataset. This is called Exploratory Data Analisys (EDA).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0: equinux.com just crashed safari tks you! 
0: tierd  whats pt swagger mean.. i love the sound of it
0: @EstelleDarlings Honestly, you can only speak to urself because no 1 cares @the airport. Someone will always direct u 2 the next person 
0: Site load rising again. Increased my capacity but it&#39;s going up still 
0: @heidimontag just got done watching the hills! loved it! excited for the next episode! and im sad this is the last season! 
</pre></div>
</div>
</div>
</div>
<p>An interesting thing to analyze is the Word Distribution. In order to count the occurrences of each word, we should tokenize the sentences first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;basic_english&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before Tokenize: &#39;</span><span class="p">,</span> <span class="n">x_train_text</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After Tokenize: &#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before Tokenize:  tierd  whats pt swagger mean.. i love the sound of it
After Tokenize:  [&#39;tierd&#39;, &#39;whats&#39;, &#39;pt&#39;, &#39;swagger&#39;, &#39;mean&#39;, &#39;.&#39;, &#39;.&#39;, &#39;i&#39;, &#39;love&#39;, &#39;the&#39;, &#39;sound&#39;, &#39;of&#39;, &#39;it&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">)]</span>
<span class="n">x_test_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">x_test_text</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a103539f6d7f4b75b721c56cfba9e213", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "bb87bbfa2de04627a03c28519339383d", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>We can count the words occurences and see how many different words are present in our dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">x_train_token</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
    <span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">words</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">sorted_words</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of different Tokens in our Dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of different Tokens in our Dataset: 14815
[&#39;.&#39;, &#39;i&#39;, &quot;&#39;&quot;, &#39;!&#39;, &#39;to&#39;, &#39;the&#39;, &#39;,&#39;, &#39;a&#39;, &#39;my&#39;, &#39;it&#39;, &#39;and&#39;, &#39;is&#39;, &#39;?&#39;, &#39;t&#39;, &#39;in&#39;, &#39;for&#39;, &#39;of&#39;, &#39;you&#39;, &#39;s&#39;, &#39;but&#39;, &#39;me&#39;, &#39;on&#39;, &#39;that&#39;, &#39;have&#39;, &#39;not&#39;, &#39;so&#39;, &#39;m&#39;, &#39;at&#39;, &#39;just&#39;, &#39;this&#39;, &#39;be&#39;, &#39;was&#39;, &#39;work&#39;, &#39;up&#39;, &#39;with&#39;, &#39;now&#39;, &#39;no&#39;, &#39;can&#39;, &#39;get&#39;, &#39;out&#39;, &#39;go&#39;, &#39;all&#39;, &#39;today&#39;, &#39;day&#39;, &#39;too&#39;, &#39;like&#39;, &#39;do&#39;, &#39;don&#39;, &#39;still&#39;, &#39;going&#39;, &#39;-&#39;, &#39;got&#39;, &#39;are&#39;, &#39;back&#39;, &#39;am&#39;, &#39;really&#39;, &#39;time&#39;, &#39;what&#39;, &#39;from&#39;, &#39;about&#39;, &#39;has&#39;, &#39;had&#39;, &#39;one&#39;, &#39;good&#39;, &#39;its&#39;, &#39;they&#39;, &#39;want&#39;, &#39;im&#39;, &#39;sad&#39;, &#39;we&#39;, &#39;why&#39;, &#39;need&#39;, &#39;home&#39;, &#39;http&#39;, &#39;sleep&#39;, &#39;your&#39;, &#39;know&#39;, &#39;night&#39;, &#39;when&#39;, &#39;there&#39;, &#39;some&#39;, &#39;will&#39;, &#39;more&#39;, &#39;oh&#39;, &#39;been&#39;, &#39;lol&#39;, &#39;last&#39;, &#39;feel&#39;, &#39;sick&#39;, &#39;miss&#39;, &#39;2&#39;, &#39;morning&#39;, &#39;much&#39;, &#39;again&#39;, &#39;off&#39;, &#39;sorry&#39;, &#39;as&#39;, &#39;think&#39;, &#39;wish&#39;, &#39;an&#39;]
</pre></div>
</div>
</div>
</div>
<p>Now we can plot their distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count_occurences</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">words</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="n">accumulated</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">while</span> <span class="n">accumulated</span> <span class="o">&lt;</span> <span class="n">count_occurences</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">:</span>
  <span class="n">accumulated</span> <span class="o">+=</span> <span class="n">words</span><span class="p">[</span><span class="n">sorted_words</span><span class="p">[</span><span class="n">counter</span><span class="p">]]</span>
  <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">counter</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="si">}</span><span class="s2">% most common words &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;account for the </span><span class="si">{</span><span class="n">accumulated</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">count_occurences</span><span class="si">}</span><span class="s2">% of the occurrences&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The 5.190685116436044% most common words account for the 80.00869187309866% of the occurrences
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">[:</span><span class="mi">100</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/888270c0b48a6837962c4dfc5ca6f9dace66a405afb902afb9a29d88baab199e.png" src="../../_images/888270c0b48a6837962c4dfc5ca6f9dace66a405afb902afb9a29d88baab199e.png" />
</div>
</div>
<p>It is very common to find this kind of distribution when analyzing corpus of text. This is referred to as the <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">zipf’s law</a>.</p>
<p>Usually the number of words in the dictionary will be very large.</p>
<p>Here are some thing we can do to reduce that number:</p>
<ul class="simple">
<li><p>Remove puntuation.</p></li>
<li><p>Remove stop-words.</p></li>
<li><p>Steaming.</p></li>
<li><p>Remove very uncommon words (the words that appears in fewer than N occations).</p></li>
<li><p>Nothing: we can use a pretrain model that handles this kind of situations.</p></li>
</ul>
<p>We used one of the simplest tokenizers availables. This tokenizer does not take into account many quirks of the language. Moreover, diferent languages have different quirks, so there is no “universal” tokenizers. There are many libraries that have “better” tokenizers:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spacy.io/">Spacy</a>: it can be accessed using: <code class="docutils literal notranslate"><span class="pre">get_tokenizer(&quot;spacy&quot;)</span></code>. Spacy supports a wide range of languages.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/">Huggingface</a>: it has many tokenizers for different laguages. <a class="reference external" href="https://huggingface.co/transformers/main_classes/tokenizer.html">Doc</a></p></li>
<li><p><a class="reference external" href="https://www.nltk.org/">NLTK</a>: it provides several tokenizers. One of them can be accessed using: <code class="docutils literal notranslate"><span class="pre">get_tokenizer(&quot;toktok&quot;)</span></code></p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-4-choose-toolkit">
<h1>Step 4: choose toolkit<a class="headerlink" href="#step-4-choose-toolkit" title="Permalink to this heading">#</a></h1>
<p>Our goal is to train a model capable of estimating the sentiment of a tweet (positive or negative) by reading its content. To that end we will try 2 different approaches:</p>
<ul class="simple">
<li><p>A logistic regression using sklearn. <strong>NOTE</strong>: it can probaly work better than an SVM model.</p></li>
<li><p>A simple Embedding + RNN.</p></li>
</ul>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading">#</a></h2>
<p>We will represent our senteces using binary vectorization. This means that our data would be represented as a matrix of instances by word with a one if the word is in the instance, and zero otherwise. Sklean vectorizers can also do things such as stop-word removal and puntuation removal, you can read more about in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">the documentation</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x_train_cv</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">)</span>
<span class="n">x_test_cv</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before Vectorize: &#39;</span><span class="p">,</span> <span class="n">x_train_text</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before Vectorize:  Site load rising again. Increased my capacity but it&#39;s going up still 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Notice that the matriz is sparse</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After Vectorize: &#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_train_cv</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After Vectorize: 
&lt;Compressed Sparse Row sparse matrix of dtype &#39;int64&#39;
	with 12 stored elements and shape (1, 14159)&gt;
  Coords	Values
  (0, 6377)	1
  (0, 11286)	1
  (0, 7410)	1
  (0, 10478)	1
  (0, 655)	1
  (0, 6190)	1
  (0, 8422)	1
  (0, 2199)	1
  (0, 2086)	1
  (0, 5251)	1
  (0, 13169)	1
  (0, 11819)	1
</pre></div>
</div>
</div>
</div>
<p>Now we can train our model. You can check the documentation of this logistic regressor <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic#sklearn.linear_model.LogisticRegression">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_cv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">/tmp/ipython-input-23-2773398188.py</span> in <span class="ni">&lt;cell line: 0&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_cv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/sklearn/base.py</span> in <span class="ni">wrapper</span><span class="nt">(estimator, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1387</span>                 <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1388</span>             <span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1389</span>                 <span class="k">return</span> <span class="n">fit_method</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1390</span> 
<span class="g g-Whitespace">   </span><span class="mi">1391</span>         <span class="k">return</span> <span class="n">wrapper</span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">   </span><span class="mi">1299</span>         <span class="n">classes_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span>
<span class="g g-Whitespace">   </span><span class="mi">1300</span>         <span class="k">if</span> <span class="n">n_classes</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1301</span>             <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1302</span>                 <span class="s2">&quot;This solver needs samples of at least 2 classes&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1303</span>                 <span class="s2">&quot; in the data, but the data contains only one&quot;</span>

<span class="nn">ValueError: This solver needs samples of at least 2 classes</span> in <span class="ni">the data, but the data contains only one class: np.int64</span><span class="nt">(0)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_cv</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="explainable-ai">
<h2>Explainable AI<a class="headerlink" href="#explainable-ai" title="Permalink to this heading">#</a></h2>
<p>The best thing about logistic regresion is that it is simple, and we can get some explanations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">))</span>

<span class="n">words_sk</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">words_sk</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="nn">/tmp/ipython-input-24-3113506201.py</span> in <span class="ni">&lt;cell line: 0&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">words_sk</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">words_sk</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]])</span>

<span class="ne">AttributeError</span>: &#39;LogisticRegression&#39; object has no attribute &#39;coef_&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words_sk</span><span class="p">[:</span><span class="mi">20</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">words_sk</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
</div>
<p>What does this mean?</p>
<p>Remember the <code class="docutils literal notranslate"><span class="pre">model.coef_</span></code> is the <span class="math notranslate nohighlight">\(W\)</span> in:</p>
<div class="math notranslate nohighlight">
\[h(x)=\sigma(WX + b)\]</div>
<p>where the label 1 is a positive tweet and the label 0 is a negative tweet.</p>
</section>
<section id="recurrent-neural-network-with-pytorch">
<h2>Recurrent Neural Network with Pytorch<a class="headerlink" href="#recurrent-neural-network-with-pytorch" title="Permalink to this heading">#</a></h2>
<p>In the previous section we use a Bag-Of-Words approach to represent each of the tweets. That meas that we only consider how many times each of the words appear in each of the tweets, we didnt take into account the order of the words. But we know that the word order is very important and carries relevant information.</p>
<p>In this section we will solve the same task, but this time we will implement a Recurrent Neural Network (RNN) instead of using a simple Logistic Regression.Unlike feedforward neural networks, RNNs have cyclic connections making them powerful for modeling sequences.</p>
<p>Let’s start by importing the relevant libraries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: For this notebook to perform best, &quot;</span>
          <span class="s2">&quot;if possible, in the menu under `Runtime` -&gt; &quot;</span>
          <span class="s2">&quot;`Change runtime type.`  select `GPU` &quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is enabled in this notebook.&quot;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the device (check if gpu is available)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU is enabled in this notebook.
</pre></div>
</div>
</div>
</div>
<p>First we will create a Dictionary (<code class="docutils literal notranslate"><span class="pre">word_to_idx</span></code>). This dictionary will map each Token (usually words) to an index (an integer number). We want to limit our dictionary to a certain number of tokens (<code class="docutils literal notranslate"><span class="pre">num_words_dict</span></code>), so we will include in our ditionary those with more occurrences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From previous section, we have a list with the most used tokens</span>
<span class="n">sorted_words</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;.&#39;, &#39;i&#39;, &quot;&#39;&quot;, &#39;!&#39;, &#39;to&#39;, &#39;the&#39;, &#39;,&#39;, &#39;a&#39;, &#39;my&#39;, &#39;it&#39;]
</pre></div>
</div>
</div>
</div>
<p>Let’s select only the most used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_words_dict</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="c1"># We reserve two numbers for special tokens.</span>
<span class="n">most_used_words</span> <span class="o">=</span> <span class="n">sorted_words</span><span class="p">[:</span><span class="n">num_words_dict</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We will add two extra Tokens to the dictionary, one for words outside the dictionary (<code class="docutils literal notranslate"><span class="pre">'UNK'</span></code>) and one for padding the sequences (<code class="docutils literal notranslate"><span class="pre">'PAD'</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dictionary to go from words to idx</span>
<span class="n">word_to_idx</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1"># dictionary to go from idx to words (just in case)</span>
<span class="n">idx_to_word</span> <span class="o">=</span> <span class="p">{}</span>


<span class="c1"># We include the special tokens first</span>
<span class="n">PAD_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">UNK_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;PAD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PAD_token</span>
<span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">UNK_token</span>

<span class="n">idx_to_word</span><span class="p">[</span><span class="n">PAD_token</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;PAD&#39;</span>
<span class="n">idx_to_word</span><span class="p">[</span><span class="n">UNK_token</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;UNK&#39;</span>

<span class="c1"># We popullate our dictionaries with the most used words</span>
<span class="k">for</span> <span class="n">num</span><span class="p">,</span><span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">most_used_words</span><span class="p">):</span>
  <span class="n">word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">num</span> <span class="o">+</span> <span class="mi">2</span>
  <span class="n">idx_to_word</span><span class="p">[</span><span class="n">num</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</pre></div>
</div>
</div>
</div>
<p>Our goal now is to transform each tweet from a sequence of tokens to a sequence of indexes. These sequences of indexes will be the input to our pytorch model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A function to convert list of tokens to list of indexes</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokens_to_idx</span><span class="p">(</span><span class="n">sentences_tokens</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">):</span>
  <span class="n">sentences_idx</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences_tokens</span><span class="p">:</span>
    <span class="n">sent_idx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_to_idx</span><span class="p">:</span>
        <span class="n">sent_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">sent_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">])</span>
    <span class="n">sentences_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sent_idx</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">sentences_idx</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train_idx</span> <span class="o">=</span> <span class="n">tokens_to_idx</span><span class="p">(</span><span class="n">x_train_token</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">)</span>
<span class="n">x_test_idx</span> <span class="o">=</span> <span class="n">tokens_to_idx</span><span class="p">(</span><span class="n">x_test_token</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">some_number</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before converting: &#39;</span><span class="p">,</span> <span class="n">x_train_token</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After converting: &#39;</span><span class="p">,</span> <span class="n">x_train_idx</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before converting:  [&#39;tierd&#39;, &#39;whats&#39;, &#39;pt&#39;, &#39;swagger&#39;, &#39;mean&#39;, &#39;.&#39;, &#39;.&#39;, &#39;i&#39;, &#39;love&#39;, &#39;the&#39;, &#39;sound&#39;, &#39;of&#39;, &#39;it&#39;]
After converting:  [4880, 801, 2396, 4881, 391, 2, 2, 3, 120, 7, 631, 18, 11]
</pre></div>
</div>
</div>
</div>
<p>We need all the sequences to have the same length. To select an adequate sequence length, let’s explore some statistics about the length of the tweets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweet_lens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">x_train_idx</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Max tweet word length: &#39;</span><span class="p">,</span><span class="n">tweet_lens</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean tweet word length: &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">tweet_lens</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;99% percent under: &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">tweet_lens</span><span class="p">,</span><span class="mf">0.99</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Max tweet word length:  62
Mean tweet word length:  16.0
99% percent under:  37.0
</pre></div>
</div>
</div>
</div>
<p>We cut the sequences which are larger than our chosen maximum length (<code class="docutils literal notranslate"><span class="pre">max_lenght</span></code>) and fill with zeros the ones that are shorter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> <span class="c1"># We choose the max length</span>
 <span class="n">max_length</span> <span class="o">=</span> <span class="mi">40</span>

<span class="c1"># A function to make all the sequence have the same lenght</span>
<span class="c1"># Note that the output is a Numpy matrix</span>
 <span class="k">def</span><span class="w"> </span><span class="nf">padding</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">):</span>
  <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">seq_len</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="n">len_tweet</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">&lt;=</span> <span class="n">seq_len</span><span class="p">:</span>
        <span class="c1"># If its shorter, we fill with zeros (the padding Token index)</span>
        <span class="n">features</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">tweet</span><span class="p">):]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tweet</span><span class="p">)[:</span><span class="n">seq_len</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">&gt;</span> <span class="n">seq_len</span><span class="p">:</span>
        <span class="c1"># If its larger, we take the last &#39;seq_len&#39; indexes</span>
        <span class="n">features</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tweet</span><span class="p">)[</span><span class="o">-</span><span class="n">seq_len</span><span class="p">:]</span>
  <span class="k">return</span> <span class="n">features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We convert our list of tokens into a numpy matrix</span>
<span class="c1"># where all instances have the same lenght</span>
<span class="n">x_train_pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">(</span><span class="n">x_train_idx</span><span class="p">,</span><span class="n">max_length</span><span class="p">)</span>
<span class="n">x_test_pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">(</span><span class="n">x_test_idx</span><span class="p">,</span><span class="n">max_length</span><span class="p">)</span>

<span class="c1"># We convert our target list a numpy matrix</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">some_number</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before padding: &#39;</span><span class="p">,</span> <span class="n">x_train_idx</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After padding: &#39;</span><span class="p">,</span> <span class="n">x_train_pad</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before padding:  [4882, 1701, 8, 19, 39, 103, 765, 6, 3175, 196, 38, 249, 4883, 4884, 976, 2, 234, 83, 235, 1980, 123, 92, 7, 236, 911]
After padding:  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0 4882 1701    8   19   39  103  765    6 3175  196   38  249 4883
 4884  976    2  234   83  235 1980  123   92    7  236  911]
</pre></div>
</div>
</div>
</div>
<p>Now, let’s convert the data to pytorch format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create Tensor datasets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train_pad</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_np</span><span class="p">))</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test_pad</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test_np</span><span class="p">))</span>

<span class="c1"># Batch size (this is an important hyperparameter)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># dataloaders</span>
<span class="c1"># make sure to SHUFFLE your data</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Each batch of data in our traning proccess will have the folllowing format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain one batch of training data</span>
<span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">sample_x</span><span class="p">,</span> <span class="n">sample_y</span> <span class="o">=</span> <span class="n">dataiter</span><span class="o">.</span><span class="fm">__next__</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input size: &#39;</span><span class="p">,</span> <span class="n">sample_x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="c1"># batch_size, seq_length</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sample_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sample_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample input size:  torch.Size([100, 40])
Sample input: 
 tensor([[    0,     0,     0,  ...,   303,   856, 14628],
        [    0,     0,     0,  ...,  3102,    33,   111],
        [    0,     0,     0,  ..., 10228,    22,    46],
        ...,
        [    0,     0,     0,  ...,     6,    42,   128],
        [    0,     0,     0,  ...,   350,  1305,  4700],
        [    0,     0,     0,  ...,  7050,  7051,  7052]])
Sample input: 
 tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p>Now, we will define the <code class="docutils literal notranslate"><span class="pre">SentimentRNN</span></code> class. Most of the model’s class will be familiar to you, but there are two important layers we would like you to pay attention to:</p>
<ul class="simple">
<li><p>Embedding Layer</p></li>
</ul>
<blockquote>
<div><p>This layer is like a linear layer, but it makes it posible to use a sequence of inedexes as inputs (instead of a sequence of one-hot-encoded vectors). During training, the Embedding layer learns a linear transformation from the space of words (a vector space of dimension <code class="docutils literal notranslate"><span class="pre">num_words_dict</span></code>) into the a new, smaller, vector space of dimension <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code>. We suggest you to read this <a class="reference external" href="https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518/3">thread</a> and the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">pytorch documentation</a> if you want to learn more about this particular kind of layers.</p>
</div></blockquote>
<ul class="simple">
<li><p>LSTM layer</p></li>
</ul>
<blockquote>
<div><p>This is one of the most used class of Recurrent Neural Networks. In Pytorch we can add several stacked layers in just one line of code. In our case, the number of layers added are decided with the parameter <code class="docutils literal notranslate"><span class="pre">no_layers</span></code>. If you want to learn more about LSTMs we strongly recommend you this <a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Colahs thread</a> about them.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SentimentRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">no_layers</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SentimentRNN</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span> <span class="o">=</span> <span class="n">no_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">=</span> <span class="n">drop_prob</span>

    <span class="c1"># Embedding Layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="c1"># LSTM Layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
                        <span class="n">num_layers</span><span class="o">=</span><span class="n">no_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span><span class="p">)</span>

    <span class="c1"># Dropout layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">drop_prob</span><span class="p">)</span>

    <span class="c1"># Linear and Sigmoid layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sig</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">hidden</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Embedding out</span>
    <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">#Shape: [batch_size x max_length x embedding_dim]</span>

    <span class="c1"># LSTM out</span>
    <span class="n">lstm_out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embeds</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="c1"># Shape: [batch_size x max_length x hidden_dim]</span>

    <span class="c1"># Select the activation of the last Hidden Layer</span>
    <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="c1"># Shape: [batch_size x hidden_dim]</span>

    <span class="c1">## You can instead average the activations across all the times</span>
    <span class="c1"># lstm_out = torch.mean(lstm_out, 1).contiguous()</span>

    <span class="c1"># Dropout and Fully connected layer</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># Sigmoid function</span>
    <span class="n">sig_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sig</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># return last sigmoid output and hidden state</span>
    <span class="k">return</span> <span class="n">sig_out</span><span class="p">,</span> <span class="n">hidden</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39; Initializes hidden state &#39;&#39;&#39;</span>
    <span class="c1"># Create two new tensors with sizes n_layers x batch_size x hidden_dim,</span>
    <span class="c1"># initialized to zero, for hidden state and cell state of LSTM</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span><span class="n">c0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
<p>We choose the parameters of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parameters of our network</span>

<span class="c1"># Size of our vocabulary</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="n">num_words_dict</span>

<span class="c1"># Embedding dimension</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Number of stacked LSTM layers</span>
<span class="n">no_layers</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Dimension of the hidden layer in LSTMs</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># Dropout parameter for regularization</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Dropout parameter for regularization</span>
<span class="n">drop_prob</span> <span class="o">=</span> <span class="mf">0.25</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s define our model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentimentRNN</span><span class="p">(</span><span class="n">no_layers</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
                     <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>
<span class="c1"># Moving to gpu</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SentimentRNN(
  (embedding): Embedding(30000, 32)
  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, dropout=0.25)
  (dropout): Dropout(p=0.25, inplace=False)
  (fc): Linear(in_features=64, out_features=1, bias=True)
  (sig): Sigmoid()
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># How many trainable parameters does our model have?</span>
<span class="n">model_parameters</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model_parameters</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Number of parameters: &#39;</span><span class="p">,</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Number of parameters:  1018433
</pre></div>
</div>
</div>
</div>
<p>We choose the losses and the optimizer for the training procces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss and optimization functions</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Binary crossentropy is a good loss function for a binary classification problem</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="c1"># We choose an Adam optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># function to predict accuracy</span>
<span class="k">def</span><span class="w"> </span><span class="nf">acc</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We are ready to train our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of training Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Maximum absolute value accepted for the gradeint</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Initial Loss value (assumed big)</span>
<span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

<span class="c1"># Lists to follow the evolution of the loss and accuracy</span>
<span class="n">epoch_tr_loss</span><span class="p">,</span><span class="n">epoch_vl_loss</span> <span class="o">=</span> <span class="p">[],[]</span>
<span class="n">epoch_tr_acc</span><span class="p">,</span><span class="n">epoch_vl_acc</span> <span class="o">=</span> <span class="p">[],[]</span>

<span class="c1"># Train for a number of Epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">train_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>

    <span class="c1"># Initialize hidden state</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="c1"># Creating new variables for the hidden state</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">each</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">h</span><span class="p">])</span>

    <span class="c1"># Move batch inputs and labels to gpu</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Set gradient to zero</span>
    <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Compute model output</span>
    <span class="n">output</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>

    <span class="c1"># Calculate the loss and perform backprop</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># calculating accuracy</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">acc</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">train_acc</span> <span class="o">+=</span> <span class="n">accuracy</span>

    <span class="c1">#`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


  <span class="c1"># Evaluate on the validation set for this epoch</span>
  <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">val_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>

    <span class="c1"># Initialize hidden state</span>
    <span class="n">val_h</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">val_h</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">each</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">val_h</span><span class="p">])</span>

    <span class="c1"># Move batch inputs and labels to gpu</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Compute model output</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">val_h</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">val_h</span><span class="p">)</span>

    <span class="c1"># Compute Loss</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

    <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">acc</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">+=</span> <span class="n">accuracy</span>

  <span class="n">epoch_train_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span>
  <span class="n">epoch_val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span>
  <span class="n">epoch_train_acc</span> <span class="o">=</span> <span class="n">train_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">epoch_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">epoch_tr_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_train_loss</span><span class="p">)</span>
  <span class="n">epoch_vl_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_val_loss</span><span class="p">)</span>
  <span class="n">epoch_tr_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_train_acc</span><span class="p">)</span>
  <span class="n">epoch_vl_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_val_acc</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_loss : </span><span class="si">{</span><span class="n">epoch_train_loss</span><span class="si">}</span><span class="s1"> val_loss : </span><span class="si">{</span><span class="n">epoch_val_loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_accuracy : </span><span class="si">{</span><span class="n">epoch_train_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1"> val_accuracy : </span><span class="si">{</span><span class="n">epoch_val_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">epoch_val_loss</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_loss_min</span><span class="p">,</span><span class="n">epoch_val_loss</span><span class="p">))</span>
    <span class="c1"># torch.save(model.state_dict(), &#39;../working/state_dict.pt&#39;)</span>
    <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">epoch_val_loss</span>
  <span class="nb">print</span><span class="p">(</span><span class="mi">25</span><span class="o">*</span><span class="s1">&#39;==&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1
train_loss : 0.12438914714439306 val_loss : 0.0018169824266806244
train_accuracy : 99.9625 val_accuracy : 100.0
Validation loss decreased (inf --&gt; 0.001817).  Saving model ...
==================================================
Epoch 2
train_loss : 0.0015338497134507634 val_loss : 0.0009810010727960617
train_accuracy : 100.0 val_accuracy : 100.0
Validation loss decreased (0.001817 --&gt; 0.000981).  Saving model ...
==================================================
Epoch 3
train_loss : 0.0009141735477896873 val_loss : 0.0006214575550984591
train_accuracy : 100.0 val_accuracy : 100.0
Validation loss decreased (0.000981 --&gt; 0.000621).  Saving model ...
==================================================
Epoch 4
train_loss : 0.0006109651429142104 val_loss : 0.000429066653305199
train_accuracy : 100.0 val_accuracy : 100.0
Validation loss decreased (0.000621 --&gt; 0.000429).  Saving model ...
==================================================
Epoch 5
train_loss : 0.00044310156408755574 val_loss : 0.00031149635469773784
train_accuracy : 100.0 val_accuracy : 100.0
Validation loss decreased (0.000429 --&gt; 0.000311).  Saving model ...
==================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_tr_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_vl_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_tr_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_vl_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/414f3417cb2a5916a701f58942064d535d9f28c19cfa90f7612a374909b11dee.png" src="../../_images/414f3417cb2a5916a701f58942064d535d9f28c19cfa90f7612a374909b11dee.png" />
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="what-s-next">
<h1>What’s Next?<a class="headerlink" href="#what-s-next" title="Permalink to this heading">#</a></h1>
<p>You can use this project template as a starting point to think about your own project. There are a lot of ways to continue, here we share with you some ideas you migth find useful:</p>
<ul class="simple">
<li><p><strong>Work on the Preproccesing.</strong> We used a very rudimentary way to tokenize tweets. But there are better ways to preprocess the data. Can you think of a suitable way to preprocess the data for this particular task? How does the performance of the model change when the data is processed correctly?</p></li>
<li><p><strong>Work on the Model.</strong> The RNN model proposed in this notebook is not optimized at all. You can work on finding a better architecture or better hyperparamenters. May be using bidirectonal LSTMs or increasing the number of stacked layers can improve the performance, feel free to try different approaches.</p></li>
<li><p><strong>Work on the Embedding.</strong> Our model learnt an embedding during the training on this Twitter corpus for a particular task. You can explore the representation of different words in this learned embedding. Also, you can try using different word embeddings. You can train them on this corpus or you can use an embedding trained on another corpus of data. How does the change of the embedding affect the model performance?</p></li>
<li><p><strong>Try sentiment analysis on another dataset.</strong> There are lots of available dataset to work with, we can help you find one that is interesting to you. Do you belive that a sentiment analysis model trained on some corpus (Twitter dataset) will perform well on another type of data (for example, youtube comments)?</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./projects/NaturalLanguageProcessing"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="ideas_and_datasets.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Ideas</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="machine_translation.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Machine Translation</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Twitter Sentiment Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome-to-the-nlp-project-template">
   Welcome to the NLP project template
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-questions-and-goals">
   Step 1: Questions and goals
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-literature-review">
   Step 2: Literature review
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-load-and-explore-the-dataset">
   Step 3: Load and explore the dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     Dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-choose-toolkit">
   Step 4: choose toolkit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explainable-ai">
     Explainable AI
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrent-neural-network-with-pytorch">
     Recurrent Neural Network with Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-s-next">
   What’s Next?
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Neuromatch
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>

</div>
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>