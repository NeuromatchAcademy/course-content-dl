
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Twitter Sentiment Analysis &#8212; Neuromatch Academy: Deep Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'projects/NaturalLanguageProcessing/sentiment_analysis';</script>
    <link rel="shortcut icon" href="../../_static/nma-dl-logo-square-4xp.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Machine Translation" href="machine_translation.html" />
    <link rel="prev" title="Ideas" href="ideas_and_datasets.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D5_Optimization/chapter_title.html">
                        Optimization (W1D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Schedule/schedule_intro.html">
                        Schedule
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../prereqs/DeepLearning.html">
                        Prerequisites and preparatory materials for NMA Deep Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
                        Basics And Pytorch (W1D1)
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
                        Linear Deep Learning (W1D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
                        Multi Layer Perceptrons (W1D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W1D5_Optimization/chapter_title.html">
                        Optimization (W1D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">
                        Regularization (W2D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/FineTuning.html">
                        Deep Learning: The Basics and Fine Tuning Wrap-up
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">
                        Convnets And Dl Thinking (W2D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">
                        Modern Convnets (W2D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">
                        Generative Models (W2D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">
                        Attention And Transformers (W2D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
                        Time Series And Natural Language Processing (W3D1)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">
                        Dl Thinking2 (W3D2)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">
                        Deep Learning: Convnets and NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
                        Unsupervised And Self Supervised Learning (W3D3)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">
                        Basic Reinforcement Learning (W3D4)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
                        Reinforcement Learning For Games And Dl Thinking3 (W3D5)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">
                        Deploy Models (Bonus)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../README.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/project_guidance.html">
                        Daily guide for projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../docs/projects_overview.html">
                        Project Templates
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../docs/datasets_and_models.html">
                        Models and Data sets
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../tutorials/intro.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/nma-dl-logo-square-4xp.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorials/intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/TechnicalHelp/Discord.html">Using Discord</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../prereqs/DeepLearning.html">Prerequisites and preparatory materials for NMA Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics Module</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">Basics And Pytorch (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">Tutorial 1: PyTorch</a></li>









</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">Linear Deep Learning (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">Tutorial 1: Gradient Descent and AutoGrad</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">Tutorial 2: Learning Hyperparameters</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">Tutorial 3: Deep linear neural networks</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">Bonus Lecture: Yoshua Bengio</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">Multi Layer Perceptrons (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">Tutorial 1: Biological vs. Artificial Neural Networks</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">Tutorial 2: Deep MLPs</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Fine Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W1D5_Optimization/chapter_title.html">Optimization (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W1D5_Optimization/student/W1D5_Tutorial1.html">Tutorial 1: Optimization techniques</a></li>













</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D1_Regularization/chapter_title.html">Regularization (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial1.html">Tutorial 1: Regularization techniques part 1</a></li>









<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D1_Regularization/student/W2D1_Tutorial2.html">Tutorial 2: Regularization techniques part 2</a></li>










</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/FineTuning.html">Deep Learning: The Basics and Fine Tuning Wrap-up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ConvNets and Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/chapter_title.html">Convnets And Dl Thinking (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">Tutorial 1: Introduction to CNNs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">Tutorial 2: Deep Learning Thinking 1: Cost Functions</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">Bonus Lecture: Kyunghyun Cho</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/chapter_title.html">Modern Convnets (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial1.html">Tutorial 1: Learn how to use modern convnets</a></li>












<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D3_ModernConvnets/student/W2D3_Tutorial2.html">Bonus Tutorial: Facial recognition using modern convnets</a></li>






</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/chapter_title.html">Generative Models (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.html">Tutorial 1: Variational Autoencoders (VAEs)</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial2.html">Tutorial 2: Diffusion models</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial3.html">Tutorial 3: Image, Conditional Diffusion and Beyond</a></li>








<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D4_GenerativeModels/student/W2D4_BonusLecture.html">Bonus Lecture: Geoffrey Hinton</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/chapter_title.html">Attention And Transformers (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial1.html">Tutorial 1: Learn how to work with Transformers</a></li>













<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial2.html">Bonus Tutorial: Understanding Pre-training, Fine-tuning and Robustness of Transformers</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">Time Series And Natural Language Processing (W3D1)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial1.html">Tutorial 1: Introduction to processing time series</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial2.html">Tutorial 2: Natural Language Processing and LLMs</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial3.html">Bonus Tutorial: Multilingual Embeddings</a></li>



</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/chapter_title.html">Dl Thinking2 (W3D2)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D2_DlThinking2/student/W3D2_Tutorial1.html">Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking</a></li>








</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/Module_WrapUps/NaturalLanguageProcessing.html">Deep Learning: Convnets and NLP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unsupervised and Reinforcement Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">Unsupervised And Self Supervised Learning (W3D3)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">Tutorial 1: Un/Self-supervised learning methods</a></li>















<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">Bonus Lecture: Melanie Mitchell</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/chapter_title.html">Basic Reinforcement Learning (W3D4)</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">Tutorial 1: Basic Reinforcement Learning</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">Bonus Lecture: Chealsea Finn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">Reinforcement Learning For Games And Dl Thinking3 (W3D5)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial1.html">Tutorial 1: Reinforcement Learning For Games</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial2.html">Tutorial 2: Deep Learning Thinking 3</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial3.html">Bonus Tutorial: Planning with Monte Carlo Tree Search</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../tutorials/W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_BonusLecture.html">Bonus Lecture: Amita Kapoor</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deploy Models on the Web</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/chapter_title.html">Deploy Models (Bonus)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/Bonus_DeployModels/student/Bonus_Tutorial1.html">Bonus Tutorial: Deploying Neural Networks on the Web</a></li>








</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to projects</a></li>





<li class="toctree-l1"><a class="reference internal" href="../docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modelingsteps/intro.html">Modeling Step-by-Step Guide</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_1through2_DL.html">Modeling Steps 1 - 2</a></li>




<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_3through4_DL.html">Modeling Steps 3 - 4</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_5through6_DL.html">Modeling Steps 5 - 6</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_7through9_DL.html">Modeling Steps 7 - 9</a></li>



<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/ModelingSteps_10_DL.html">Modeling Steps 10</a></li>


<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionDataProjectDL.html">Example Data Project: the Train Illusion</a></li>













<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/TrainIllusionModelingProjectDL.html">Example Model Project: the Train Illusion</a></li>












<li class="toctree-l2"><a class="reference internal" href="../modelingsteps/Example_Deep_Learning_Project.html">Example Deep Learning Project</a></li>












</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../docs/projects_overview.html">Project Templates</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../ComputerVision/README.html">Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/em_synapses.html">Knowledge Extraction from a Convolutional Neural Network</a></li>





<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/spectrogram_analysis.html">Music classification and generation with spectrograms</a></li>

<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/screws.html">Something Screwy - image recognition, detection, and classification of screws</a></li>







<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/data_augmentation.html">Data Augmentation in image classification models</a></li>






<li class="toctree-l3"><a class="reference internal" href="../ComputerVision/transfer_learning.html">Transfer Learning</a></li>



</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../ReinforcementLearning/README.html">Reinforcement Learning</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/ideas_and_datasets.html">Ideas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/robolympics.html">NMA Robolympics: Controlling robots using reinforcement learning</a></li>
















<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/lunar_lander.html">Performance Analysis of DQN Algorithm on the Lunar Lander task</a></li>






<li class="toctree-l3"><a class="reference internal" href="../ReinforcementLearning/human_rl.html">Using RL to Model Cognitive Tasks</a></li>




</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="README.html">Natural Language Processing</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3 current active"><a class="current reference internal" href="#">Twitter Sentiment Analysis</a></li>






<li class="toctree-l3"><a class="reference internal" href="machine_translation.html">Machine Translation</a></li>








</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Neuroscience/README.html">Neuroscience</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/slides.html">Slides</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/ideas_and_datasets.html">Ideas</a></li>

<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/pose_estimation.html">Animal Pose Estimation</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/cellular_segmentation.html">Segmentation and Denoising</a></li>





<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/algonauts_videos.html">Load algonauts videos</a></li>



<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/blurry_vision.html">Vision with Lost Glasses: Modelling how the brain deals with noisy input</a></li>






<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/finetuning_fmri.html">Moving beyond Labels: Finetuning CNNs on BOLD response</a></li>




<li class="toctree-l3"><a class="reference internal" href="../Neuroscience/neuro_seq_to_seq.html">Focus on what matters: inferring low-dimensional dynamics from neural recordings</a></li>








</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../docs/datasets_and_models.html">Models and Data sets</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Fprojects/NaturalLanguageProcessing/sentiment_analysis.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../_sources/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Twitter Sentiment Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Twitter Sentiment Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome-to-the-nlp-project-template">
   Welcome to the NLP project template
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-questions-and-goals">
   Step 1: Questions and goals
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-literature-review">
   Step 2: Literature review
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-load-and-explore-the-dataset">
   Step 3: Load and explore the dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-choose-toolkit">
   Step 4: choose toolkit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explainable-ai">
     Explainable AI
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrent-neural-network-with-pytorch">
     Recurrent Neural Network with Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-s-next">
   Whats Next?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>  <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="twitter-sentiment-analysis">
<h1>Twitter Sentiment Analysis<a class="headerlink" href="#twitter-sentiment-analysis" title="Permalink to this heading">#</a></h1>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong>  Juan Manuel Rodriguez, Salomey Osei, Gonzalo Uribarri</p>
<p><strong>Production editors:</strong> Amita Kapoor, Spiros Chavlis</p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="welcome-to-the-nlp-project-template">
<h1>Welcome to the NLP project template<a class="headerlink" href="#welcome-to-the-nlp-project-template" title="Permalink to this heading">#</a></h1>
<img alt="https://imgs.xkcd.com/comics/machine_learning.png" src="https://imgs.xkcd.com/comics/machine_learning.png" />
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-1-questions-and-goals">
<h1>Step 1: Questions and goals<a class="headerlink" href="#step-1-questions-and-goals" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Can we infer emotion from a tweet text?</p></li>
<li><p>How words are distributed accross the dataset?</p></li>
<li><p>Are words related to one kind of emotion?</p></li>
</ul>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-2-literature-review">
<h1>Step 2: Literature review<a class="headerlink" href="#step-2-literature-review" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf">Original Dataset Paper</a></p>
<p><a class="reference external" href="https://paperswithcode.com/dataset/imdb-movie-reviews">Papers with code</a></p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-3-load-and-explore-the-dataset">
<h1>Step 3: Load and explore the dataset<a class="headerlink" href="#step-3-load-and-explore-the-dataset" title="Permalink to this heading">#</a></h1>
<section id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas<span class="w"> </span>--quiet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>torchtext<span class="w"> </span>--quiet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>datasets<span class="w"> </span>--quiet
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">torchvision 0.14.0 requires torch==1.13.0, but you have torch 2.3.1 which is incompatible.</span>
<span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">torchvision 0.14.0 requires torch==1.13.0, but you have torch 2.3.1 which is incompatible.</span>

</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We import some libraries to load the dataset</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">torchtext</span>
<span class="kn">from</span> <span class="nn">torchtext.data</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>

<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>You can find the dataset we are going to use in <a class="reference external" href="https://huggingface.co/datasets/stanfordnlp/sentiment140">this website</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stanfordnlp/sentiment140&quot;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cd6b527daf25440a8acc7a7645af679d", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "5b7c93b4ee524a01adec2669170ee097", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "19e6cbe3cb7648b4b5e0b2ce60c12d6b", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "e5bfc518fd6a48deb991309cec03facd", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "983915e475a747bd920d53cd924eb7ca", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We load the dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sentiment&#39;</span><span class="p">:</span> <span class="s1">&#39;polarity&#39;</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;polarity&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;query&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">]]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>polarity</th>
      <th>user</th>
      <th>date</th>
      <th>query</th>
      <th>user</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>_TheSpecialOne_</td>
      <td>Mon Apr 06 22:19:45 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>_TheSpecialOne_</td>
      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>scotthamilton</td>
      <td>Mon Apr 06 22:19:49 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>scotthamilton</td>
      <td>is upset that he can't update his Facebook by ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>mattycus</td>
      <td>Mon Apr 06 22:19:53 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>mattycus</td>
      <td>@Kenichan I dived many times for the ball. Man...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>ElleCTF</td>
      <td>Mon Apr 06 22:19:57 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>ElleCTF</td>
      <td>my whole body feels itchy and like its on fire</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>Karoli</td>
      <td>Mon Apr 06 22:19:57 PDT 2009</td>
      <td>NO_QUERY</td>
      <td>Karoli</td>
      <td>@nationwideclass no, it's not behaving at all....</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>For this project we will use only the text and the polarity of the tweet. Notice that polarity is 0 for negative tweets and 4 for positive tweet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Changes values from [0,4] to [0,1]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">polarity</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="c1"># Split the data into train and test</span>
<span class="n">x_train_text</span><span class="p">,</span> <span class="n">x_test_text</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first thing we have to do before working on the models is to familiarize ourselves with the dataset. This is called Exploratory Data Analisys (EDA).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1: @paisleypaisley LOL why do i get ideas so far in advance? it&#39;s not even june yet! we need a third knitter to have our own summer group 
0: worst headache ever 
0: @ewaniesciuszko  i am so sad i wont see you! I miss you already. and yeah! that&#39;s perfect; i come back the 18th!
1: doesn&#39;t know how to spell conked 
0: &amp;quot;So we stand here now and no one knows us at all I won&#39;t get used to this I won&#39;t get used to being gone&amp;quot;...I miss home and everyone  -a
</pre></div>
</div>
</div>
</div>
<p>An interesting thing to analyze is the Word Distribution. In order to count the occurrences of each word, we should tokenize the sentences first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;basic_english&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before Tokenize: &#39;</span><span class="p">,</span> <span class="n">x_train_text</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After Tokenize: &#39;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before Tokenize:  worst headache ever 
After Tokenize:  [&#39;worst&#39;, &#39;headache&#39;, &#39;ever&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">)]</span>
<span class="n">x_test_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">x_test_text</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cd7802db570b408eb5f29af92ca95be1", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "dcc80b45cf1c40769f49d27d96bbeaed", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>We can count the words occurences and see how many different words are present in our dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">x_train_token</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
    <span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">words</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">sorted_words</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of different Tokens in our Dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of different Tokens in our Dataset: 669284
[&#39;.&#39;, &#39;i&#39;, &#39;!&#39;, &quot;&#39;&quot;, &#39;to&#39;, &#39;the&#39;, &#39;,&#39;, &#39;a&#39;, &#39;my&#39;, &#39;it&#39;, &#39;and&#39;, &#39;you&#39;, &#39;?&#39;, &#39;is&#39;, &#39;for&#39;, &#39;in&#39;, &#39;s&#39;, &#39;of&#39;, &#39;t&#39;, &#39;on&#39;, &#39;that&#39;, &#39;me&#39;, &#39;so&#39;, &#39;have&#39;, &#39;m&#39;, &#39;but&#39;, &#39;just&#39;, &#39;with&#39;, &#39;be&#39;, &#39;at&#39;, &#39;not&#39;, &#39;was&#39;, &#39;this&#39;, &#39;now&#39;, &#39;can&#39;, &#39;good&#39;, &#39;up&#39;, &#39;day&#39;, &#39;all&#39;, &#39;get&#39;, &#39;out&#39;, &#39;like&#39;, &#39;are&#39;, &#39;no&#39;, &#39;go&#39;, &#39;http&#39;, &#39;-&#39;, &#39;today&#39;, &#39;do&#39;, &#39;too&#39;, &#39;your&#39;, &#39;work&#39;, &#39;going&#39;, &#39;love&#39;, &#39;we&#39;, &#39;got&#39;, &#39;what&#39;, &#39;lol&#39;, &#39;time&#39;, &#39;back&#39;, &#39;from&#39;, &#39;u&#39;, &#39;one&#39;, &#39;will&#39;, &#39;know&#39;, &#39;about&#39;, &#39;im&#39;, &#39;really&#39;, &#39;don&#39;, &#39;am&#39;, &#39;had&#39;, &#39;)&#39;, &#39;see&#39;, &#39;some&#39;, &#39;there&#39;, &#39;its&#39;, &#39;&amp;amp&#39;, &#39;how&#39;, &#39;if&#39;, &#39;still&#39;, &#39;they&#39;, &#39;&amp;quot&#39;, &#39;night&#39;, &#39;(&#39;, &#39;well&#39;, &#39;want&#39;, &#39;new&#39;, &#39;think&#39;, &#39;2&#39;, &#39;home&#39;, &#39;thanks&#39;, &#39;ll&#39;, &#39;oh&#39;, &#39;when&#39;, &#39;as&#39;, &#39;he&#39;, &#39;more&#39;, &#39;here&#39;, &#39;much&#39;, &#39;off&#39;]
</pre></div>
</div>
</div>
</div>
<p>Now we can plot their distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count_occurences</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">words</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="n">accumulated</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">while</span> <span class="n">accumulated</span> <span class="o">&lt;</span> <span class="n">count_occurences</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">:</span>
  <span class="n">accumulated</span> <span class="o">+=</span> <span class="n">words</span><span class="p">[</span><span class="n">sorted_words</span><span class="p">[</span><span class="n">counter</span><span class="p">]]</span>
  <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">counter</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="si">}</span><span class="s2">% most common words &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;account for the </span><span class="si">{</span><span class="n">accumulated</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">count_occurences</span><span class="si">}</span><span class="s2">% of the occurrences&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The 0.13970153178620734% most common words account for the 80.00532743602652% of the occurrences
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">[:</span><span class="mi">100</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/903ea4eafdfec9b01b1591c6b030e0967e82a9bc09fc4a838bfdc03f96c517d9.png" src="../../_images/903ea4eafdfec9b01b1591c6b030e0967e82a9bc09fc4a838bfdc03f96c517d9.png" />
</div>
</div>
<p>It is very common to find this kind of distribution when analyzing corpus of text. This is referred to as the <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">zipfs law</a>.</p>
<p>Usually the number of words in the dictionary will be very large.</p>
<p>Here are some thing we can do to reduce that number:</p>
<ul class="simple">
<li><p>Remove puntuation.</p></li>
<li><p>Remove stop-words.</p></li>
<li><p>Steaming.</p></li>
<li><p>Remove very uncommon words (the words that appears in fewer than N occations).</p></li>
<li><p>Nothing: we can use a pretrain model that handles this kind of situations.</p></li>
</ul>
<p>We used one of the simplest tokenizers availables. This tokenizer does not take into account many quirks of the language. Moreover, diferent languages have different quirks, so there is no universal tokenizers. There are many libraries that have better tokenizers:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spacy.io/">Spacy</a>: it can be accessed using: <code class="docutils literal notranslate"><span class="pre">get_tokenizer(&quot;spacy&quot;)</span></code>. Spacy supports a wide range of languages.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/">Huggingface</a>: it has many tokenizers for different laguages. <a class="reference external" href="https://huggingface.co/transformers/main_classes/tokenizer.html">Doc</a></p></li>
<li><p><a class="reference external" href="https://www.nltk.org/">NLTK</a>: it provides several tokenizers. One of them can be accessed using: <code class="docutils literal notranslate"><span class="pre">get_tokenizer(&quot;toktok&quot;)</span></code></p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="step-4-choose-toolkit">
<h1>Step 4: choose toolkit<a class="headerlink" href="#step-4-choose-toolkit" title="Permalink to this heading">#</a></h1>
<p>Our goal is to train a model capable of estimating the sentiment of a tweet (positive or negative) by reading its content. To that end we will try 2 different approaches:</p>
<ul class="simple">
<li><p>A logistic regression using sklearn. <strong>NOTE</strong>: it can probaly work better than an SVM model.</p></li>
<li><p>A simple Embedding + RNN.</p></li>
</ul>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading">#</a></h2>
<p>We will represent our senteces using binary vectorization. This means that our data would be represented as a matrix of instances by word with a one if the word is in the instance, and zero otherwise. Sklean vectorizers can also do things such as stop-word removal and puntuation removal, you can read more about in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">the documentation</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x_train_cv</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train_text</span><span class="p">)</span>
<span class="n">x_test_cv</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before Vectorize: &#39;</span><span class="p">,</span> <span class="n">x_train_text</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before Vectorize:  doesn&#39;t know how to spell conked 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Notice that the matriz is sparse</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After Vectorize: &#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_train_cv</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After Vectorize: 
  (0, 528584)	1
  (0, 165468)	1
  (0, 300381)	1
  (0, 242211)	1
  (0, 489893)	1
  (0, 134160)	1
</pre></div>
</div>
</div>
</div>
<p>Now we can train our model. You can check the documentation of this logistic regressor <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic#sklearn.linear_model.LogisticRegression">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_cv</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_cv</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.81      0.79      0.80    160000
           1       0.79      0.81      0.80    160000

    accuracy                           0.80    320000
   macro avg       0.80      0.80      0.80    320000
weighted avg       0.80      0.80      0.80    320000
</pre></div>
</div>
</div>
</div>
</section>
<section id="explainable-ai">
<h2>Explainable AI<a class="headerlink" href="#explainable-ai" title="Permalink to this heading">#</a></h2>
<p>The best thing about logistic regresion is that it is simple, and we can get some explanations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">))</span>

<span class="n">words_sk</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">words_sk</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 589260)
589260
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words_sk</span><span class="p">[:</span><span class="mi">20</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>roni: -3.8625743295204957
inaperfectworld: -3.5734332703128837
dontyouhate: -3.5001974848534263
xbllygbsn: -3.4126706055950495
anqju: -3.3363734662876445
sad: -3.200515320038219
pakcricket: -3.1949201520762647
condolences: -3.1325044251779404
heartbreaking: -3.066490736238656
saddest: -3.0420206470077464
sadd: -3.0290359193094782
heartbroken: -3.028758057376751
boohoo: -3.0225999274601483
sadface: -2.9918433622017107
rachelle_lefevr: -2.9250755659458325
disappointing: -2.9025305172931777
lvbu: -2.8947126358841744
saddens: -2.885505898962137
bummed: -2.8364963698917003
neda: -2.792965453263205
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">words_sk</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">w</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>iamsoannoyed: 2.849404979800149
myfax: 2.7974231693128444
jennamadison: 2.566709062644627
yeyy: 2.4780376468589687
tryout: 2.4383326853311327
goldymom: 2.4374101525708456
wooohooo: 2.4029624310379774
thesupergirl: 2.3565547667359015
iammaxathotspot: 2.3116516945468017
londicreations: 2.3074597815514477
smilin: 2.2991641364971334
worries: 2.2899475148214545
sinfulsignorita: 2.2798843862743605
finchensnail: 2.264277870479377
smackthis: 2.237665085200092
kv: 2.215872609715896
tojosan: 2.2117820541821733
russmarshalek: 2.2095325084648705
traciknoppe: 2.1768517653116426
congratulations: 2.1715832459661644
</pre></div>
</div>
</div>
</div>
<p>What does this mean?</p>
<p>Remember the <code class="docutils literal notranslate"><span class="pre">model.coef_</span></code> is the <span class="math notranslate nohighlight">\(W\)</span> in:</p>
<div class="math notranslate nohighlight">
\[h(x)=\sigma(WX + b)\]</div>
<p>where the label 1 is a positive tweet and the label 0 is a negative tweet.</p>
</section>
<section id="recurrent-neural-network-with-pytorch">
<h2>Recurrent Neural Network with Pytorch<a class="headerlink" href="#recurrent-neural-network-with-pytorch" title="Permalink to this heading">#</a></h2>
<p>In the previous section we use a Bag-Of-Words approach to represent each of the tweets. That meas that we only consider how many times each of the words appear in each of the tweets, we didnt take into account the order of the words. But we know that the word order is very important and carries relevant information.</p>
<p>In this section we will solve the same task, but this time we will implement a Recurrent Neural Network (RNN) instead of using a simple Logistic Regression.Unlike feedforward neural networks, RNNs have cyclic connections making them powerful for modeling sequences.</p>
<p>Lets start by importing the relevant libraries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: For this notebook to perform best, &quot;</span>
          <span class="s2">&quot;if possible, in the menu under `Runtime` -&gt; &quot;</span>
          <span class="s2">&quot;`Change runtime type.`  select `GPU` &quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is enabled in this notebook.&quot;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the device (check if gpu is available)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
<p>First we will create a Dictionary (<code class="docutils literal notranslate"><span class="pre">word_to_idx</span></code>). This dictionary will map each Token (usually words) to an index (an integer number). We want to limit our dictionary to a certain number of tokens (<code class="docutils literal notranslate"><span class="pre">num_words_dict</span></code>), so we will include in our ditionary those with more occurrences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From previous section, we have a list with the most used tokens</span>
<span class="n">sorted_words</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;.&#39;, &#39;i&#39;, &#39;!&#39;, &quot;&#39;&quot;, &#39;to&#39;, &#39;the&#39;, &#39;,&#39;, &#39;a&#39;, &#39;my&#39;, &#39;it&#39;]
</pre></div>
</div>
</div>
</div>
<p>Lets select only the most used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_words_dict</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="c1"># We reserve two numbers for special tokens.</span>
<span class="n">most_used_words</span> <span class="o">=</span> <span class="n">sorted_words</span><span class="p">[:</span><span class="n">num_words_dict</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We will add two extra Tokens to the dictionary, one for words outside the dictionary (<code class="docutils literal notranslate"><span class="pre">'UNK'</span></code>) and one for padding the sequences (<code class="docutils literal notranslate"><span class="pre">'PAD'</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dictionary to go from words to idx</span>
<span class="n">word_to_idx</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1"># dictionary to go from idx to words (just in case)</span>
<span class="n">idx_to_word</span> <span class="o">=</span> <span class="p">{}</span>


<span class="c1"># We include the special tokens first</span>
<span class="n">PAD_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">UNK_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;PAD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PAD_token</span>
<span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">UNK_token</span>

<span class="n">idx_to_word</span><span class="p">[</span><span class="n">PAD_token</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;PAD&#39;</span>
<span class="n">idx_to_word</span><span class="p">[</span><span class="n">UNK_token</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;UNK&#39;</span>

<span class="c1"># We popullate our dictionaries with the most used words</span>
<span class="k">for</span> <span class="n">num</span><span class="p">,</span><span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">most_used_words</span><span class="p">):</span>
  <span class="n">word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">num</span> <span class="o">+</span> <span class="mi">2</span>
  <span class="n">idx_to_word</span><span class="p">[</span><span class="n">num</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</pre></div>
</div>
</div>
</div>
<p>Our goal now is to transform each tweet from a sequence of tokens to a sequence of indexes. These sequences of indexes will be the input to our pytorch model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A function to convert list of tokens to list of indexes</span>
<span class="k">def</span> <span class="nf">tokens_to_idx</span><span class="p">(</span><span class="n">sentences_tokens</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">):</span>
  <span class="n">sentences_idx</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences_tokens</span><span class="p">:</span>
    <span class="n">sent_idx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_to_idx</span><span class="p">:</span>
        <span class="n">sent_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">sent_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_to_idx</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">])</span>
    <span class="n">sentences_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sent_idx</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">sentences_idx</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train_idx</span> <span class="o">=</span> <span class="n">tokens_to_idx</span><span class="p">(</span><span class="n">x_train_token</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">)</span>
<span class="n">x_test_idx</span> <span class="o">=</span> <span class="n">tokens_to_idx</span><span class="p">(</span><span class="n">x_test_token</span><span class="p">,</span><span class="n">word_to_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">some_number</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before converting: &#39;</span><span class="p">,</span> <span class="n">x_train_token</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After converting: &#39;</span><span class="p">,</span> <span class="n">x_train_idx</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before converting:  [&#39;worst&#39;, &#39;headache&#39;, &#39;ever&#39;]
After converting:  [721, 458, 237]
</pre></div>
</div>
</div>
</div>
<p>We need all the sequences to have the same length. To select an adequate sequence length, lets explore some statistics about the length of the tweets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweet_lens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">x_train_idx</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Max tweet word length: &#39;</span><span class="p">,</span><span class="n">tweet_lens</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean tweet word length: &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">tweet_lens</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;99% percent under: &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">tweet_lens</span><span class="p">,</span><span class="mf">0.99</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Max tweet word length:  229
Mean tweet word length:  15.0
99% percent under:  37.0
</pre></div>
</div>
</div>
</div>
<p>We cut the sequences which are larger than our chosen maximum length (<code class="docutils literal notranslate"><span class="pre">max_lenght</span></code>) and fill with zeros the ones that are shorter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> <span class="c1"># We choose the max length</span>
 <span class="n">max_length</span> <span class="o">=</span> <span class="mi">40</span>

<span class="c1"># A function to make all the sequence have the same lenght</span>
<span class="c1"># Note that the output is a Numpy matrix</span>
 <span class="k">def</span> <span class="nf">padding</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">):</span>
  <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">seq_len</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="n">len_tweet</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">&lt;=</span> <span class="n">seq_len</span><span class="p">:</span>
        <span class="c1"># If its shorter, we fill with zeros (the padding Token index)</span>
        <span class="n">features</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">tweet</span><span class="p">):]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tweet</span><span class="p">)[:</span><span class="n">seq_len</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">len_tweet</span> <span class="o">&gt;</span> <span class="n">seq_len</span><span class="p">:</span>
        <span class="c1"># If its larger, we take the last &#39;seq_len&#39; indexes</span>
        <span class="n">features</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tweet</span><span class="p">)[</span><span class="o">-</span><span class="n">seq_len</span><span class="p">:]</span>
  <span class="k">return</span> <span class="n">features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We convert our list of tokens into a numpy matrix</span>
<span class="c1"># where all instances have the same lenght</span>
<span class="n">x_train_pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">(</span><span class="n">x_train_idx</span><span class="p">,</span><span class="n">max_length</span><span class="p">)</span>
<span class="n">x_test_pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">(</span><span class="n">x_test_idx</span><span class="p">,</span><span class="n">max_length</span><span class="p">)</span>

<span class="c1"># We convert our target list a numpy matrix</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">some_number</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before padding: &#39;</span><span class="p">,</span> <span class="n">x_train_idx</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After padding: &#39;</span><span class="p">,</span> <span class="n">x_train_pad</span><span class="p">[</span><span class="n">some_number</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before padding:  [1, 3, 71, 24, 122, 3, 533, 74, 13, 4, 3, 102, 13, 209, 2, 12, 150, 4, 22, 5, 18, 667, 3, 138, 61, 7, 3296, 4]
After padding:  [   0    0    0    0    0    0    0    0    0    0    0    0    1    3
   71   24  122    3  533   74   13    4    3  102   13  209    2   12
  150    4   22    5   18  667    3  138   61    7 3296    4]
</pre></div>
</div>
</div>
</div>
<p>Now, lets convert the data to pytorch format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create Tensor datasets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train_pad</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_np</span><span class="p">))</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test_pad</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test_np</span><span class="p">))</span>

<span class="c1"># Batch size (this is an important hyperparameter)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># dataloaders</span>
<span class="c1"># make sure to SHUFFLE your data</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Each batch of data in our traning proccess will have the folllowing format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain one batch of training data</span>
<span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">sample_x</span><span class="p">,</span> <span class="n">sample_y</span> <span class="o">=</span> <span class="n">dataiter</span><span class="o">.</span><span class="fm">__next__</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input size: &#39;</span><span class="p">,</span> <span class="n">sample_x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="c1"># batch_size, seq_length</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sample_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample input: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sample_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample input size:  torch.Size([100, 40])
Sample input: 
 tensor([[    0,     0,     0,  ...,    12,  4491,     2],
        [    0,     0,     0,  ...,     0,     1,   383],
        [    0,     0,     0,  ...,     6,   246,     2],
        ...,
        [    0,     0,     0,  ...,   108,    14,     4],
        [    0,     0,     0,  ...,  2434,    29,     1],
        [    0,     0,     0,  ...,  1150, 20247,     2]])
Sample input: 
 tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,
        1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,
        1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,
        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,
        0, 0, 1, 1])
</pre></div>
</div>
</div>
</div>
<p>Now, we will define the <code class="docutils literal notranslate"><span class="pre">SentimentRNN</span></code> class. Most of the models class will be familiar to you, but there are two important layers we would like you to pay attention to:</p>
<ul class="simple">
<li><p>Embedding Layer</p></li>
</ul>
<blockquote>
<div><p>This layer is like a linear layer, but it makes it posible to use a sequence of inedexes as inputs (instead of a sequence of one-hot-encoded vectors). During training, the Embedding layer learns a linear transformation from the space of words (a vector space of dimension <code class="docutils literal notranslate"><span class="pre">num_words_dict</span></code>) into the a new, smaller, vector space of dimension <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code>. We suggest you to read this <a class="reference external" href="https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518/3">thread</a> and the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">pytorch documentation</a> if you want to learn more about this particular kind of layers.</p>
</div></blockquote>
<ul class="simple">
<li><p>LSTM layer</p></li>
</ul>
<blockquote>
<div><p>This is one of the most used class of Recurrent Neural Networks. In Pytorch we can add several stacked layers in just one line of code. In our case, the number of layers added are decided with the parameter <code class="docutils literal notranslate"><span class="pre">no_layers</span></code>. If you want to learn more about LSTMs we strongly recommend you this <a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Colahs thread</a> about them.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SentimentRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">no_layers</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SentimentRNN</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span> <span class="o">=</span> <span class="n">no_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">=</span> <span class="n">drop_prob</span>

    <span class="c1"># Embedding Layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="c1"># LSTM Layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
                        <span class="n">num_layers</span><span class="o">=</span><span class="n">no_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span><span class="p">)</span>

    <span class="c1"># Dropout layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">drop_prob</span><span class="p">)</span>

    <span class="c1"># Linear and Sigmoid layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sig</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">hidden</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Embedding out</span>
    <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">#Shape: [batch_size x max_length x embedding_dim]</span>

    <span class="c1"># LSTM out</span>
    <span class="n">lstm_out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embeds</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="c1"># Shape: [batch_size x max_length x hidden_dim]</span>

    <span class="c1"># Select the activation of the last Hidden Layer</span>
    <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="c1"># Shape: [batch_size x hidden_dim]</span>

    <span class="c1">## You can instead average the activations across all the times</span>
    <span class="c1"># lstm_out = torch.mean(lstm_out, 1).contiguous()</span>

    <span class="c1"># Dropout and Fully connected layer</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># Sigmoid function</span>
    <span class="n">sig_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sig</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># return last sigmoid output and hidden state</span>
    <span class="k">return</span> <span class="n">sig_out</span><span class="p">,</span> <span class="n">hidden</span>

  <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39; Initializes hidden state &#39;&#39;&#39;</span>
    <span class="c1"># Create two new tensors with sizes n_layers x batch_size x hidden_dim,</span>
    <span class="c1"># initialized to zero, for hidden state and cell state of LSTM</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">no_layers</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span><span class="n">c0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
<p>We choose the parameters of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parameters of our network</span>

<span class="c1"># Size of our vocabulary</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="n">num_words_dict</span>

<span class="c1"># Embedding dimension</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Number of stacked LSTM layers</span>
<span class="n">no_layers</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Dimension of the hidden layer in LSTMs</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># Dropout parameter for regularization</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Dropout parameter for regularization</span>
<span class="n">drop_prob</span> <span class="o">=</span> <span class="mf">0.25</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s define our model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentimentRNN</span><span class="p">(</span><span class="n">no_layers</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span>
                     <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>
<span class="c1"># Moving to gpu</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SentimentRNN(
  (embedding): Embedding(30000, 32)
  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, dropout=0.25)
  (dropout): Dropout(p=0.25, inplace=False)
  (fc): Linear(in_features=64, out_features=1, bias=True)
  (sig): Sigmoid()
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># How many trainable parameters does our model have?</span>
<span class="n">model_parameters</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model_parameters</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Number of parameters: &#39;</span><span class="p">,</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Number of parameters:  1018433
</pre></div>
</div>
</div>
</div>
<p>We choose the losses and the optimizer for the training procces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss and optimization functions</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Binary crossentropy is a good loss function for a binary classification problem</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="c1"># We choose an Adam optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># function to predict accuracy</span>
<span class="k">def</span> <span class="nf">acc</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>We are ready to train our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of training Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Maximum absolute value accepted for the gradeint</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Initial Loss value (assumed big)</span>
<span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

<span class="c1"># Lists to follow the evolution of the loss and accuracy</span>
<span class="n">epoch_tr_loss</span><span class="p">,</span><span class="n">epoch_vl_loss</span> <span class="o">=</span> <span class="p">[],[]</span>
<span class="n">epoch_tr_acc</span><span class="p">,</span><span class="n">epoch_vl_acc</span> <span class="o">=</span> <span class="p">[],[]</span>

<span class="c1"># Train for a number of Epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">train_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>

    <span class="c1"># Initialize hidden state</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="c1"># Creating new variables for the hidden state</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">each</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">h</span><span class="p">])</span>

    <span class="c1"># Move batch inputs and labels to gpu</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Set gradient to zero</span>
    <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Compute model output</span>
    <span class="n">output</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>

    <span class="c1"># Calculate the loss and perform backprop</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># calculating accuracy</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">acc</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">train_acc</span> <span class="o">+=</span> <span class="n">accuracy</span>

    <span class="c1">#`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


  <span class="c1"># Evaluate on the validation set for this epoch</span>
  <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">val_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>

    <span class="c1"># Initialize hidden state</span>
    <span class="n">val_h</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">val_h</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">each</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">val_h</span><span class="p">])</span>

    <span class="c1"># Move batch inputs and labels to gpu</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Compute model output</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">val_h</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">val_h</span><span class="p">)</span>

    <span class="c1"># Compute Loss</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

    <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">acc</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">+=</span> <span class="n">accuracy</span>

  <span class="n">epoch_train_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span>
  <span class="n">epoch_val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span>
  <span class="n">epoch_train_acc</span> <span class="o">=</span> <span class="n">train_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">epoch_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">epoch_tr_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_train_loss</span><span class="p">)</span>
  <span class="n">epoch_vl_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_val_loss</span><span class="p">)</span>
  <span class="n">epoch_tr_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_train_acc</span><span class="p">)</span>
  <span class="n">epoch_vl_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_val_acc</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_loss : </span><span class="si">{</span><span class="n">epoch_train_loss</span><span class="si">}</span><span class="s1"> val_loss : </span><span class="si">{</span><span class="n">epoch_val_loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_accuracy : </span><span class="si">{</span><span class="n">epoch_train_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1"> val_accuracy : </span><span class="si">{</span><span class="n">epoch_val_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">epoch_val_loss</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_loss_min</span><span class="p">,</span><span class="n">epoch_val_loss</span><span class="p">))</span>
    <span class="c1"># torch.save(model.state_dict(), &#39;../working/state_dict.pt&#39;)</span>
    <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">epoch_val_loss</span>
  <span class="nb">print</span><span class="p">(</span><span class="mi">25</span><span class="o">*</span><span class="s1">&#39;==&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1
train_loss : 0.4357354193425272 val_loss : 0.3897459434857592
train_accuracy : 79.552578125 val_accuracy : 82.34125
Validation loss decreased (inf --&gt; 0.389746).  Saving model ...
==================================================
Epoch 2
train_loss : 0.3756973787629977 val_loss : 0.37125814022496345
train_accuracy : 83.20953125 val_accuracy : 83.41875
Validation loss decreased (0.389746 --&gt; 0.371258).  Saving model ...
==================================================
Epoch 3
train_loss : 0.35649536208133215 val_loss : 0.36528081766329706
train_accuracy : 84.24179687499999 val_accuracy : 83.76593749999999
Validation loss decreased (0.371258 --&gt; 0.365281).  Saving model ...
==================================================
Epoch 4
train_loss : 0.3434784019400831 val_loss : 0.361129659358412
train_accuracy : 84.91164062499999 val_accuracy : 83.9671875
Validation loss decreased (0.365281 --&gt; 0.361130).  Saving model ...
==================================================
Epoch 5
train_loss : 0.33264520978555084 val_loss : 0.3602768037747592
train_accuracy : 85.53132812499999 val_accuracy : 84.0209375
Validation loss decreased (0.361130 --&gt; 0.360277).  Saving model ...
==================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_tr_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_vl_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_tr_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_vl_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/33d3011681e7d94ced32c6da525cf58b97e52769de18d8baa0742cd23f45b991.png" src="../../_images/33d3011681e7d94ced32c6da525cf58b97e52769de18d8baa0742cd23f45b991.png" />
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="what-s-next">
<h1>Whats Next?<a class="headerlink" href="#what-s-next" title="Permalink to this heading">#</a></h1>
<p>You can use this project template as a starting point to think about your own project. There are a lot of ways to continue, here we share with you some ideas you migth find useful:</p>
<ul class="simple">
<li><p><strong>Work on the Preproccesing.</strong> We used a very rudimentary way to tokenize tweets. But there are better ways to preprocess the data. Can you think of a suitable way to preprocess the data for this particular task? How does the performance of the model change when the data is processed correctly?</p></li>
<li><p><strong>Work on the Model.</strong> The RNN model proposed in this notebook is not optimized at all. You can work on finding a better architecture or better hyperparamenters. May be using bidirectonal LSTMs or increasing the number of stacked layers can improve the performance, feel free to try different approaches.</p></li>
<li><p><strong>Work on the Embedding.</strong> Our model learnt an embedding during the training on this Twitter corpus for a particular task. You can explore the representation of different words in this learned embedding. Also, you can try using different word embeddings. You can train them on this corpus or you can use an embedding trained on another corpus of data. How does the change of the embedding affect the model performance?</p></li>
<li><p><strong>Try sentiment analysis on another dataset.</strong> There are lots of available dataset to work with, we can help you find one that is interesting to you. Do you belive that a sentiment analysis model trained on some corpus (Twitter dataset) will perform well on another type of data (for example, youtube comments)?</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./projects/NaturalLanguageProcessing"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="ideas_and_datasets.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Ideas</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="machine_translation.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Machine Translation</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Twitter Sentiment Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome-to-the-nlp-project-template">
   Welcome to the NLP project template
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-questions-and-goals">
   Step 1: Questions and goals
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-literature-review">
   Step 2: Literature review
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-load-and-explore-the-dataset">
   Step 3: Load and explore the dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-choose-toolkit">
   Step 4: choose toolkit
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explainable-ai">
     Explainable AI
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recurrent-neural-network-with-pytorch">
     Recurrent Neural Network with Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-s-next">
   Whats Next?
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Neuromatch
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>

</div>
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>