{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W1D5_Regularization/W1D5_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Regularization techniques part 2\n",
    "**Week 1, Day 5: Regularization**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "\n",
    "__Content creators:__ Ravi Teja Konkimalla, Mohitrajhu Lingan Kumaraian, Kevin Machado Gamboa, Kelson Shilling-Scrivo, Lyle Ungar\n",
    "\n",
    "__Content reviewers:__ Piyush Chauhan, Kelson Shilling-Scrivo\n",
    "\n",
    "__Content editors:__ Roberto Guidotti, Spiros Chavlis\n",
    "\n",
    "__Production editors:__ Saeed Salehi, Spiros Chavlis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "\n",
    "1.   Regularization as shrinkage of overparameterized models: L1, L2\n",
    "2.   Regularization by Dropout\n",
    "3.   Regularization by Data Augmentation\n",
    "4.   Perils of Hyper-Parameter Tuning\n",
    "5.   Rethinking generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "outputId": "1c07c75a-2b4d-4ea6-fe14-88bc60a074a4"
   },
   "outputs": [],
   "source": [
    "#@markdown Tutorial slides\n",
    "\n",
    "#@markdown **Do not read them now.**\n",
    "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/1N9aguIPiBSjzo0ToqPi5uwwG8ChY6_E3/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup\n",
    "Note that some of the code for today can take up to an hour to run. We have therefore \"hidden\" that code and shown the resulting outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure you're running a GPU notebook:**\n",
    "From \"Runtime\" in the drop-down menu above, click \"Change runtime type\". Ensure that \"Hardware Accelerator\" says \"GPU\".\n",
    "\n",
    "**Ensure you can save:** From \"File\", click \"Save a copy in Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Loading Animal Faces data\n",
    "%%capture\n",
    "!rm -r AnimalFaces32x32/\n",
    "!git clone https://github.com/arashash/AnimalFaces32x32\n",
    "!rm -r afhq/\n",
    "!unzip ./AnimalFaces32x32/afhq_32x32.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Loading Animal Faces Randomized data\n",
    "%%capture\n",
    "!rm -r Animal_faces_random/\n",
    "!git clone https://github.com/Ravi3191/Animal_faces_random.git\n",
    "!rm -r afhq_random_32x32/\n",
    "!unzip ./Animal_faces_random/afhq_random_32x32.zip\n",
    "!rm -r afhq_10_32x32/\n",
    "!unzip ./Animal_faces_random/afhq_10_32x32.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5     # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.axis(False)\n",
    "  plt.show()\n",
    "\n",
    "def plot_weights(norm, labels, ws, title='Weight Size Measurement'):\n",
    "  plt.figure(figsize=[8, 6])\n",
    "  plt.title(title)\n",
    "  plt.ylabel('Frobenius Norm Value')\n",
    "  plt.xlabel('Model Layers')\n",
    "  plt.bar(labels, ws)\n",
    "  plt.axhline(y=norm,\n",
    "              linewidth=1,\n",
    "              color='r',\n",
    "              ls='--',\n",
    "              label='Total Model F-Norm')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "##Network Class - Animal Faces\n",
    "class AnimalNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(AnimalNet, self).__init__()\n",
    "    self.fc1 = nn.Linear(3 * 32 * 32, 128)\n",
    "    self.fc2 = nn.Linear(128, 32)\n",
    "    self.fc3 = nn.Linear(32, 3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch,\n",
    "          reg_function1=None, reg_function2=None, criterion=F.nll_loss):\n",
    "  \"\"\"\n",
    "  Trains the current inpur model using the data\n",
    "  from Train_loader and Updates parameters for a single pass\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    if reg_function1 is None:\n",
    "      loss = criterion(output, target)\n",
    "    elif reg_function2 is None:\n",
    "      loss = criterion(output, target)+args['lambda']*reg_function1(model)\n",
    "    else:\n",
    "      loss = criterion(output, target)+args['lambda1']*reg_function1(model)+args['lambda2']*reg_function2(model)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, loader = 'Test', criterion=F.nll_loss):\n",
    "  \"\"\"\n",
    "  Tests the current Model\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += criterion(output, target, reduction='sum').item()  # sum up batch loss\n",
    "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def main(args, model, train_loader, val_loader, test_data,\n",
    "         reg_function1=None, reg_function2=None, criterion=F.nll_loss):\n",
    "  \"\"\"\n",
    "  Trains the model with train_loader and tests the learned model using val_loader\n",
    "  \"\"\"\n",
    "\n",
    "  use_cuda = not args['no_cuda'] and torch.cuda.is_available()\n",
    "  device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "  model = model.to(device)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "  val_acc_list, train_acc_list,param_norm_list = [], [], []\n",
    "  for epoch in tqdm(range(args['epochs'])):\n",
    "    train(args, model, device, train_loader, optimizer, epoch,reg_function1=reg_function1,reg_function2=reg_function2)\n",
    "    train_acc = test(model,device,train_loader, 'Train')\n",
    "    val_acc = test(model,device,val_loader, 'Val')\n",
    "    param_norm = calculate_frobenius_norm(model)\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_acc_list.append(val_acc)\n",
    "    param_norm_list.append(param_norm)\n",
    "\n",
    "  return val_acc_list, train_acc_list, param_norm_list, model, 0\n",
    "\n",
    "\n",
    "def calculate_frobenius_norm(model):\n",
    "\n",
    "  norm = 0.0\n",
    "\n",
    "  # Sum the square of all parameters\n",
    "  for param in model.parameters():\n",
    "      norm += torch.sum(param**2)\n",
    "\n",
    "  # Take a square root of the sum of squares of all the parameters\n",
    "  norm = norm**0.5\n",
    "  return norm\n",
    "\n",
    "\n",
    "def calculate_frobenius_norm(model):\n",
    "    norm = 0.0\n",
    "\n",
    "    for name,param in model.named_parameters():\n",
    "        norm += torch.norm(param).data**2\n",
    "    return norm**0.5\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(1, 300)\n",
    "    self.fc2 = nn.Linear(300, 500)\n",
    "    self.fc3 = nn.Linear(500, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.leaky_relu(self.fc1(x))\n",
    "    x = F.leaky_relu(self.fc2(x))\n",
    "    output = self.fc3(x)\n",
    "    return output\n",
    "\n",
    "# Network Class - Animal Faces\n",
    "class BigAnimalNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BigAnimalNet, self).__init__()\n",
    "    self.fc1 = nn.Linear(3*32*32, 124)\n",
    "    self.fc2 = nn.Linear(124, 64)\n",
    "    self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = F.leaky_relu(self.fc1(x))\n",
    "    x = F.leaky_relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def visualize_data(dataloader):\n",
    "\n",
    "  for idx, (data,label) in enumerate(dataloader):\n",
    "    plt.figure(idx)\n",
    "    # Choose the datapoint you would like to visualize\n",
    "    index = 22\n",
    "\n",
    "    # choose that datapoint using index and permute the dimensions\n",
    "    # and bring the pixel values between [0,1]\n",
    "    data = data[index].permute(1, 2, 0) * \\\n",
    "           torch.tensor([0.5, 0.5, 0.5]) + \\\n",
    "           torch.tensor([0.5, 0.5, 0.5])\n",
    "\n",
    "    # Convert the torch tensor into numpy\n",
    "    data = data.numpy()\n",
    "\n",
    "    plt.imshow(data)\n",
    "    plt.axis(False)\n",
    "    image_class = classes[label[index].item()]\n",
    "    print(f'The image belongs to : {image_class}')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def early_stopping_main(args, model, train_loader, val_loader, test_data):\n",
    "\n",
    "  device = set_device()\n",
    "\n",
    "  model = model.to(device)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "  best_acc  = 0.0\n",
    "  best_epoch = 0\n",
    "\n",
    "  # Number of successive epochs that you want to wait before stopping training process\n",
    "  patience = 20\n",
    "\n",
    "  # Keps track of number of epochs during which the val_acc was less than best_acc\n",
    "  wait = 0\n",
    "\n",
    "  val_acc_list, train_acc_list = [], []\n",
    "  for epoch in tqdm(range(args['epochs'])):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    train_acc = test(model,device,train_loader, 'Train')\n",
    "    val_acc = test(model,device,val_loader, 'Val')\n",
    "    if (val_acc > best_acc):\n",
    "      best_acc = val_acc\n",
    "      best_epoch = epoch\n",
    "      best_model = copy.deepcopy(model)\n",
    "      wait = 0\n",
    "    else:\n",
    "      wait += 1\n",
    "    if (wait > patience):\n",
    "      print('early stopped on epoch:',epoch)\n",
    "      break\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "  return val_acc_list, train_acc_list, best_model, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f936e7eb-9f8d-4614-bfcf-4a9ce86d2cd7"
   },
   "outputs": [],
   "source": [
    "#@title Seeding for Reproducibility\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "set_seed(seed=90108, seed_torch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "8d839178-674c-481d-a64b-2790b65a4482"
   },
   "outputs": [],
   "source": [
    "#@title Set device (GPU or CPU). Execute `set_device()`\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "\n",
    "set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "00768c40-834c-43c9-c6cb-5e1395be0567"
   },
   "outputs": [],
   "source": [
    "# Seed parameter\n",
    "# Notice that changing this values some results may not be identical\n",
    "# with the solutions\n",
    "SEED = 90108\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Dataloaders for the Dataset\n",
    "##Dataloaders for the Dataset\n",
    "batch_size = 128\n",
    "classes = ('cat', 'dog', 'wild')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "\n",
    "\n",
    "####################################################\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "\n",
    "##Dataloaders for the  Original Dataset\n",
    "img_train_data, img_val_data,_ = torch.utils.data.random_split(img_dataset,\n",
    "                                                               [100, 100, 14430])\n",
    "\n",
    "#Creating train_loader and Val_loader\n",
    "train_loader = torch.utils.data.DataLoader(img_train_data,batch_size=batch_size,\n",
    "                                           worker_init_fn=seed_worker,\n",
    "                                           generator=g_seed)\n",
    "val_loader = torch.utils.data.DataLoader(img_val_data,batch_size=1000,\n",
    "                                         worker_init_fn=seed_worker,\n",
    "                                         generator=g_seed)\n",
    "\n",
    "#creating test dataset\n",
    "test_transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "img_test_dataset = ImageFolder(data_path/'val', transform=test_transform)\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "##Dataloaders for the  Random Dataset\n",
    "\n",
    "#splitting randomized data into training and validation data\n",
    "data_path = pathlib.Path('.')/'afhq_random_32x32/afhq_random' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "random_img_train_data, random_img_val_data,_ = torch.utils.data.random_split(img_dataset, [100,100,14430])\n",
    "\n",
    "#Randomized train and validation dataloader\n",
    "rand_train_loader = torch.utils.data.DataLoader(random_img_train_data,\n",
    "                                                batch_size=batch_size,num_workers = 0,\n",
    "                                                worker_init_fn=seed_worker,\n",
    "                                                generator=g_seed)\n",
    "rand_val_loader = torch.utils.data.DataLoader(random_img_val_data,\n",
    "                                              batch_size=1000,\n",
    "                                              num_workers = 0,\n",
    "                                              worker_init_fn=seed_worker,\n",
    "                                              generator=g_seed)\n",
    "\n",
    "####################################################\n",
    "\n",
    "##Dataloaders for the Partially Random Dataset\n",
    "\n",
    "#Splitting data between training and validation dataset for partially randomized data\n",
    "data_path = pathlib.Path('.')/'afhq_10_32x32/afhq_10' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "partially_random_train_data, partially_random_val_data, _ = torch.utils.data.random_split(img_dataset, [100,100,14430])\n",
    "\n",
    "#Training and Validation loader for partially randomized data\n",
    "partial_rand_train_loader = torch.utils.data.DataLoader(partially_random_train_data,\n",
    "                                                        batch_size=batch_size,num_workers = 0,\n",
    "                                                        worker_init_fn=seed_worker,\n",
    "                                                        generator=g_seed)\n",
    "partial_rand_val_loader = torch.utils.data.DataLoader(partially_random_val_data,\n",
    "                                                      batch_size=1000,\n",
    "                                                      num_workers = 0,\n",
    "                                                      worker_init_fn=seed_worker,\n",
    "                                                      generator=g_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: L1 and L2 Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "7184507fbe7c419691f9e1ecb0d4179c",
      "63c39c3293bc48cdac85cb8dac09ece9",
      "f8817157c24e474382af22dbe6761e0e",
      "48d8ce637b1642519d61c2beb3fade63",
      "3a7fd7d11f704d1fac64499cc4cb02d0",
      "0755a910331a4ea5b6cc72a72a13b495"
     ]
    },
    "outputId": "bb7a4f58-5af2-4e48-8d05-34f240fba853"
   },
   "outputs": [],
   "source": [
    "#@title Video 1: L1 and L2 regression\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"oQNdloKdysM\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you might have already come across L1 and L2 regularization before in other courses. L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term.\n",
    "\n",
    "***Cost function = Loss (say, binary cross entropy) + Regularization term***\n",
    "\n",
    "This regularization term makes the parameters smaller, giving simpler models that will overfit less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss among your teammates whether the above assumption is good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1: Unregularized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Dataloaders for Regularization\n",
    "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "\n",
    "# Splitting dataset\n",
    "reg_train_data, reg_val_data,_ = torch.utils.data.random_split(img_dataset,\n",
    "                                                               [30, 100, 14500])\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "# Creating train_loader and Val_loader\n",
    "reg_train_loader = torch.utils.data.DataLoader(reg_train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               worker_init_fn=seed_worker,\n",
    "                                               generator=g)\n",
    "reg_val_loader = torch.utils.data.DataLoader(reg_val_data,\n",
    "                                             batch_size=1000,\n",
    "                                             worker_init_fn=seed_worker,\n",
    "                                             generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model without any regularization and keep it aside as our benchmark for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496,
     "referenced_widgets": [
      "1e4c6975575d49508dd430bb544e1aa0",
      "9752bfaf48a74ed3b8451353e86ccf79",
      "3dbe8f4fb1464daf99b8ce70992bcd4b",
      "36ecc2b9c9fc4839a40a29f8a17350d0",
      "9d9f2b70a026423f903af42f2be493eb",
      "103c782b736a4370afd74d7ab63d4276",
      "57d57efcb91b45ff9078a9cb1200704b",
      "5390c80e66fe4804b7e6c75d02776d22"
     ]
    },
    "outputId": "9100a28d-4694-4716-bd88-b2aa4917865d"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 150,\n",
    "    'lr': 5e-3,\n",
    "    'momentum': 0.99,\n",
    "    'no_cuda': False,\n",
    "}\n",
    "\n",
    "acc_dict = {}\n",
    "model = AnimalNet()\n",
    "\n",
    "val_acc_unreg, train_acc_unreg,param_norm_unreg,_ ,_ = main(args,\n",
    "                                                            model,\n",
    "                                                            reg_train_loader,\n",
    "                                                            reg_val_loader,\n",
    "                                                            img_test_dataset)\n",
    "\n",
    "# Train and Test accuracy plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(val_acc_unreg, label='Val Accuracy', c='red', ls='dashed')\n",
    "plt.plot(train_acc_unreg, label='Train Accuracy', c='red', ls='solid')\n",
    "plt.axhline(y=max(val_acc_unreg), c='green', ls='dashed')\n",
    "plt.title('Unregularized Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('maximum Validation Accuracy reached:%f' % max(val_acc_unreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2: L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 (or \"LASSO\") Regularization uses a penalty which is the sum of the absolute value of all the weights in the DLN, resulting in the following loss function (L  is the usual Cross Entropy loss):\n",
    "\n",
    "\\begin{equation}\n",
    "L_R=L+λ∑|w^{(r)}_{ij}|\n",
    "\\end{equation}\n",
    "\n",
    "At a high level, L1 Regularization is similar to L2 Regularization since it leads to smaller weights. (You will see the analogy in the next subsection.) It results in the following weight update equation when using Stochastic Gradient Descent (where  sgn  is the sign function, such that  sgn(w)=+1  if  w>0 ,  sgn(w)=−1  if  $w<0$ , and sgn(0)=0 ):\n",
    "\n",
    "\\begin{equation}\n",
    "w^{(r)}_{ij}←w^{(r)}_{ij}−ηλsgn(w^{(r)}_{ij})−η\\frac{\\partial L}{\\partial w_{ij}^{r}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 1.1: L1 Regularization\n",
    "\n",
    "Write a function which calculates the L1 norm of all the tensors of a Pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b5ad4c3b-6f14-4329-c11f-fb84749ae1a4"
   },
   "outputs": [],
   "source": [
    "def l1_reg(model):\n",
    "  \"\"\"\n",
    "    Inputs: Pytorch model\n",
    "    This function calculates the l1 norm of the all the tensors in the model\n",
    "  \"\"\"\n",
    "  l1 = 0.0\n",
    "  ####################################################################\n",
    "  # Fill in all missing code below (...),\n",
    "  # then remove or comment the line below to test your function\n",
    "  raise NotImplementedError(\"Complete the l1_reg function\")\n",
    "  ####################################################################\n",
    "  for param in model.parameters():\n",
    "    l1 += ...\n",
    "\n",
    "  return l1\n",
    "\n",
    "\n",
    "set_seed(seed=SEED)\n",
    "## uncomment to test\n",
    "# net = nn.Linear(20, 20)\n",
    "# print(f'L1 norm of the model: {l1_reg(net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "13fc2e28-7a1d-48b1-ae7a-5da5cbfbc945"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "def l1_reg(model):\n",
    "  \"\"\"\n",
    "    Inputs: Pytorch model\n",
    "    This function calculates the l1 norm of the all the tensors in the model\n",
    "  \"\"\"\n",
    "  l1 = 0.0\n",
    "\n",
    "  for param in model.parameters():\n",
    "    l1 += torch.sum(torch.abs(param))\n",
    "\n",
    "  return l1\n",
    "\n",
    "\n",
    "set_seed(seed=SEED)\n",
    "## uncomment to test\n",
    "net = nn.Linear(20, 20)\n",
    "print(f'L1 norm of the model: {l1_reg(net)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Random seed 2021 has been set.\n",
    "L1 norm of the model: 48.445133209228516\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a classifier which uses L1 regularization. Tune the hyperparameter `lambda` such that the validation accuracy is higher than that of the unregularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496,
     "referenced_widgets": [
      "5d4efa8ece8949c2a4057fedce6f92ef",
      "31a2d7f78e214e32ab49491f6c44c435",
      "e5f42aab449f49feb899127510a69f49",
      "a8b9ee38b3784c81a3b434053ff8b9ba",
      "c1355f97487942fcbfb20f453e3451d2",
      "a1fc0b540a6143688ed48a60884442da",
      "9cf2f43d22014550b50d415785ee3dac",
      "7b683ec4c6fa49b4ab6b4ccaec721d2f"
     ]
    },
    "outputId": "60b6350b-bf11-46a1-c78a-63df696c1f3d"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 150,\n",
    "    'lr': 5e-3,\n",
    "    'momentum': 0.99,\n",
    "    'no_cuda': False,\n",
    "    'lambda': 0.0  # <<<<<<<< Tune the hyperparameter lambda\n",
    "}\n",
    "\n",
    "acc_dict = {}\n",
    "model = AnimalNet()\n",
    "\n",
    "val_acc_l1reg, train_acc_l1reg, param_norm_l1reg, _, _ = main(args,\n",
    "                                                              model,\n",
    "                                                              reg_train_loader,\n",
    "                                                              reg_val_loader,\n",
    "                                                              img_test_dataset,\n",
    "                                                              reg_function1=l1_reg)\n",
    "\n",
    "# Train and Test accuracy plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(val_acc_l1reg, label='Val Accuracy L1 Regularized',\n",
    "         c='red', ls='dashed')\n",
    "plt.plot(train_acc_l1reg, label='Train Accuracy L1 regularized',\n",
    "         c='red', ls='solid')\n",
    "plt.axhline(y=max(val_acc_l1reg), c='green', ls='dashed')\n",
    "plt.title('L1 regularized model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('maximum Validation Accuracy reached:%f'%max(val_acc_l1reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of Lambda worked for L1 Regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.3: L2 / Ridge Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Regularization, sometimes referred to as “Weight Decay”, is widely used. It works by adding a quadratic penalty term to the Cross Entropy Loss Function  L, which results in a new Loss Function  LR  given by:\n",
    "\n",
    "\\begin{equation}\n",
    "LR=L+λ∑(w^{(r)}_{ij})^2\n",
    "\\end{equation}\n",
    "\n",
    "In order to get further insight into L2 Regularization, we investigate its effect on the Gradient Descent based update equations for the weight and bias parameters. Taking the derivative on both sides of the above equation, we obtain\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L_r}{\\partial w^{(r)}_{ij}}=\\frac{\\partial L}{\\partial w^{(r)}_{ij}}+λw^{(r)}_{ij}\n",
    "\\end{equation}\n",
    "Thus the weight update rule becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "w^{(r)}_{ij}←w^{(r)}_{ij}−η\\frac{\\partial L}{\\partial W^{(r)}_{ij}}−ηλw^{(r)}_{ij}=(1−ηλ)w^{(r)}_{ij}−η\\frac{\\partial L}{\\partial w^{(r)}_{ij}}\n",
    "\\end{equation}\n",
    "\n",
    "where, $\\eta$ is learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 1.2: L2 Regularization\n",
    "\n",
    "Write a function which calculates the L2 norm of all the tensors of a Pytorch model. (What did we call this before?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c22b801-c170-49c6-d44d-caf2bd35175d"
   },
   "outputs": [],
   "source": [
    "def l2_reg(model):\n",
    "\n",
    "  \"\"\"\n",
    "    Inputs: Pytorch model\n",
    "    This function calculates the l2 norm of the all the tensors in the model\n",
    "  \"\"\"\n",
    "\n",
    "  l2 = 0.0\n",
    "  ####################################################################\n",
    "  # Fill in all missing code below (...),\n",
    "  # then remove or comment the line below to test your function\n",
    "  raise NotImplementedError(\"Complete the l2_reg function\")\n",
    "  ####################################################################\n",
    "  for param in model.parameters():\n",
    "    l2 += ...\n",
    "\n",
    "  return l2\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "## uncomment to test\n",
    "# net = nn.Linear(20, 20)\n",
    "# print(f'L2 norm of the model: {l2_reg(net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "963ddb45-cdfb-443a-9afe-5b51025e3e2f"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "def l2_reg(model):\n",
    "\n",
    "  \"\"\"\n",
    "    Inputs: Pytorch model\n",
    "    This function calculates the l2 norm of the all the tensors in the model\n",
    "  \"\"\"\n",
    "\n",
    "  l2 = 0.0\n",
    "  for param in model.parameters():\n",
    "    l2 += torch.sum(torch.abs(param)**2)\n",
    "\n",
    "  return l2\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "## uncomment to test\n",
    "net = nn.Linear(20, 20)\n",
    "print(f'L2 norm of the model: {l2_reg(net)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Random seed 2021 has been set.\n",
    "L2 norm of the model: 7.328375816345215\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train a classifier which uses L2 regularization. Tune the hyperparameter `lambda` such that the val accuracy is higher than that of the unregularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496,
     "referenced_widgets": [
      "d03eb81ea22f45c38704bb56c638682c",
      "e212370f438d4e2d8f32bd472039767f",
      "75723acda6a54681ba2ee41df11e3956",
      "e235c3356ba7458ba8c545f8f774ded6",
      "1ce0aa2ff63145aab89f93f259dfcf09",
      "e5569115d34f4824abec52a8de6115a9",
      "ba1d9d07df644355b7c9f8f17cce3257",
      "e93e0330a27a4f0a9e8da53a017f6c0b"
     ]
    },
    "outputId": "6a27377b-0311-402c-d5ff-82313a85afac"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'test_batch_size': 1000,\n",
    "    'epochs': 150,\n",
    "    'lr': 5e-3,\n",
    "    'momentum': 0.99,\n",
    "    'no_cuda': False,\n",
    "    'lambda': 0.0  # <<<<<<<< Tune the hyperparameter lambda\n",
    "}\n",
    "\n",
    "acc_dict = {}\n",
    "model = AnimalNet()\n",
    "\n",
    "val_acc_l2reg, train_acc_l2reg, param_norm_l2reg, model, _ = main(args,\n",
    "                                                                  model,\n",
    "                                                                  train_loader,\n",
    "                                                                  val_loader,\n",
    "                                                                  img_test_dataset,\n",
    "                                                                  reg_function2=l2_reg)\n",
    "\n",
    "##Train and Test accuracy plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(val_acc_l2reg, label='Val Accuracy L2 regularized',\n",
    "         c='red', ls='dashed')\n",
    "plt.plot(train_acc_l2reg, label='Train Accuracy L2 regularized',\n",
    "         c='red', ls='solid')\n",
    "plt.axhline(y=max(val_acc_l2reg), c='green', ls='dashed')\n",
    "plt.title('L2 Regularized Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('maximum Validation Accuracy reached:%f'%max(val_acc_l2reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of Lambda worked for L2 Regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "referenced_widgets": [
      "8e8ec659cc9744309982098b1c508475",
      "e300e6bb70d7420a80a834cac07210cc",
      "f8f2617e38004825a1b35dab735be6ae",
      "14ad76feef4e45b5834e97cbcd7afec8",
      "b8aa6d041842498e8fbea2c366d76484",
      "ac344e7a8b594fc3bb7c57c2f1fa492d",
      "1498ad96235a4342b42f23ed1ffae7b8",
      "c707c7eeab2c4e02b279cfa2df46922d"
     ]
    },
    "outputId": "01d90d41-9066-469b-de9c-759f68a3865f"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Visualize all of them together (Run Me!)\n",
    "args = {'test_batch_size': 1000,\n",
    "        'epochs': 150,\n",
    "        'lr': 5e-3,\n",
    "        'momentum': 0.99,\n",
    "        'no_cuda': False,\n",
    "        'lambda1': 0.001,\n",
    "        'lambda2': 0.001\n",
    "        }\n",
    "model = AnimalNet()\n",
    "val_acc_l1l2reg, train_acc_l1l2reg, param_norm_l1l2reg, _, _ = main(args,\n",
    "                                                  model,\n",
    "                                                  train_loader,\n",
    "                                                  val_loader,\n",
    "                                                  img_test_dataset,\n",
    "                                                  reg_function1=l1_reg,\n",
    "                                                  reg_function2=l2_reg)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_acc_l2reg,c='red',ls = 'dashed')\n",
    "plt.plot(train_acc_l2reg,label='L2 regularized',c='red',ls = 'solid')\n",
    "plt.axhline(y=max(val_acc_l2reg),c = 'red',ls = 'dashed')\n",
    "plt.plot(val_acc_l1reg,c='green',ls = 'dashed')\n",
    "plt.plot(train_acc_l1reg,label='L1 regularized',c='green',ls = 'solid')\n",
    "plt.axhline(y=max(val_acc_l1reg),c = 'green',ls = 'dashed')\n",
    "plt.plot(val_acc_unreg,c='blue',ls = 'dashed')\n",
    "plt.plot(train_acc_unreg,label='Unregularized',c='blue',ls = 'solid')\n",
    "plt.axhline(y=max(val_acc_unreg),c = 'blue',ls = 'dashed')\n",
    "plt.plot(val_acc_l1l2reg,c='orange',ls = 'dashed')\n",
    "plt.plot(train_acc_l1l2reg,label='L1+L2 regularized',c='orange',ls = 'solid')\n",
    "plt.axhline(y=max(val_acc_l1l2reg),c = 'orange',ls = 'dashed')\n",
    "\n",
    "plt.title('Unregularized Vs L1-Regularized vs L2-regularized Vs L1+L2 regularized')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize what these different regularization does to the parameters of the model. We observe the effect by computing the size (technically, the Frobenius norm) of the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "a808c42e-95d9-4399-d602-43674bfca2e4"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Visualize Norm of the Models (Train Me!)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(param_norm_unreg,label='Unregularized',c = 'blue')\n",
    "plt.plot(param_norm_l1reg,label = 'L1 Regularized', c='green')\n",
    "plt.plot(param_norm_l2reg,label='L2 Regularized',c='red')\n",
    "plt.plot(param_norm_l1l2reg,label='L1+L2 Regularized',c='orange')\n",
    "plt.title('Parameter Norm as a function of training Epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Parameter Norms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plots, you should have seen that even after the model acheives 100% train accuracy the val accuracies are fluctuating This suggests that the model is still trying to learn something. Why whould this be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "88c0ee87910f440d852b5417dd311c35",
      "0a3e6ea3f7774b478bcee51d334d2722",
      "c7d019d37d594cf6b820504f8c3cad41",
      "978ac58902ea4152b327e09d75533934",
      "984576a7d9ee4e13946f7ea297e754a9",
      "79865ee9303c4a92a273ffd4bca371ed"
     ]
    },
    "outputId": "7f3df656-52ec-4d22-f1ea-d10e94271828"
   },
   "outputs": [],
   "source": [
    "#@title Video 2: Dropout\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"UZfUzawej3A\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dropout, we literally drop out (zero out) some neurons during training. Throughout training, on each iteration, standard dropout zeros out some fraction (usually 1/2) of the nodes in each layer before calculating the subsequent layer. Randomly selecting different subsets to dropout introduces noise into the process and reduces overfitting.\n",
    "\n",
    "<center><img src=\"https://d2l.ai/_images/dropout2.svg\" alt=\"Dropout\" width=\"600\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's revisit the toy dataset that we generated above to visualize how the dropout stabilizes training on a noisy dataset. We will slightly modify the architecture we used above to add dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Class - 2D\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(1, 300)\n",
    "    self.fc2 = nn.Linear(300, 500)\n",
    "    self.fc3 = nn.Linear(500, 1)\n",
    "    self.dropout1 = nn.Dropout(0.4)\n",
    "    self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.leaky_relu(self.dropout1(self.fc1(x)))\n",
    "    x = F.leaky_relu(self.dropout2(self.fc2(x)))\n",
    "    output = self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "c599d40798ad4fe9ae861ad128678d7b",
      "745a8fd8ef1e41c7a6250ab486f75630",
      "77dc7a25e6d8411dae798f8e7647a72a",
      "eba5411c8ec74a278cad09925d3fa404",
      "d4db0b6e84604c3e9b52d9b115442be9",
      "e929c65ff1b94da39424ecec9b18ff8e",
      "efc8b0b5971f4d098191bf0af043addd",
      "dd78a8aa9a6a4b7091dfa7cabdf48c64",
      "df5a4dde3e004a08b4d35fb328e7907d",
      "dabdef6251844217b146a152d9ea2cef",
      "8c6333526188498b838ace0fb356480c",
      "1e6125723b3f49199fc2210cb15e3f83",
      "e101dd0661e741c495635690aaf1f3a4",
      "c30cbe7dfd704334916ba97980f4b963",
      "71ce84c83ab34764bd3499a636cb66c9",
      "ef5f805b80ff4f1aad5ea159945922da"
     ]
    },
    "outputId": "7d900d54-488c-490d-89c1-85f65dd9414f"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Run to train the default network\n",
    "\n",
    "#creating train data\n",
    "X = torch.rand((10,1))\n",
    "X.sort(dim = 0)\n",
    "Y = 2*X + 2*torch.empty((X.shape[0],1)).normal_(mean=0,std=1) #adding small error in the data\n",
    "\n",
    "X = X.unsqueeze_(1)\n",
    "Y = Y.unsqueeze_(1)\n",
    "\n",
    "#creating test dataset\n",
    "X_test = torch.linspace(0, 1, 40)\n",
    "X_test = X_test.reshape((40, 1, 1))\n",
    "\n",
    "#train the network on toy dataset\n",
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 1e-4)\n",
    "max_epochs = 10000\n",
    "iters = 0\n",
    "\n",
    "running_predictions = np.empty((40,(int)(max_epochs/500 + 1)))\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "model_norm = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "\n",
    "  #training\n",
    "  model_norm.append(calculate_frobenius_norm(model))\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  predictions = model(X)\n",
    "  loss = criterion(predictions,Y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  train_loss.append(loss.data)\n",
    "  model.eval()\n",
    "  Y_test = model(X_test)\n",
    "  loss = criterion(Y_test,2*X_test)\n",
    "  test_loss.append(loss.data)\n",
    "\n",
    "  if (epoch % 500 == 0 or epoch == max_epochs - 1):\n",
    "    running_predictions[:,iters] = Y_test[:,0,0].detach().numpy()\n",
    "    iters += 1\n",
    "\n",
    "\n",
    "model = BigAnimalNet()\n",
    "\n",
    "args = {'test_batch_size': 1000,\n",
    "        'epochs': 200,\n",
    "        'lr': 5e-3,\n",
    "        'momentum': 0.9,\n",
    "        'no_cuda': False,\n",
    "        }\n",
    "\n",
    "val_acc_pure, train_acc_pure, _, model ,_ = main(args,\n",
    "                                                 model,\n",
    "                                                 train_loader,\n",
    "                                                 val_loader,\n",
    "                                                 img_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "1eef9840de7b4d70bb28dd8b4a288afb",
      "ef2bc597b970454091099ecd98b07eab",
      "9d62f3aaf66149c7b28fa3b18933d7f6",
      "b6c231316f5a42ec9f5de730e494cae5",
      "608a9267a37a41f9a31c44c54653ce0e",
      "5204f6f05da64045b2e04330ed1eedcc",
      "3489739d74eb49b2a160c3e1efcb334b",
      "9d7cff8b1ffa4fe2ab7ce2e117d436a5"
     ]
    },
    "outputId": "b646028f-1d6a-4a79-8054-276363f1d345"
   },
   "outputs": [],
   "source": [
    "# train the network on toy dataset\n",
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "max_epochs = 10000\n",
    "iters = 0\n",
    "\n",
    "running_predictions_dp = np.empty((40, (int)(max_epochs / 500)))\n",
    "\n",
    "train_loss_dp = []\n",
    "test_loss_dp = []\n",
    "model_norm_dp = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "\n",
    "  # training\n",
    "  model_norm_dp.append(calculate_frobenius_norm(model))\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  predictions = model(X)\n",
    "  loss = criterion(predictions, Y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  train_loss_dp.append(loss.data)\n",
    "  model.eval()\n",
    "  Y_test = model(X_test)\n",
    "  loss = criterion(Y_test, 2*X_test)\n",
    "  test_loss_dp.append(loss.data)\n",
    "\n",
    "  if (epoch % 500 == 0 or epoch == max_epochs):\n",
    "    running_predictions_dp[:, iters] = Y_test[:, 0, 0].detach().numpy()\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished training, let's see how the model has evolved over the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "outputId": "a424e3bd-8d9a-4f7e-b70f-0e90d89488b3"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Visualization (Run Me!)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes()\n",
    "def frame(i):\n",
    "    ax.clear()\n",
    "    ax.scatter(X[:,0,:].numpy(),Y[:,0,:].numpy())\n",
    "    plot = ax.plot(X_test[:,0,:].detach().numpy(),running_predictions_dp[:,i])\n",
    "    title = \"Epoch: \" + str(i * 500)\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(\"X axis\")\n",
    "    ax.set_ylabel(\"Y axis\")\n",
    "    return plot\n",
    "anim = animation.FuncAnimation(fig, frame, frames=range(20), blit=False, repeat=False, repeat_delay=10000)\n",
    "html_anim = HTML(anim.to_html5_video());\n",
    "plt.close()\n",
    "display(html_anim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "7bb77e4e-4bcf-43d7-f680-79202964cfb3"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Plot the train and test losses\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(test_loss_dp,label='test_loss dropout',c = 'blue',ls='dashed')\n",
    "plt.plot(test_loss, label='test_loss',c = 'red',ls='dashed')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('dropout vs without dropout')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "aa99ed75-d879-4e12-a37b-7c70b75b7ed8"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Plot the train and test losses\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss_dp,label='train_loss dropout',c = 'blue',ls='dashed')\n",
    "plt.plot(train_loss, label='train_loss',c = 'red',ls='dashed')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('dropout vs without dropout')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "98a69c3a-038f-452a-b8ab-6bbcf51fec29"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Plot model weights with epoch\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(model_norm_dp, label = 'dropout')\n",
    "plt.plot(model_norm, label = 'no dropout')\n",
    "plt.ylabel('norm of the model')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.title('Size of the model vs Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think this performed better than the initial model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Dropout Implementation Caveats: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*  Dropout is used only during training, during testing the complete model weights are used and hence it is important to use model.eval() before testing the model. \n",
    "\n",
    "* Dropout reduces the capacity of the model during training and hence as a general practice wider networks are used when using dropout. If you are using a dropout with a random probability of 0.5 then you might want to double the number of hidden neurons in that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how dropout fares on the Animal Faces Dataset. We first modify the existing model to include dropout and then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Class - Animal Faces\n",
    "class AnimalNetDropout(nn.Module):\n",
    "  def __init__(self):\n",
    "    torch.manual_seed(32)\n",
    "    super(AnimalNetDropout, self).__init__()\n",
    "    self.fc1 = nn.Linear(3*32*32, 248)\n",
    "    self.fc2 = nn.Linear(248, 210)\n",
    "    self.fc3 = nn.Linear(210, 3)\n",
    "    self.dropout1 = nn.Dropout(p=0.5)\n",
    "    self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = x.view(x.shape[0], -1)\n",
    "      x = F.leaky_relu(self.dropout1(self.fc1(x)))\n",
    "      x =F.leaky_relu(self.dropout2(self.fc2(x)))\n",
    "      x = self.fc3(x)\n",
    "      output = F.log_softmax(x, dim=1)\n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "referenced_widgets": [
      "bb4f139d112d4b3fada2306c00b3dfab",
      "1eb5022b9a7e45c8bb95e084278efb03",
      "1b5d81ccaee94e6fa54926504942037f",
      "9833a92580e04a5db14d248abe298bbd",
      "0da9de5039fa4ab199d084d9d08c5ecf",
      "aac4951a1ee24f11bb6828eec91f83a7",
      "fac1126b0a584ee9a7633db9bb2cc777",
      "af0e37763567492486a7b445d7632878"
     ]
    },
    "outputId": "9daae64a-8df2-4f15-8bfa-fbdcb6c48468"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'test_batch_size': 1000,\n",
    "    'epochs': 200,\n",
    "    'lr': 5e-3,\n",
    "    'batch_size': 32,\n",
    "    'momentum': 0.9,\n",
    "    'no_cuda': False,\n",
    "    'seed': 1,\n",
    "    'log_interval': 100\n",
    "}\n",
    "\n",
    "acc_dict = {}\n",
    "model = AnimalNetDropout()\n",
    "\n",
    "val_acc_dropout, train_acc_dropout, _, model ,_ = main(args,\n",
    "                                                       model,\n",
    "                                                       train_loader,\n",
    "                                                       val_loader,\n",
    "                                                       img_test_dataset)\n",
    "\n",
    "##Train and Test accuracy plot\n",
    "\n",
    "plt.plot(val_acc_pure, label='Val', c='blue', ls='dashed')\n",
    "plt.plot(train_acc_pure, label='Train', c='blue', ls='solid')\n",
    "plt.plot(val_acc_dropout, label='Val - DP', c='red', ls='dashed')\n",
    "plt.plot(train_acc_dropout, label='Train - DP', c='red', ls='solid')\n",
    "plt.title('Dropout')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When do you think dropouts can perform bad and do you think their placement within a model matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "7ce683215c42470788c97a5ad70286d0",
      "eeca50ae0c5b4728a1baa4ba57d60521",
      "f0e8cc9133c745b692c72523a93da61f",
      "17b91fcc9e004eff9fb2446031544203",
      "b01cc75b9088416f9bfa03dbc15f7ce6",
      "c8c61ba0802342fc817793398d34a9c7"
     ]
    },
    "outputId": "259ce395-b768-4830-fccf-a7ab5c4cb6a3"
   },
   "outputs": [],
   "source": [
    "#@title Video 3: Data Augmentation\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"nm44FhjL3xc\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is often used to increase the number of training samples. Now we will explore the effects of data augmentation on regularization. Here regularization is acheived by adding noise into training data after every epoch.\n",
    "\n",
    "Pytorch's torchvision module provides a few built-in data augmentation techniques, which we can use on image datasets. Some of the techniques we most frequently use are:\n",
    "\n",
    "\n",
    "*   Random Crop\n",
    "*   Random Rotate\n",
    "*   Vertical Flip\n",
    "*   Horizontal Flip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@markdown ####  Data Loader without Data Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "\n",
    "#Splitting dataset\n",
    "img_train_data, img_val_data,_ = torch.utils.data.random_split(img_dataset, [250,100,14280])\n",
    "\n",
    "#Creating train_loader and Val_loader\n",
    "train_loader = torch.utils.data.DataLoader(img_train_data,batch_size=batch_size,worker_init_fn=seed_worker)\n",
    "val_loader = torch.utils.data.DataLoader(img_val_data,batch_size=1000,worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a DataLoader using [torchvision.transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) which randomly augments the data for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Augmentation using transforms\n",
    "new_transforms = transforms.Compose([\n",
    "                                     transforms.RandomHorizontalFlip(p=0.1),\n",
    "                                     transforms.RandomVerticalFlip(p=0.1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                          (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=new_transforms)\n",
    "#Splitting dataset\n",
    "new_train_data, _,_ = torch.utils.data.random_split(img_dataset,\n",
    "                                                    [250, 100, 14280])\n",
    "\n",
    "#Creating train_loader and Val_loader\n",
    "new_train_loader = torch.utils.data.DataLoader(new_train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "61e0b4d32d7c4384b9b0ec16e9b5016f",
      "f1f64713d40e49a2b0e3b647d2fc78f2",
      "d2cbcf9d92094da29d10b3d41b1a1392",
      "6c5e9ca10dfc4c1bb33993d563a25a86",
      "d05081ff94c84f0cbdd156e53e6769fa",
      "74fe360b5e944fa7ad714fa76c9dede5",
      "bc32c1df9fa14804bcdb1177ad02ea09",
      "e38c0a7cfce44c28a1da43144e768cb7",
      "ca70fae424ee415caab207330e688c1d",
      "e1c3042cf41d49e38ef8b9c80b56dbe5",
      "030729a15f3a4e6cbb31eff47ba55c97",
      "9d2bdbbbf4b548328353a481ec3ed61c",
      "ed3304771ed7446f8a8b845b2af0f7f1",
      "f9dd4c8cfe4744e294b3d18a062cea6d",
      "1d439ab83ca848c1b5d2074540ec2a79",
      "5ebb7fc129384807b30c20d68cf843f8"
     ]
    },
    "outputId": "0bce36cb-55ae-48ce-e20d-cd5746efafa9"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 250,\n",
    "    'lr': 1e-3,\n",
    "    'momentum': 0.99,\n",
    "    'no_cuda': False,\n",
    "}\n",
    "\n",
    "\n",
    "acc_dict = {}\n",
    "model = AnimalNet()\n",
    "\n",
    "val_acc_dataaug, train_acc_dataaug, param_norm_datadug, _ ,_ = main(args,\n",
    "                                                                    model,\n",
    "                                                                    new_train_loader,\n",
    "                                                                    val_loader,\n",
    "                                                                    img_test_dataset)\n",
    "model = AnimalNet()\n",
    "val_acc_pure, train_acc_pure, param_norm_pure, _, _ = main(args,\n",
    "                                                           model,\n",
    "                                                           train_loader,\n",
    "                                                           val_loader,\n",
    "                                                           img_test_dataset)\n",
    "\n",
    "\n",
    "##Train and Test accuracy plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(val_acc_pure, label='Val Accuracy Pure',\n",
    "         c='red', ls='dashed')\n",
    "plt.plot(train_acc_pure, label='Train Accuracy Pure',\n",
    "         c='red', ls='solid')\n",
    "plt.plot(val_acc_dataaug, label='Val Accuracy data augment',\n",
    "         c='blue', ls='dashed')\n",
    "plt.plot(train_acc_dataaug, label='Train Accuracy data augment',\n",
    "         c='blue', ls='solid')\n",
    "plt.axhline(y=max(val_acc_pure), c='red', ls='dashed')\n",
    "plt.axhline(y=max(val_acc_dataaug), c='blue', ls='dashed')\n",
    "plt.title('Data Augmentation')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "outputId": "7eb04955-bf57-4cb8-a941-142ef50272ac"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(param_norm_pure, c='red', label='Without Augmentation')\n",
    "plt.plot(param_norm_datadug, c='blue', label='With Augmentation')\n",
    "plt.title('Norm of parameters as a function of training epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Norm of model parameters')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of more ways of augmenting training data? (Think of other problems beyond object recogition.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think! 3.1: Thought Question\n",
    "Why does it work better to regularize an overparameterized ANN than to start with a smaller one? Think about  the regularization  methods you know.\n",
    "Each group has a 10 min discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "96912fafae77493abd4d829412de3f83",
      "12a685ebe559438eb0c4debbda4fb0bd",
      "0b0710b5feed4267a166c4ef4e692591",
      "6584a6f5ede4454baf2040b777cbd7ed",
      "78bf48630b96459f8c07715257eef2b2",
      "32e67e6a647745da89ef48eb83147dd0"
     ]
    },
    "outputId": "0a869f71-fe4b-490f-c2bd-83da76d7e220"
   },
   "outputs": [],
   "source": [
    "#@title Video 4: SGD\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"rjzlFvJhNqE\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.1: Learning Rate\n",
    "In this section, we will see how learning rate can act as regularizer while training a neural network. In summary:\n",
    "\n",
    "\n",
    "*   Smaller learning rates regularize less. They slowly converge to deep minima. \n",
    "*   Larger learning rates regularizes more by missing local minima and converging to broader, flatter minima, which often generalize better.\n",
    "\n",
    "But beware, a very large learning rate may result in overshooting or finding a really bad local minimum.\n",
    "\n",
    "\n",
    "\n",
    "In the block below, we will train the Animal Net model with different learning rates and see how that affects the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6fcd6bb9-db72-4342-ca0c-9767fa1c1d37"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Generating Data Loaders\n",
    "batch_size = 128\n",
    "train_transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     ])\n",
    "\n",
    "data_path = pathlib.Path('.')/'afhq' # using pathlib to be compatible with all OS's\n",
    "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
    "img_train_data, img_val_data, = torch.utils.data.random_split(img_dataset, [11700,2930])\n",
    "\n",
    "full_train_loader = torch.utils.data.DataLoader(img_train_data,\n",
    "                                                batch_size=batch_size,\n",
    "                                                num_workers=2,\n",
    "                                                worker_init_fn=seed_worker,\n",
    "                                                generator=g)\n",
    "full_val_loader = torch.utils.data.DataLoader(img_val_data,\n",
    "                                              batch_size=1000,\n",
    "                                              num_workers=4,\n",
    "                                              worker_init_fn=seed_worker,\n",
    "                                              generator=g)\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    # [TO-DO]\n",
    "     ])\n",
    "img_test_dataset = ImageFolder(data_path/'val', transform=test_transform)\n",
    "# img_test_loader = DataLoader(img_test_dataset, batch_size=batch_size,shuffle=False, num_workers=1)\n",
    "classes = ('cat', 'dog', 'wild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "2650bdbb9b764a63bf4bbd12de243c24",
      "2188ecd2ef244c0eafbfef51a2ea0f5b",
      "aaec167fa09f4d39bf49e284d8f903b6",
      "b4e9f103256944e2a7269ebdb676872d",
      "384bd24f3da0415e99d378db097b1ce7",
      "79762a2a5ae74a02959354fefe4b33a5",
      "2a5861558cfd4ed1ac29b950d7dea983",
      "be8c115843334dd7997c96712b758a44",
      "71e566778dcc48a3880b01434fc154a3",
      "5348a85364994870afb131cd4e7e5982",
      "e59c5611473741ee8747cb44b2664af8",
      "c030f4dfcd3b4e55b5abc68444106925",
      "040d95b819e14178b661d0d4bcd6fa86",
      "da141fb3b3a54eeaa5a3b77c7e439d3e",
      "746af2df64104b768c97f75684a735fd",
      "0a3605e5688641bc9d345130416a2f12",
      "b8d77f41ac144c6988cdb11bba2937a7",
      "2b3c1c69d5be49c4a69fc480db752325",
      "ca99327706014cf1b8856e22c1707d2d",
      "b510dfc97f5a454e980daa6b5bb90503",
      "7474792caf3c44138045be6b261d6f27",
      "3fb80de2c72a4a93ac355802849e3644",
      "aaf35dad74bc4c9f831b3a5def0681dd",
      "c2d05144f3e94020a93c89203d183295"
     ]
    },
    "outputId": "9ee3236e-b951-4078-d742-f56bb693bea9"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'test_batch_size': 1000,\n",
    "    'epochs': 350,\n",
    "    'batch_size': 32,\n",
    "    'momentum': 0.99,\n",
    "    'no_cuda': False\n",
    "}\n",
    "\n",
    "lr = [5e-4, 1e-3, 5e-3]\n",
    "acc_dict = {}\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    model = AnimalNet()\n",
    "    args['lr'] = lr[i]\n",
    "    val_acc, train_acc, param_norm,_,_ = main(args,\n",
    "                                              model,\n",
    "                                              train_loader,\n",
    "                                              val_loader,\n",
    "                                              img_test_dataset)\n",
    "    acc_dict['val_'+str(i)] = val_acc\n",
    "    acc_dict['train_'+str(i)] = train_acc\n",
    "    acc_dict['param_norm'+str(i)] = param_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "outputId": "3289643a-c7f5-46ed-d774-dfa209bc8483"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Plot Train and Validation accuracy (Run me)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(acc_dict['val_0'], linestyle='dashed',label='lr = 5e-4 - validation', c = 'blue')\n",
    "plt.plot(acc_dict['train_0'],label = '5e-4 - train', c = 'blue')\n",
    "plt.plot(acc_dict['val_1'], linestyle='dashed',label='lr = 1e-3 - validation', c = 'green')\n",
    "plt.plot(acc_dict['train_1'],label='1e-3 - train', c = 'green')\n",
    "plt.plot(acc_dict['val_2'], linestyle='dashed',label='lr = 5e-3 - validation', c = 'purple')\n",
    "plt.plot(acc_dict['train_2'],label = '5e-3 - train', c = 'purple')\n",
    "plt.title('Optimal Learning Rate')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "print('Maximum Test Accuracy obtained with lr = 5e-4: '+str(max(acc_dict['val_0'])))\n",
    "print('Maximum Test Accuracy obtained with lr = 1e-3: '+str(max(acc_dict['val_1'])))\n",
    "print('Maximum Test Accuracy obtained with lr = 5e-3: '+str(max(acc_dict['val_2'])))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "outputId": "65185ee5-bb4d-4900-c90b-6f3302d71737"
   },
   "outputs": [],
   "source": [
    "#@markdown #### Plot parametric norms (Run me)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(acc_dict['param_norm0'],label='lr = 5e-4',c='blue')\n",
    "plt.plot(acc_dict['param_norm1'],label = 'lr = 1e-3',c='green')\n",
    "plt.plot(acc_dict['param_norm2'],label ='lr = 5e-3', c='red')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('parameter norms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model above, we observe something different from what we expected. Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "67e664aaca3c40bbbe36ef874f95f38f",
      "6b048d1ebf334342883eeca17232f0b0",
      "2ee7b2749a6b4df6b72b45ed343d6071",
      "6a43a2bb241d43568fce0cb1ea0cc1bf",
      "468772ac64964cad98c18c53f981c801",
      "e1d99ffd621a4cf3975a57e132690823"
     ]
    },
    "outputId": "4666cdbc-e4fe-42d2-c758-646d45241adf"
   },
   "outputs": [],
   "source": [
    "#@title Video 5: Hyperparameter tuning\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"HgkiKRYc-3A\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hyper-Parameter tuning is often difficult and time consuming.  It is a key part of training any Deep Learning model to give good generalization. There are a few techniques that we can use to guide us during the search. \n",
    "\n",
    "\n",
    "\n",
    "*   Grid Search: Try all possible combinations of hyperparameters\n",
    "*   Random Search: Randomly try different combinations of hyperparameters\n",
    "*   Coordinate-wise Gradient Descent: Start at one set of hyperparameters and try changing one at a time, accept any changes that reduce your validation error\n",
    "*   Bayesian Optimization/ Auto ML:  Start from a set of hyperparameters that have worked well on a similar problem, and then do some sort of local exploration (e.g. gradient descent) from there.\n",
    "\n",
    "There are lots of choices, like what range to explore over, which parameter to optimize first, etc. Some hyperparameters don’t matter much (people use a dropout of either 0.5 or 0, but not much else).  Others can matter a lot more (e.g. size and depth of the neural net). The key is to see what worked on similar problems.\n",
    "\n",
    "One can automate the process of tuning the network Architecture using \"Neural Architecture Search\", which designs new architectures using a few building blocks (Linear, Convolutional, Convolution Layers, etc.) and optimizes the design based on performance using a wide range of techniques such as Grid Search, Reinforcement Learning, GD, Evolutionary Algorithms, etc. This obviously requires very high computer power. Read this [article](https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html) to learn more about NAS.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which regularization technique today do you think had the biggest effect on the network? Why might do you think so? Can you apply all of the regularization methods on the same network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Adversarial  Attacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "710cb9104be0424c89606a2a6b8a77ae",
      "aa66060fb34f4f5aa05a1ee9d253c1f6",
      "5875769e83bb4eb1a3dc9da247f64176",
      "afa0479039144256aca52f8af1924810",
      "28ea126a99284b26ab344ff7cd6feac4",
      "52b7bf2ecbf34134a179d71a6f8473c3"
     ]
    },
    "outputId": "886a235a-1e96-4d8d-8cfa-ac17eee510d0"
   },
   "outputs": [],
   "source": [
    "#@title Video 6: Adversarial Attacks\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"LzPPoiKi5jE\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing perturbations to the input data to trick a machine learning model is called an \"adversarial attack\". These attacks are an inevitable consequence of learning in high dimensional space with complex decision boundaries. Depending on the application, these attacks can be very dangerous.\n",
    "\n",
    "![Adversarial Examples of a Stop Sign](https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs13638-020-01775-5/MediaObjects/13638_2020_1775_Fig1_HTML.png?as=webp)\n",
    "\n",
    "Hence, it is important for us to build models which can defend against such attcks. One possible way to do it is by regularizing the networks, which smooths the decision boundaries. A few ways of building models robust to such attachs are:\n",
    "\n",
    "\n",
    "\n",
    "*   [Defensive Distillation](https://deepai.org/machine-learning-glossary-and-terms/defensive-distillation) : Models trained via distillation are less prone to such attacks as they are trained on soft labels as there is an element of randomness in the training process.\n",
    "*   [Feature Squeezing](https://evademl.org/squeezing/): Identifies adversarial attacks for on-line classifiers whose model is being used by comparing model's perdiction before and after squeezing the input. \n",
    "* [SGD](https://arxiv.org/abs/1706.06083) You can also pick weight to minimize what the adversary is trying to maximize via SGD.\n",
    "\n",
    "In the optional supplemental project, you can design an attack and defend your model against it using regularization techniques you learned this week. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Optional Supplements\n",
    "\n",
    "1.   [Understanding Generalization](https://docs.google.com/document/d/1XOaTXYBleQlDNFM1-t512RHfJXRwA4-LIejuBA6pbLY/edit)\n",
    "2.   [Adversarial Attacks](https://)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W1D5_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
