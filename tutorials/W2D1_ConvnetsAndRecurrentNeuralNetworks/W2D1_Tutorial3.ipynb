{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/W2D1_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 3: Introduction to RNNs\n",
    "**Week 2, Day 1: Convnets And Recurrent Neural Networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Dawn McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe\n",
    "\n",
    "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva\n",
    "\n",
    "__Production editors:__ Anmol Gupta, Spiros Chavlis \n",
    "\n",
    "*Based on material from:* Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "At the end of this tutorial, we will be able to:\n",
    "- Understand the structure of a Recurrent Neural Network (RNN)\n",
    "- Build a simple RNN model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in the tutorial\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/a95k2/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install livelossplot --quiet\n",
    "!pip install opencv-python --quiet\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import sleep\n",
    "from IPython.display import HTML\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "import unidecode\n",
    "import string\n",
    "\n",
    "# Reading and un-unicode-encoding data\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "  file = unidecode.unidecode(open(filename).read())\n",
    "  return file, len(file)\n",
    "\n",
    "\n",
    "# Turning a string into a tensor\n",
    "def char_tensor(string):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "    try:\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "    except:\n",
    "      continue\n",
    "  return tensor\n",
    "\n",
    "\n",
    "# Readable time elapsed\n",
    "def time_since(since):\n",
    "  s = time.time() - since\n",
    "  m = math.floor(s / 60)\n",
    "  s -= m * 60\n",
    "  return '%dm %ds' % (m, s)\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8,\n",
    "             cuda=False):\n",
    "\n",
    "  hidden = decoder.init_hidden(1)\n",
    "  prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "\n",
    "  if cuda:\n",
    "    hidden = hidden.cuda()\n",
    "    prime_input = prime_input.cuda()\n",
    "  predicted = prime_str\n",
    "\n",
    "  # Use priming string to \"build up\" hidden state\n",
    "  for p in range(len(prime_str) - 1):\n",
    "    _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "  inp = prime_input[:,-1]\n",
    "\n",
    "  for p in range(predict_len):\n",
    "    output, hidden = decoder(inp, hidden)\n",
    "\n",
    "    # Sample from the network as a multinomial distribution\n",
    "    output_dist = output.data.view(-1).div(temperature).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "    # Add predicted character to string and use as next input\n",
    "    predicted_char = all_characters[top_i]\n",
    "    predicted += predicted_char\n",
    "    inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "    if cuda:\n",
    "      inp = inp.cuda()\n",
    "\n",
    "  return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#@title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: RNNs\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1L44y1m7PP\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"PsZjS125lLs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "RNNs are compact models that operate over timeseries, and have the ability to remember past input. They also save parameters by using the same weights at every time step.  If you've heard of Transformers, those models dont' have this kind of temporal weight sharing, and so they are *much* larger.\n",
    "\n",
    "The code below is adapted from https://github.com/spro/char-rnn.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Run Me to get the data\n",
    "!wget --output-document=/content/sample_data/twain.txt https://raw.githubusercontent.com/amfyshe/amfyshe.github.io/master/twain.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "class CharRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
    "    super(CharRNN, self).__init__()\n",
    "    self.model = model.lower()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "    if self.model == \"gru\":\n",
    "      self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"lstm\":\n",
    "      self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"rnn\":\n",
    "      self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "    self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    batch_size = input.size(0)\n",
    "    encoded = self.encoder(input)\n",
    "    output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "    output = self.decoder(output.view(batch_size, -1))\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    if self.model == \"lstm\":\n",
    "      return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "              Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "    return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This next section of code takes care of training the RNN on several of Mark Twain's books.  In this short section, we won't dive into the code, but you'll get to learn a lot more about RNNs in a few days!  For now, we are just going to observe the training process.\n",
    "\n",
    "One cool thing about RNNs is that they can be used to _generate_ language based on what the network sees during training.  As the network makes predictions, instead of confirming of those predictions are correct against some training text, we just feed them back into the model as the next observed token.  Starting from a random vector for the hidden state, we can generate many original sentences!  And what the network generates will reflect the text it was trained on.\n",
    "\n",
    "Let's try it!  Run the code below.  As the network trains, it will output samples of generated text every 25 epochs.  Notice that as the training progresses, the model learns to spell short words, then learns to string some words together, and eventually can produce meaningful sentences (sometimes)!  Keep in mind that this is a relatively small network, and doesn't employ some of the cool things you'll learn about later in the week (e.g. LSTMs, though you can change that in the code below by changing the value of the `model` variable if you wish!)\n",
    "\n",
    "After running the model, and observing the output, get together with your pod, and talk about what you noticed during training.  Did your network produce anything interesting?  Did it produce anything characteristic of Twain?  \n",
    "\n",
    "**Note**: training for the full 2000 epochs is likely to take a while, so you may need to stop it before it finishes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "batch_size = 50\n",
    "chunk_len = 200\n",
    "model = \"rnn\" # other options: lstm, gru\n",
    "\n",
    "# hyperparams\n",
    "n_layers = 2\n",
    "hidden_size = 200\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "print_every = 25\n",
    "\n",
    "def train(inp, target):\n",
    "  hidden = decoder.init_hidden(batch_size)\n",
    "  decoder.zero_grad()\n",
    "  loss = 0\n",
    "\n",
    "  for c in range(chunk_len):\n",
    "    output, hidden = decoder(inp[:,c], hidden)\n",
    "    loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "  return loss.item() / chunk_len\n",
    "\n",
    "\n",
    "file, file_len = read_file('/content/sample_data/twain.txt')\n",
    "\n",
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "  inp = torch.LongTensor(batch_size, chunk_len)\n",
    "  target = torch.LongTensor(batch_size, chunk_len)\n",
    "  for bi in range(batch_size):\n",
    "    start_index = random.randint(0, file_len - chunk_len - 1)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    chunk = file[start_index:end_index]\n",
    "    inp[bi] = char_tensor(chunk[:-1])\n",
    "    target[bi] = char_tensor(chunk[1:])\n",
    "  inp = Variable(inp)\n",
    "  target = Variable(target)\n",
    "  return inp, target\n",
    "\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    hidden_size,\n",
    "    n_characters,\n",
    "    model=model,\n",
    "    n_layers=n_layers,\n",
    "    )\n",
    "\n",
    "decoder_optimizer = torch.optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in tqdm(range(1, n_epochs + 1), position=0, leave=True):\n",
    "  loss = train(*random_training_set(chunk_len, batch_size))\n",
    "  loss_avg += loss\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "    print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch,\\\n",
    "                                   epoch / n_epochs * 100, loss))\n",
    "    print(generate(decoder, 'Wh', 100), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Power consumption in Deep Learning\n",
    "\n",
    "Training NN models can be incredibly costly, both in actual money but also in power consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Carbon Footprint of AI\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1My4y1j7HJ\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"as6C334LmRs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Take a few moments to chat with your pod about the following points:\n",
    "* Which societal costs of training do you find most compelling?\n",
    "* When is training an AI model worth the cost?  Who should make that decision?\n",
    "* Should there be additional taxes on energy costs for compute centers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "What a day!  We've learned a lot!  The basics of CNNs and RNNs, and how changes to architecture that allow models to parameter share can greatly reduce the size of the model.  We learned about convolution and pooling, as well as the basic idea behind RNNs.  To wrap up we thought about the impact of training large NN models."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W2D1_Tutorial3",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
