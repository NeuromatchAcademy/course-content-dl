{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/W2D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Introduction to RNNs\n",
    "\n",
    "**Week 2, Day 1: Convnets And Recurrent Neural Networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Dawn McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe\n",
    "\n",
    "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva, Nina Kudryashova, Kelson Shilling-Scrivo\n",
    "\n",
    "__Content editors:__ Nina Kudryashova\n",
    "\n",
    "__Production editors:__ Anmol Gupta, Spiros Chavlis \n",
    "\n",
    "*Based on material from:* Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "At the end of this tutorial, we will be able to:\n",
    "- Understand the structure of a Recurrent Neural Network (RNN)\n",
    "- Build a simple RNN model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in this tutorial\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/5asx2/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install livelossplot --quiet\n",
    "!pip install unidecode\n",
    "\n",
    "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
    "from evaltools.airtable import AirtableForm\n",
    "\n",
    "# generate airtable form\n",
    "atform = AirtableForm('appn7VdPRseSoMXEG','W2D1_T2','https://portal.neuromatchacademy.org/api/redirect/to/351ca652-13d8-4e31-be28-30153d03e639')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "def read_file(filename):\n",
    "  file = unidecode.unidecode(open(filename).read())\n",
    "  return file, len(file)\n",
    "\n",
    "\n",
    "# Turning a string into a tensor\n",
    "def char_tensor(string):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "    try:\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "    except:\n",
    "      continue\n",
    "  return tensor\n",
    "\n",
    "\n",
    "# Readable time elapsed\n",
    "def time_since(since):\n",
    "  s = time.time() - since\n",
    "  m = math.floor(s / 60)\n",
    "  s -= m * 60\n",
    "  out = f\"{m}min {s}sec\"\n",
    "  return out\n",
    "\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8,\n",
    "             device='cpu'):\n",
    "\n",
    "  hidden = decoder.init_hidden(1)\n",
    "  prime_input = char_tensor(prime_str).unsqueeze(0)\n",
    "\n",
    "  hidden = hidden.to(device)\n",
    "  prime_input = prime_input.to(device)\n",
    "  predicted = prime_str\n",
    "\n",
    "  # Use priming string to \"build up\" hidden state\n",
    "  for p in range(len(prime_str) - 1):\n",
    "    _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "  inp = prime_input[:,-1]\n",
    "\n",
    "  for p in range(predict_len):\n",
    "    output, hidden = decoder(inp, hidden)\n",
    "\n",
    "    # Sample from the network as a multinomial distribution\n",
    "    output_dist = output.data.view(-1).div(temperature).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "    # Add predicted character to string and use as next input\n",
    "    predicted_char = all_characters[top_i]\n",
    "    predicted += predicted_char\n",
    "    inp = char_tensor(predicted_char).unsqueeze(0)\n",
    "    inp = inp.to(device)\n",
    "\n",
    "  return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#@title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: RNNs\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1L44y1m7PP\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"PsZjS125lLs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# add event to airtable\n",
    "atform.add_event('Video 1: RNNs')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "RNNs are compact models that operate over timeseries, and have the ability to remember past input. They also save parameters by using the same weights at every time step.  If you've heard of Transformers, those models don't have this kind of temporal weight sharing, and so they are *much* larger.\n",
    "\n",
    "The code below is adapted from [this github repository](https://github.com/spro/char-rnn.pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "class CharRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size,\n",
    "               model=\"gru\", n_layers=1):\n",
    "    \"\"\"\n",
    "    input_size: int\n",
    "      Size of the input layer.\n",
    "    hidden_size: int\n",
    "      Size of the hidden layers.\n",
    "    output_size: int\n",
    "      Size of the output layer.\n",
    "    model: string\n",
    "      `model` can take the values \"gru\", \"rnn\", \"lstm\". Default is \"gru\".\n",
    "    n_layers: int\n",
    "      Number of layers\n",
    "    \"\"\"\n",
    "    super(CharRNN, self).__init__()\n",
    "    self.model = model.lower()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "    if self.model == \"gru\":\n",
    "      self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"lstm\":\n",
    "      self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"rnn\":\n",
    "      self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "    self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    batch_size = input.size(0)\n",
    "    encoded = self.encoder(input)\n",
    "    output, hidden = self.rnn(encoded.reshape(1, batch_size, -1), hidden)\n",
    "    output = self.decoder(output.reshape(batch_size, -1))\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    if self.model == \"lstm\":\n",
    "      return (torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "\n",
    "    return torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This next section of code takes care of training the RNN on several of Mark Twain's books. In this short section, we won't dive into the code, but you'll get to learn a lot more about RNNs in a few days! For now, we are just going to observe the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Run Me to get the data\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/static/twain.txt'\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open('twain.txt', 'wb') as fd:\n",
    "  fd.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "One cool thing about RNNs is that they can be used to _generate_ language based on what the network sees during training. As the network makes predictions, instead of confirming of those predictions are correct against some training text, we just feed them back into the model as the next observed token.  Starting from a random vector for the hidden state, we can generate many original sentences! And what the network generates will reflect the text it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "def random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                        device='cpu', seed=0):\n",
    "  random.seed(seed)\n",
    "\n",
    "  inp = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "  target = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "\n",
    "  for bi in range(batch_size):\n",
    "    start_index = random.randint(0, file_len - chunk_len - 1)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    chunk = file[start_index:end_index]\n",
    "    inp[bi] = char_tensor(chunk[:-1])\n",
    "    target[bi] = char_tensor(chunk[1:])\n",
    "\n",
    "  return inp, target, chunk_len, batch_size, device\n",
    "\n",
    "\n",
    "def train(decoder, criterion, inp, target, chunk_len, batch_size, device):\n",
    "  hidden = decoder.init_hidden(batch_size)\n",
    "  decoder.zero_grad()\n",
    "  loss = 0\n",
    "\n",
    "  for c in range(chunk_len):\n",
    "    output, hidden = decoder(inp[:, c].to(device), hidden.to(device))\n",
    "    loss += criterion(output.reshape(batch_size, -1), target[:,c])\n",
    "\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "  return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "First, let's load the text file, and define the model and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Reading and un-unicode-encoding data\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# load the text file\n",
    "file, file_len = read_file('twain.txt')\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 50\n",
    "chunk_len = 200\n",
    "model = \"rnn\"  # other options: `lstm`, `gru`\n",
    "\n",
    "n_layers = 2\n",
    "hidden_size = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define the model, optimizer, and the loss criterion\n",
    "decoder = CharRNN(n_characters, hidden_size, n_characters,\n",
    "                  model=model, n_layers=n_layers)\n",
    "decoder.to(DEVICE)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's try it! Run the code below. As the network trains, it will output samples of generated text every 25 epochs. Notice that as the training progresses, the model learns to spell short words, then learns to string some words together, and eventually can produce meaningful sentences (sometimes)! Keep in mind that this is a relatively small network, and doesn't employ some of the cool things you'll learn about later in the week (e.g., LSTMs, though you can change that in the code below by changing the value of the `model` variable if you wish!)\n",
    "\n",
    "After running the model, and observing the output, get together with your pod, and talk about what you noticed during training. Did your network produce anything interesting? Did it produce anything characteristic of Twain?  \n",
    "\n",
    "**Note:** training for the full 2000 epochs is likely to take a while, so you may need to stop it before it finishes. If you have time left, set `n_epochs` to 2000 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000   # initial was set to 2000\n",
    "\n",
    "print_every = 25  # frequency of printing the outputs\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "print(f\"Training for {n_epochs} epochs...\\n\")\n",
    "for epoch in tqdm(range(1, n_epochs + 1), position=0, leave=True):\n",
    "  loss = train(decoder, criterion,\n",
    "               *random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                                    device=DEVICE, seed=epoch))\n",
    "  loss_avg += loss\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "    print(f\"[{time_since(start)} {epoch/n_epochs * 100}%) {loss:.4f}]\")\n",
    "    print(f\"{generate(decoder, prime_str='Wh', predict_len=100, device=DEVICE)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now you can generate more examples using a trained model. Recall that `generate` takes the mentioned below arguments to work:\n",
    "\n",
    "```python\n",
    "generate(decoder, prime_str='A', predict_len=100, temperature=0.8, device='cpu')\n",
    "```\n",
    "\n",
    "Try it by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "print(f\"{generate(decoder, prime_str='Wh', predict_len=100, device=DEVICE)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Power consumption in Deep Learning\n",
    "\n",
    "Training NN models can be incredibly costly, both in actual money but also in power consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Carbon Footprint of AI\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1My4y1j7HJ\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"as6C334LmRs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# add event to airtable\n",
    "atform.add_event('Video 2: Carbon Footprint of AI')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Take a few moments to chat with your pod about the following points:\n",
    "* Which societal costs of training do you find most compelling?\n",
    "* When is training an AI model worth the cost?  Who should make that decision?\n",
    "* Should there be additional taxes on energy costs for compute centers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Exercise 2: Calculate the carbon footprint that your pod generated today.\n",
    "You can use this [online calculator](https://mlco2.github.io/impact/#compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "What a day!  We've learned a lot!  The basics of CNNs and RNNs, and how changes to architecture that allow models to parameter share can greatly reduce the size of the model.  We learned about convolution and pooling, as well as the basic idea behind RNNs.  To wrap up we thought about the impact of training large NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Airtable Submission Link\n",
    "from IPython import display as IPydisplay\n",
    "IPydisplay.HTML(\n",
    "   f\"\"\"\n",
    " <div>\n",
    "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
    "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
    " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
    "   </div>\"\"\" )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W2D1_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
