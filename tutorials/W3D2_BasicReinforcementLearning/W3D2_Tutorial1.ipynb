{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "W3D2_Tutorial1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a11859f704fe48a3bfb5e16e3dd11c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc9d1629df3a4cdd80e0b76ac4a98a4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_030000630dfa4ea78227009c9dca0e21",
              "IPY_MODEL_66cbcd695c994568b7255430aeaf007f"
            ]
          }
        },
        "bc9d1629df3a4cdd80e0b76ac4a98a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "030000630dfa4ea78227009c9dca0e21": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=BWz3scQN50M\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/BWz3scQN50M?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f29fc8190>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_f9a160a9fb6d47e6b9334bbab55a057b",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "66cbcd695c994568b7255430aeaf007f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV18V411p7iK\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV18V411p7iK&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f2a01ef90>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_9a387a69da0c44f2a0d8adf2a596830b",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "f9a160a9fb6d47e6b9334bbab55a057b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a387a69da0c44f2a0d8adf2a596830b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e1484224fb14ac9939c6439f3e4aad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac663fc3a25840559d25d3ad347a8c1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a42549d21f9b4485b6eb6dae1adce9bd",
              "IPY_MODEL_838348de4afd46b5b79bf30b169b7027"
            ]
          }
        },
        "ac663fc3a25840559d25d3ad347a8c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a42549d21f9b4485b6eb6dae1adce9bd": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=h6TxAALY5Fc\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/h6TxAALY5Fc?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f2a0f5290>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_2c05237b9eba48f1bc29cb574142a240",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "838348de4afd46b5b79bf30b169b7027": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1k54y1E7Zn\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1k54y1E7Zn&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f2a0f5890>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_2f27f3bf95a54755ad7a879c133247af",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "2c05237b9eba48f1bc29cb574142a240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f27f3bf95a54755ad7a879c133247af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6d0aaebd52b4c768f942dc819b6cf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33139b1fc28c404ab1c0e5b3364c94c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7b2612127534df5bb648e3e9a902cea",
              "IPY_MODEL_fa9b677c832f4b06831b70a838ca47f3"
            ]
          }
        },
        "33139b1fc28c404ab1c0e5b3364c94c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7b2612127534df5bb648e3e9a902cea": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=cLCoNBmYUns\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/cLCoNBmYUns?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f2a1b1910>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_336a9f475719417abfbcc878f7cd3d63",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "fa9b677c832f4b06831b70a838ca47f3": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1Lv411E7CB\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1Lv411E7CB&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f2a12a810>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_8126febbc65f445d80c003114aacd82c",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "336a9f475719417abfbcc878f7cd3d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8126febbc65f445d80c003114aacd82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec7d8e59ec1b4e3997be73c73f23e07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f3e74468ea04940947aa23d35df0f62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee2c43bee8ae45b991070da90642b78a",
              "IPY_MODEL_b900d95177c5456cb11779b6595695fe"
            ]
          }
        },
        "6f3e74468ea04940947aa23d35df0f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee2c43bee8ae45b991070da90642b78a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=HAxR4SuaZs4\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/HAxR4SuaZs4?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f2108aa10>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_565fb67ce4324c83a9d48546703eada4",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "b900d95177c5456cb11779b6595695fe": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV15f4y157zA\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV15f4y157zA&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f2108a290>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_9090b6b4b95d449881fb11e97efabbdd",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "565fb67ce4324c83a9d48546703eada4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9090b6b4b95d449881fb11e97efabbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a344b026c8e445f9a14ace7210c76f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f3281569bc64259b42df2267a751573",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ce1a49aa4a944b99b380e62cfd56b42",
              "IPY_MODEL_15653d47eae44707a9ac64c80671c872"
            ]
          }
        },
        "2f3281569bc64259b42df2267a751573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ce1a49aa4a944b99b380e62cfd56b42": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=Y4TweUYnexU\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/Y4TweUYnexU?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f20ba2190>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_0fd5189873c74a91abc7a990b09e2d4d",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "15653d47eae44707a9ac64c80671c872": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1iU4y1n7M6\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1iU4y1n7M6&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f20ba2290>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_e9fca183305b4e0eb79ea5b279c06019",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "0fd5189873c74a91abc7a990b09e2d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9fca183305b4e0eb79ea5b279c06019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fbc379b9fe54250a2b1b30c82dbcc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60911565deb6479497fcb2074c06beae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d105442c65614eaaad3ca7b0458d6005",
              "IPY_MODEL_9de2efc1133e4bbfa035a29d3f1a28ef"
            ]
          }
        },
        "60911565deb6479497fcb2074c06beae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d105442c65614eaaad3ca7b0458d6005": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=7_MYePyYhrM\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/7_MYePyYhrM?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f203d6090>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_3938eb5b459b4a179b8392cefd4bc503",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "9de2efc1133e4bbfa035a29d3f1a28ef": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1sg411M7cn\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1sg411M7cn&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f2077e250>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_1bfd2e94148846bd9ac7f8c7ff060559",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "3938eb5b459b4a179b8392cefd4bc503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bfd2e94148846bd9ac7f8c7ff060559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f952fc40591425b8def52b0dd6133f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dc2c8dcb9d64fc59cd89a3403dcf339",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f65aa76f7d8949198e5b57fe6675c7b4",
              "IPY_MODEL_7ce3a4bc948e4f3fab5dc8b92799e834"
            ]
          }
        },
        "5dc2c8dcb9d64fc59cd89a3403dcf339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f65aa76f7d8949198e5b57fe6675c7b4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=HEDoNtV1y-w\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/HEDoNtV1y-w?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f0776f750>",
                "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhwaGRoeHRsfIi0lJCIiIjIvJSIuNy09MTIwMC01PVBFNThLOS0tRWFFS1NWW1xbOkJlbWRYbFBZW1cBERISGRYZLxsbMFc9OEBfV1dXV1dXX1dXV1dXV19XV11XV1dXXVddV1dXV1dXV1ddV1dXV11XV1ddV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAABAUBAwYCB//EAEMQAAIBAgMDCAYIBAYDAQEAAAECAAMRBBIhBTFREyJBU2GRktIUFRdxgbEGFjIzUnKh0SNCosE0Q2Ky4fAkc4LxY//EABoBAQEBAQEBAQAAAAAAAAAAAAABAgMEBQb/xAArEQEBAAIABQMDBAMBAQAAAAAAAQIRAxIhMVETFEEEImEyUpHBcaHwQjP/2gAMAwEAAhEDEQA/APn8REBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByETr/Zxjetw/ifyR7OMb1uH8T+SByES+xP0SxFJyrPSJHAtb/bNDfRysBfNTt7zp+kCoiXA+jdb8VPvP7T0n0Yrk/bpD3sf2k2KWJdfViv+Kl3n9o+rNf8VPvP7Rs0pYlx9W6/4qfef2nhtgVR/NT7z+0bhp9qiIlCJresimxdQeBInpHDC4II4gwPUTEQMxMRAzExEDMTEQMxMQTAzE1rXRjYOpPAET3AzExDMALk2HbAzETEDMTEzAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERA5naaXqtp0/2lbUSwJ4Ay1x5HKue3XulZjnCUnY7gpJI4WlGpKWgHZPdHAVK1E1UqqlzzFy3LdAJ4Xm4rqJvwtJEoqrMxF7ZTc6DWwC++crXTGbulLgsW3KmjWGWoN3bLI0ZA+kqIjoEWzn7JH8oBufnKw1nuCXbQ/iMbMpq6XlRBIVYDjLY0r7hORxWHKswI3Ej9ZEfXpiZmJ1Yc/VUHHYi+F9I5tPoTm6H8REmVcScPRSqKIpUVJ5WnYZkF/tDKbabyOBmyrs5+WerTrtTLhQRkUjm7t/vmxsAX5PlahqBDmsVADH+UkDh85nTrcpdIr4+vyVOoFQGtVVUVr81G3ZiD9rp/Ttnr02rQq5MQUqKab1FZEKkZLZlIJPHQ3mvF7NKU6dOkXyekKygD7oa3t/pB47t0k0tmk1DUrVOVbIUAyhVVTv0HSbC57I6n2oFPbLgJUapRYMVvRRTmUMQNGvqRe5047pKpYmtUqYgHkxSpOVtlJZ/4Ya172GrfHsm7DYGpTyqMQxpJuUqM1huUv0j4X7Zto4IIaxDE8s2Y9nNC6eGOqW4/CqpbTK0cLTVqVEvQVyxBKqLABVW/ad50t0zYdr1ORcqab1EqU0zAEI4dgL2vodSN51ElDZWVaPJVSlSinJhrAhlsNGXp3A9E2VcC1SlkqVSxzq+awH2WDWA4aR1W3HaOMZVo1yldkdDSeqCiFSuUi41Y3+1PeCfFVAlVmpBHAJp5TmUEXHPvqfhJNXBq9ZapP2abJl6CGIJ/2zRhdn1KWVRXY0k+yhUZrdCl+kDv7ZU3NK/12zI1ZKtEKLlaJU52Av8AzX0Y2000lzWcNRZhuKE/pItPZz07rSrslIknLlBK3NyFY7hfiDJ1VMyleII74iZWfDkaHJVMJh6NLDsMU1NClTk8tiALuH6QOzfftltW2oxq1EWtRpCkcv8AEUsXawJOjCw1tJZ2UvIUaQchqGXI9tQVFv1FwR2zL4B1qO9GtyfKEF1KhgTa2YcDYDiNN0mq3c8ajLtKrVOHFIIhrU3Zs4JylSo01F9SZH2hiahoYmhWyl6YpsGUWDKzaaEmxup6ZKxeFqHE4fK7jJTqA1LA68y2YbtbHhunv1RmSqKlQtUq5cz2A0U3AA6Bv7zHU3jNf98vG0cbUWoy061JMqgkGkz+IggIJ6we02d6JYBUr0Q6cQw1ZSenQ3HuM2ts9hVqPTq5BVsXXKDqBlup6NAOMg7QwP8A49DCU85dcgWoB9hRzWYtuBylhbtjqk5b0WOzMS1amapsFZjydvwDQE++xPuIkyeKdMIoVRZVAAHACe5pzvfoREQhERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQOY2g38Zx2/2lPtl74dh+Ky97Af3ljteqEr1LkDXpPZKDaOOpkIAwP8RCQNTYMCd3ulHQ42oiWLsFHaZX4b6Q0+WKFuRToqHW5v0joFpz2PxrVqrO19ToOA6BI+KospKsCGXeD0TMx6dV5tdlp9K6lM1KWSryjAEswPG1t0hU6oIy35wleQbbpgabr90XGdl5t9X0rCuuVTxUHvE5nbCWr1B237xeXX0dx3LYZTuZOaw924/EWlX9IVIxBPQVB+Y/tOVWPosRE7MEREBMSHtPFmiKdmRc9TKWqfZXms3Efht8Zqw21Ay84ZmzMByWocLa7Ds1A9+msCyiQX2tSW32yLIcyoSBnNl7zpaevWSWFg5csVyZedcanThYjXtHGBMiQ12nSKswJsqBzzTexJAsON1ItvvPS49C+XnasUDW5pYb1vx0PxFoEqJDq7QVKroysFRA+e2huSLDt0+MHaKDeHDZguTLzrkEjTgbHXdv4GBMiV/rillLHOFCO9yh3J9se8f/l5sO0aYzZg6lbc0qczZjZbDpuf+bQJkxInrKnoLPmL5MuU5g2XNY8NNb7prxe1AiVSFbPTpu4DAgNlGv8AaBYRNNfErTy3BJY2VVFyTa/ymmptKmu8PooZjkP8MHdm4bjAmTEiPtKmM2jnK4Q2Qm7HcBx39EyMembLZvtZM1ubm/Dfj0cL6b4EuJAp7TXk6burDOoYkA5Vvpv/AO26Yp7SBJBXIBUZCW6cqk3HdAnxIPrWlYkh15oYBkILKSBcDedSNN4uNJn1nT3WfPnyZMvOvlz+77Ov/MCbEi4vF8nTVwpOZkW1jfnG27ffWKO0Kbtk5ytzrhhaxWxIPRezA9ogSokU45BTSpqRUtkFtWuLjQ7tOM1ttNVdlZHVVpioWIPSSLW330gTokI7TpgG4cMCoyFDm532dBvBsdew8Jj1it8pDMxLAKqknm2vfh9oQJ0SA216IXOMzJyYqFlUkKpFwT77bptxWM5N6KZC3KvkuP5eaWv/AE/OBKiQxtJCgcLUKk6cw69uv/T0XmG2nTB0zEWUlgpygN9kk/8AbQJsSE+0VyVGUG1MNziDlupsRprv/wCJ5XaQL5SpQCqad26bIXuPD0wJ8SCNq0spY5wMucXQ3Zd11HTvGm/UTJ2km6zhs+TKVsxOXNp0Wtr/AMwJsTRWxGVFbdmZRzgQecQN3HWa6G0EqMFAcZs1iVIBymxsYEuJGq4xUcIwYXIGa3NudAL+/SeMTtKnSqpSbNnqC4CoSLAgEkjcBcamBMiVS/SHDFHfMwVUNS5QjOgNiy3HOGo7xxnitt5LWpq2cVaaMtRGQhXawYA9G/ugXEStqbcoqzqwqKUVm1psMwX7WXTW3y1kqjjadSoyIblVViQNAG1GvG2vdAkREQEREBERAxYcIsOEzEDFhwiw4TMQMWHCLDhMxAxaaMcP4NT8jfKSJox33NT8jfKBviIgIiIGjEYYVDTJ/wAt84HQeaVsfFIZ2MlksfuwypmVWCqSDlsRuFhaWcQITbNUgi5APJ7gB922YaAW1htn881Ecq+YtewIswAItw5oPwk2IEAbKT+Fzm/hkk7v4lzm52n4gG0tr2RQ2WiVC62tmL2KLcE3J51r2uSf720k+IELF7OWqzFmNnQKRYdDFlIv0gn3RS2cq5TcXVw3NRVBsCLae8ybECrxuys2HqIhJbk6yrewBNTXX4za+zsxLPVYvzcrWAyZTcaW113/ANpPiBDpYAK4qFyz5y5NgATkyWt0ACRzsVCrLnNilRNFF7PvJNtSJaRAj4nDZyjBirobqQL7xYgjpE0VdnZsw5V7VFC1NBz7aX3aEg20k+IEUYFeJ+85T48PdpNSbMRapcWsWz2KKSD2Na9r6+/p6JPiBWNsZSAM5tkVDdQTZSSCD0b9f7TadmqSczEqXZsv5lKkX4aydECuOys1uUqs5VQqkgAgZlY7hqSUW57OibK+zw+fnfeMGIZQy6KFtY+68mxAiPgb0Uph3GQqQ2hY5SCL3HTaRMXssumXMzM9QO9S4GUWCkAdqXXTje8togaMTh+UTJcAcCoZSOBB6JF9Urly52tkyHdfRsykcLE6dG6S8RXCDieE2I2YA8YEQbPu2d3LPdTewAst7C3vYn4z1SwKrU5QMb3c26OeVJ/2iS4gUdfZTpS5GiXytRWkWJWxyjKCbi4NuG/s3y0xOG5Q0mzFTSfOO3mlSD8GMkRAgNsxctNQ33alRcA3BtfQ9Om+ZTZqhCmZrFUXo/k3SdECuq7KDs7M556spsoBsbbyBzrW0nt9mqz3ZiV5Q1MthvNM0yL8LNeTogV/qu4s9VmsmRbgCwuD0bzzRrNlfABy5v8AbIJDKGU2FrWMmRAi+hDkqdPMxCFCCd5ykEX7opYJV5OxP8PNbtzSVECBV2YrVC+Y6ujnQE3W1gD0Dm7u08Ztq4FWrrWJNxTanl6CGIJ/2yVEDnK/0ZCYWvSonMzUjTphlQEX4uFueGsljYILF6lapUqFqZzEKLCm2ZVsABvJuZcRApaGwEovyqk1CoqWQhRnz6kM1rnhczd9HtmHC4fK/wB4zFm1vboVb9NlCj4S0iAiIgIiICIiAiIgIiICIiAmjHfc1PyN8pvmjHfc1PyN8oG+IiAiIgIiICImIGYiICIiAieKtVUUsxsoFyT0TzRxCVBdHVh2EGXV7jkcT9JcSKjqCgCsQObwNuM1fWbFfiXwysxf31T87f7jCYZ2XMqki9tOk6bhvO8d8+zODwpJuQWf1mxX4l8MfWbFfiXwypyHge6BTJ6Oi/wmvR4XiLpbfWbFfiXwx9ZsV+JfDKjKeB7pnIeB7o9HheIaW31mxX4l8MfWbFfiTwyqekykhgQQSD7xvngiPR4V+Iad5sDHviKJepluGI5osLWH7y0lD9ED/wCM3/sPyEvp8jjSTiWRCYmuvWCC539Anum+YAjpnIRkwpzlnN+HbJcRAREQEREBERAREQEREBMTVi2IpVCDYhGIPwlam0qoQnIpSlyYYljmbMqkkdozfGBcRIW0sW9IKUTNe9zZiFtuuFBOvG1hI9XarZatRFU06IBfnG7XQOcmljzWFuJ00gWsSqfaNbNzaaFTWNEXY3v+I6btN08VNruCtPIOVvUBIV2WyFdQFBOudfdrruuFxEhNjH9GFVaRzkDmHeLmx7TbU2tc8LyI22GsgCgu2e9kqEAKQNVC5gecNCNO3S4XESnba1Uq7LSUcnQWswckE3LgqNP/AOe88d03HaTCtkZQqH7JN7tzc2htlvvGW99LwLKJV7N2m1ZlvTIV0zg5XGXdoSygHQ7xwmnG4mv/AOUAVyoUyWJDa5Ta/beBdRKmvtR6ZZHRTUzIFy5mFmDG5AF9MjaDfpu6M0dpVXenTFIBmz3LZlFlK6gEX1z7j0wLWJVbP2q1Zk/hkJUBIORxl6RclQpuOB38d8Yzaxp1coUMquiNYMSC5A1IGVbZgbE3PZpAtYlOdr1MoY0wM9V6aWDMeYWBYhRfcmgHfJ+BxBq0wzKUNyCCCNxtcAgGx7RAkxEQE0Y77mp+RvlN80Y77mp+RvlA3zyzAAk6AamepqxVLPSdN2ZSveLQNeGxJaktR9M+qi2oB+yPfabkqBt3Qbai0h0V5XD0xYbgGU9BGhHYQRNmHpOjAXHJ2Ykakg6WsxPv6PlrOu2tTTelZGNgykjoBF55r4lKds5tmNhod/CRKWAdaiOXUlc/QdcxB3dG74z1Xo1alOiSFzqyuw1AuBqBv4zV/Dlblq9ElMSjIHDXU6X7b2tbjeYZs5UKSAG53RuF7fqJrem7q6sq2z6bwCuh7731nvC0SgIvpe4F7203XMx126ztv5MNXLF1YAMjWNtxBFwR8D3gzfIeEGavXqD7JyoOBKg3I+LW+E11Ma1VjTw1jY2aqfsJ2D8R7J0mNqSbSsTi6dIXqOFHRfeewDeTIwxVer91S5Nfx1dD8EGvfabcLs9KZzkmpUO+o+rfDgOwSXLvGdup0irxGzKlSm4fEOxKkBRZUvbgBe3xkbZv0bp0iHqMXfgNFH9zL2JqcbOS4yrzXWnzTF/e1Pzt/uM24bHtSXKoX7Qa5vvBB3Xt0e+15txeza/KueRqWLsQcp11M0+rq/U1PCZ9jeGWMlrLa21KhTKABoRcFri992uh1OvT0xU2pUaoHIW4Ui1jbXf0zV6ur9TU8Jj1dX6mp4TJy8L8G3ptoVCxbTMVy313Zs3H4e6b6m2HZWuozE9F7AWYHS+v2jv0kb1dX6mp4THq6v1NTwmS48K+F2lJtlrjMilQWYgA84nNobnddv0lazEkkm5OpPGSPV1fqanhMerq/U1PCZrH08e2k26H6MYClVw7NUQE5yL3IO4cJZ1sEKQvSrVU4KWzqfg1/nNP0Xw708Oy1EZDnJswsdwlu6BhYi4nyuNxL6l1ei7qqqVspFSsrmmd7AXC+8DUDtlpTdWUMpBU7iNxnq0rquGbDk1MOLqdXojce1ODdnTOUkvT5O6yiasPXWogdDdWFwZtmOyEREBERAREQEREBERA8soIIIuCLETV6JTysuQWa1xxsAB+gE2VSQpKgMwBsCbAnhfolDgvpBUGFoVsRTUCqrHMrbyEzjS2lwG0v0dN4F1iMLTq2zre243IIvv1HQZ5fZ9FmDGmLgADoFhuuBobdF90ql+koKZuROYKAyZtVqGqaQp3t+INrwEn4DHtV5VKlPk6tIgMobMuq5gQ1hfQ8IEr0ZPwj7Wf/wCuM8VMDSben8xa4JBudDqNdZR7P23V9GogUzXqjDitVJcLzbkaaascp003b5Jr/SGwZ6dEvRp00qVHLZSqsLjKtucbanUQLVsNTNPkygyAABbaC263C1hNZ2fSyhcmgJINzmud5zXvr75XV9vMrViMPmo0HC1H5QA2IU3Vba2zai4+M2rthjimoGkF1IUs+VqhC5rqpGq9FwSeyBPGDpWYBFAZBTIA3qL2X3c4988jA0hU5TIMw1vra9rXtuvbS++020GYopdQjkDMoN8p6RfpmyBHoYKnTJKIAbW6dBwHAdgmamDpsxZkBLAA9tjcXm+IGirhKb5syglrXPTzbldei1zFLCU0KlUAKggHp5xBbXpuQJviBHpYKmjl1QBjfjpfU2G4X7J5q7Pou+dkBa4PTYkbiRuuLDXfJUQI7YOmUyZRluWFrixJJJBGoNye+bKNJUUKoAUdAmyICIiAmjHfc1PyN8pvmjHfc1PyN8oG+IiBi0zEQEREBExK/GOa1T0dCQoF6rDoB3KDxP6Caxm6sjwxOJJp0zkw66M66GpxVeA4mWNKkqKFQBVAsANwinTCKFUAKBYAbgJ7jLLfSdi0iImUIiICIiAiIgIiICa6tUILn/8AZskR8MzVLseb0ftAxhs7vnJsPn2SZMAW0EzATEzMQK4j0fEC2lKuTfgtS17/AP0AfiJYKwIuCCOIlH9KcAalIVVuTT+0vQV424iWey6eTDUV4IvynbPGXCZ769m7Om0uIicWCImIGYiICIiAiIgJX+pMNyQpcn/DDioFzGysN1tdB2DSWExAhHZOHIrA0wRXYNU384jcewiwOnTrNuCwNOgpWmCMxuxLFmY2tcsSSdAJImHcKpY7gLmBX1Ng4ZkRDTOVFyCzsLr+EkHnL2Ge8RsbD1XDvT1AAsCQrAbgyg2YDoBnvDbSpVCApYFhdcylcw7CRrJbMACSbAb5bLOlXWlQmwKbVq1WsM/KVRUADMFsFUAMt7NYrfWSjsmgavKlTmuW+02UMRYsFvYNbp3yYjhlDKQQRcHiJ5r1lpoXc2UbzGvhChRWmiot8qgAXJJsO06mbJFw2Pp1WKrmDAXyspU24gHeJJiyzuMxMRIMxMTV6SlgQSwLZeaL2O7W27dGhuiYiBmIiAiIgJox33NT8jfKb5ox33NT8jfKBviIgIiICImIEfH4rkaRYC7blX8THQDvjAYXkqdibuTmdvxMd5kep/Fxar/LQXMfztoO4XPxljN3pNL8EREwhERAREQEREBERATxUqBRczNRwoud0hKrVmudFECXRqh1uJsmFUAWG6aMXjKdBQ1Rsqk2vbp/6IWS3pHrFsVpOQbEKSD8JyPrTEdc36Tpq2MpVaFTk6iPzG3EHonI0qRa9raC5JNgPeTOXErxfVc2Nk7JHrTEdc36R60xHXN+k0ejv0Ix1toLgkcCN8ejv+BtBf7J3cZz3Xk5s/NbztPEH/Nb9IG064FhVa3wmgUHIJyNYb9N3/bzHJNcjK1xqRY3EbpzZ+ak+tcR1rfpHrXEda36TQcO4BJRgBv0Oml/lMDDudyMf/kxunNn5rf60xHWt+k6rZlQth6bMbsVBJ4zjGQi1wRfUXG+ddsiqvo9IZhfKNL6zfDt31en6W5XK7T4mInZ7mYiICIiAlZt3AVcRSVaT5SGuQSQG04iWcTWGVxsyiy6u2jB0mSkiO2ZlUAtxM9YlS1NwNSVIHdNsSb67RTYehWcYZGpGmKNiWZhqQtrCxPGRsJs6sWOellDUnV7nQsSCNcxLe8zoonT1a1zOefA1ORoIKBGVSGFwedYC9s1rHU33iTHwtVsJSUi9WmUYqT9oqb2vLWIvFtOaqWomJqVGKq9JWpuBnZdGsLWtuG+R02dV5KoFR0uEGW6i5DXJFidbX1vrOimInFs7Q5lJidnVByy0lIpl6bBQftADngXPu32vMUtmuwpKysKfKMzKWAyqVsBzTuJ6ATvl5Eerlo5qomwdY4nOKZAFUXa+9LW3lr/AAtaZw2z3QKopZSuIDFgRZku1unoBEvIj1brRzVR4bA1RUUlGDAvylTNcVQb2AF+JHRpabdnbPek2HbKQeSIqnNfXS19demW8zF4tpzUiInJkiIgJox33NT8jfKb5ox33NT8jfKBviJ5dgoJOgAuYHqJXevML1y9x/aPXmF65e4/tOnpZ/tv8Ly3wsYld68wvXL3H9phtuYWx/jL3H9o9LP9t/g5b4etkc5alXpqVWPwByj9FlhKTZe18NTw9NWqqGC6ix39PRJXrzC9cvcf2ms+HnzXpf4W43fZYxK/15heuXuP7THrzC9cvcf2mfSz/bf4TlvhYxNdCstRA6HMp3HjNk59kIiICIiAieXYKLnQSGlR6j3GiiBNZQRY7pHxGKp0FGY26FUasx4AbyZrxmMKsKVFQ9Zhex+yg/Ex4dnTM4PACmS7E1Kx31G3+5R/KOwQ3MZJvJqD4qt9kLh04sM1Q/8AzuX9Zox2wuWTK1eozXBzMbgcbILCW8Qs4lxu8eioXYtDD0ahVczhG57and0cJzdKqVvYAgixBFwen+07bGKTSqAC5KkAfCcf6vr9U/hM5cT8PB9Zc88pb1Y9MfKV0AII0HQb6f1GextF7G4BJOYG246/vPPq+v1T+Ex6vr9U/hM5/c8n3/k9Of8A093aDf380Ty2McsWvYmw7iCP1E9er6/VP4THq+v1T+Ex9yff+Rsc5JvlN+i2m4j5EwcdUve46Ojg2b5x6vr9U/hMer6/VP4TH3L9/wCWqtXZwt7c0WFhOl2fs2hUw9MvRpsSouSoufjOf9X1+qfwmdXsxCuHpqwIIUXB3ibw3vq9P0vNM7Wo7JVdaNSpRP8Apa6+FriefSq1D79Q6dbTB0/Mm8e8XllMTs+hz2/q6vNKorqGUhlOoINwZ7lbWwjUWNXDjQ6vR6H7V4N85Mw2IWqgdDdT3jiCOgwlx+Z2boiIZIiICIiBUttm1RlNMFeeFIckkoCdebYfZO4kjhw9HarqP4lEAsisgD3zXYKA2gym7Lxm/wBVUbk5T/MbZ2yjMCGsL2F7ndNtTBU3+0t+Zk3ndcH5gawI2Dr1WxNRKqhctNDZXzLqzagkA9HDoljI2GwNOkxZQ2ZgAWZmZiBe1yxPEyTAREQEREBERAREQEREBERATRjvuan5G+U3zRjvuan5G+UDfNGN+5qfkb5TfNGO+5q/kb5SzuPnQmw0XyZ8py8baTWN0nYfHkZQKas4yqCemzXGn6T9Fncp+mPbUKJP9bNe+VSL3sdxN1sTxPN/Uz0u06mYPkuFuezoW5PTbd8TMc+f7f8AabvhXEW39OsyFNibaCwv793yMmnarFWGUarl9w1/Sx/QTOG2kwCIqZiLAWJ1NiBYced8YuWev0/7N1BIOnbu7ZiWJ2qwY3QXsRYk2AJLbvj8pWzWFyveaWO7+j/+Dpe4/wC4yxld9H/8HS9x/wBxljPg8X9eX+a8mXekRE5skTDEAXO6a6NYPe3RA1YmizsBfm/KecZX5BAtNc1RzlprxPE9g3mS5X4IctWeudVW9On7gec3xI/SG8ZO9+G/AYMUUNzmdjd3O9m/bgOiSoiGbbbukREIxMxEBERAREQEREBMTMQEREDErcQPRq3LD7qoQKo6FY6B/wCx+BlnPFakroyMLqwII7DDWN1XqZkDZNUmmabm70WNNjxt9k/FSDJ8JlNXRMTMq9vYCriKSrSfKQ1yCSA2nEQuElurdLOYdwqljuAuZqwVJqdJEdszKoBbiZ6xKlqbgbypA7oTXXTRhdpUqrBVzAlcy5kK5hxFxrvEl3lN6rdcMCMz1xSyBWbRb2zAWtw49G+aKezapupQrTNVGy3C2XKQ2gOnRuh2uGF7V0F4vKHGYCqa16dKwVqeRgRootcXJuOnQDWZXZLEgsnOOIcsc2+mSbDfu3aQnp463zL288NVUMEJGZgSB0kDf8xKOps+qFAyFqa1ah5MWN1P2TYmxA107Zsp7NZamGcoXyKytdgWUkgqSem2u6D08f3Lu8Tn8Ns6sC2ZWz5HDNdbVCRp2njra0ttm4UUqKLazWBa5uS1hfWGc8Jj2u0uIiHMiIgIiICIiAmjHfc1PyN8pvmjHfc1PyN8oG+aMb9zV/I3ym+eK1POjLe2YEX94lg+cUnylWG8EHu1k5dqW0FMWBUgXPQ2bXjLj6pL158H/MfVIdefB/zPr5fU8DLv/b03PCqvD7UAJzgiykKV3jRR0/lv8TNGH2i9NFUfy6DU7iwY/wC23xl39Uh158H/ADMH6Jr158H/ADM+t9MnPgqBtG70iygLT6B7racJldqsP5BvB1J1tl38Tzd/aZPwP0ep16QqJXNj0ZBoeG+SPqkOvPgH7y3i/Ty6v9rzYKddpHmgqAAwJt0gAA3HSbD9ZDr1M7lrWudBwHQPgJ0n1SHXnwf8x9Uh158A/eXH6j6fG7hM8Is/o/8A4Ol7j/uMsZHwGF5GilIHNlFr2tfW8kT5XEsuVsefK7pME2FzumZgiYRBdzWbKuij/t5Mp0wosIp0wosBae4EXaeINLD1ag3qhI99tP1nvBYcUqNOmP5VA/SRtuf4c9roP6xLCG//ABCIiGCIiAiIgIiICIiAiIgIiICIiAiIgV9MZMa46ykrfFTlP6ESfINb/G0v/U/zWTobz+KzERDBMTM11gxRshs1jlPbbSBsnl2CgkkADUk7hObqU6qUKrBatMDDtyhdr5qnQV1PbqOIm04OpUWqqJVVWokEVG+1U6CNT236DDv6U8r3llzhL84rm3aW9+6e5Q1sPVNO1NKqj0cqATqHzjt37/hGJ2c49IycrpTVqXPP3mt7a79FhPTnld06ysWAvdTY6Hhf4z3KHF0ax5YGnUbNUXKQTzByYBYC4vrfTjNePoViAKVOtzaS5CSS2a+t+cAG3am94JwpddV9UxCKGJP2BdgNSPgNZsBlFXwbhsUUSpnqU7owbS9tRv0N4xNCuarELUL50NJw3MRdMwYX/N0a3g9OX5X0Sk9EqBhUAqZ/SfxG3Jk66Xta0uoYyxk+WYiIYIiICIiAmjHfc1PyN8pvmjHfc1PyN8oG+IiAiIgJoxgY0XCC7lSBrbW03zEsuhz/ANGcNVotVRsuVTYrfUNYEEabiDOhldizyFda3+W9qdTs/C3ebfESwnTi5XPLn8tZXfVmIicmSYJmZGxaO1gu47/+8IGp6zVGCpoB0yaJ4o0ggsPieM2QERECBtwH0SqRvUZvCc39pLqV1VDUJsgGYns3z1UQMpU7iLH3SmFQ+rq1Nvt0kam3wGh+IsZZ1rVv2f4/7+m/6w4Trf6W/aPrDhOt/pb9pws9IhY2Auf2FzPZ7fHy+f7nJ3H1hwnW/wBLftH1hwnW/wBLftOHemV3gjQHv1Ey1Jha6nUXHfb5gx7fDye4z8O3+sOE63+lv2j6w4Trf6W/acOyEGxBBvbUdPCenostsykXJGo6QbR7fDye4z8O2+sOE63+lv2j6w4Trf6W/acNMR7fHye5yfSqNVXRXU3VgCDxBkattagjFGezDQjKf2jY/wDhKH/rX5TmtrC+KqD/AFTw8S8vZ24vFuGEsdF67w3Wf0t+0eu8N1n9LftOVOGf8JO/cL2sbHd7o9GqWByNru0Nzu192onLnrh7nieHVeu8N1n9LftHrvDdZ/S37TlGw7jejWsDu6Duno4WoFzZDbQ7ugi4Pu0j1Ke54nh1PrvDdZ/S37R67w3Wf0t+05M0mBsVa9r2sd09DDPYnI2gvqO22nGPUqe5z8Oq9d4brP6W/aSMLjada/Jtmy79CPnOKNNgLlTbjbST8DjTh8NXqLbNdAt+JJ/teXHO26duBxs+JxJhruvl52OY9XRA+LNf5KJPlP8ARzE8stWoykO73Y25u6wCnpsBLmdXu4suOXLfgiIhzIiIHipTV1KsAykWIO4iehMxAxEzEDETMQMRMxAxMxEBERAREQEREBNGO+5qfkb5TfNGO+5qfkb5QN8REBERAREQPFWkrqUYXVhYjiJBwlZqLjD1TfqnP84/Cf8AUP1ljNOJwyVUKOLg94PQQegzWN+L2WVumJW08U+HITEHMm5a3Qex+B7dxm3EVi5yJ8Tx/wCIyx0WaSaddWJAO79ZtmqhQCDt6TNsyhERAREQEp9t4VlStVpkc6mVqKekAaMO0a++XEhbY/wlf/1t8pce8LdSvn02UKpRwwANr6HcQRY/oZrifUr5CyXarBQFQXB3alQAFAFr6/Y3mel2nVa6LTF2ATexI321J36yFg6/J1Ve18t9PgR/eSRteoP5V3jj0Ze3X7I1Ou/jOdw8R0mXmsYrH1HXIVAGfNcXOurb79s9euKma+Vd97G5Fy2a+p/6JhdqNdMwFlIJtfUdIte2sh1qpd2Y7yb+7siY+YXLxWcRWNR2c2ueHdNUROk6OdfQdj/4Sh/61+U5naxtiqv5v7Tptj/4Sh/61+U5na/+Jq/m/tPj8Z6/qP8A54sDaDgHRbkgjTQG5N7cbme8PjKxbmBSQCd3AC5PhEgz0jlb26QR8DOO68kzvzUnlq2RlynLax5p0A01+At8J6Q17ABSALC5W3QVF/gTNbY+oeA1voOnXzGPTXuTzbkg7um97+/Uy7a5p5r3y9cuKmVswXTmm1j02+M8jaFSwGlh2b937CY9OqabtCDu3kW1PcJGk34ZuXipFTGuylTax4D9P0Em7F2emIzCpcqjBsvQxsQL9m+VUv8A6Lf5v/z/AHlw65Ov0+eXqy7XyIFACgADcBuE9RE9D6RE14isKdN3O5VLH4C8i4f0k5HZqZDaugUjKCP5WvqRpvGvZAnRK07apjNmV1yqXsQLsAQDYA3B1GhsdZKw2LFRmTKyMtiVa17HcdCdND3QJESuO2aI35h/Daobj7IW9wf9XNbT/SZ6G1qfKZLN9rJm0sG/Da99+l7WvAnxI1fGBHCBHdrZiEA0G65uR+8g0NuIKKM9yxpio9gBlU31IJB6DoLnSBbxIY2gpcqqOyhgpdQCoJAIG+/SNQLC/vnkbUQkc1wpLBXsMrlQSQNb/wAp3jW0CdEg1tq00VWYNZqRqiwucoy3+PPGk1YraZCkBGp1M1PRwNVaoqkixPE9o0gWcSDT2rTaoEF9WKK2lmYXuN9+g7x0TGKx7LUemKbaUi+fTKN+8Xv0QJ8StpbXTkw1RXQ8mHGYDng2HNF+JAsbbxMnbFOxurBgwXJdb3IJGubLbQ9PRbfAsYlfX2vTS11e+QOy6AopvqQSOB0FzpPBxlTllCvTcMw/hqpJFMjRy3Ruvut0dsCziIgJox33NT8jfKb5ox33NT8jfKBviIgIiICIiAiYkTEYgk5E38RAlMoIIIBB3g7pCq4erTbPQKkWsabdPubeD79JNS9hff0zMsuhDw+0kZsjg0qn4H0J9x3H4SbNVfDpUXLUVWHAi8iegPT+4rMo/BU56frqO+a+2/helWESv9Mrp95hyw/FSYMPCbH5zK7Yw+5nyHhUUof6gI5MvjqctT4mpMRTb7Lq3uYGbBMa0jM1YqgKtN6ZJAdSpI3i82zw1VV3sB7zENbUP1SpdbU/T9o+qVLrancP2lrU2rh10NVCeCnMe4Xmv1kzfdYeq/awyL3tY/pO/NxXP2+HhXfVKl1tTuH7SJjdgUaVlWrUeq32EFrntPAdsvORxNT7dRaK/hp6t4j/AGEkYXBU6N8i6nexN2b3sdTL6uU73Z6HDnw49MDhlqNRr1KlKopsToUPaDa9vfLVPorRYAis5B1BFrGTtpbDp4mqlRiRYEMBvbhr2az2q4miLAJXQbtQjgf7T+k5+tn5dcuBwMpOWdflA+qVLran6ftH1SpdbU7h+0sfWyr97SrU/fTLDvS4npdsYY/5yD8xt85fWz8se1n7UjC0BSppTBJCKFBO82ketsmg7F2S7HUm5mz1jQ6+l4x+88NtfDD/AD6fwYH5Tlevdv0rZrla/UmH/B/Uf3j1Jh+r/qP7x64pt92lar+Wm1u9rCOVxVT7NNKI4u2ZvCun6yaie3nzJGuvsvCUlLuuVR0lj+807P2RTdWd6RUM10UkgqvRfXed/wAZNo7NUMKlVmrVBuZ9y/lUaCTY5YXh8OTUiv8AUmH6v+o/vHqTD9X/AFH95YxHLPDHp4eIrvUmH6v+o/vJGEwNOjfk1tm36k/OSYjUWYYzrIREStPLKCCCLg6EcZDo7Oy5By1Vkp/ZQkcLC7AXaw4n33k6IFVT2FTUAZ3ICGmPsiykg9A1PNGpk9cOBVarc3ZVUjospJH+4zdECufY1I5tW51UVN+638o/0m7XH+ozYuzVWpnDEAsXK2Fsx362va+trybECLXwmZw6u1NsuUlbc4XvY3B3a69pkZdiooUK7iyBCdCWAvbUjQ6nUSziBDGAs5ZajqrMGZARYkADfa4BsLgH5meU2YoK3diiEstM2yqSCN9rn7RsCen3SdECnxOxf4RC1KjsKJpIGIFlJU7wBrzBrJL7MDXNSo7tzbE2GUK4ewsOkqLyfECFQ2atN8ysctywWwsCdTra5FydL/2nuvgw75szC6FCBazA+8dHZJUQIVfZlOoFDFubTyDvVgfeCgmPV3MK8o1yb3stt1rFbWI+G+TogVg2LTAUIzLZMhNlJIBJG8aWLNa1t/YJOSjlZmB3gC1hpa/Tv6embYgIiICaMd9zU/I3ym+aMd9zU/I3ygZ9JXt7o9JXt7pClWdshatVXULTpnLnzG5OltMtt7D+aB0PpK9vdHpK9vdKNdr0TqGOWwObKcove123X5pnltsUswVblsyCx0sGZVv8M40gX3pK9vdHpK9vdOdqbaCYhqTIAitlNTMdP4ee9strW7b9k9rtukzKFzFWH2gCcpzKoBtu+2NYFziMRdbJ8ZjDFEH+o9kpl23SFPO+ZLAEgqdxvqOI5p7p7Xa9Pn5gy5S1tNGAYLcH/wCh3wL30le3uj0le3unP1Nt0RTLrmPMzglSFPMLgXtobA9Emek/xuSyP9jPntzN9rX49kC09JXt7o9JXt7pzGG+kdNgWqKEGlirZtSCcp0FmspNtdLSUu16V7G+rWBUEjVgqkm2lyRAvfSV7e6Yauh0Oo7RKDD7apsgZ1ZL67iQBqVubWBIUm02natIKzHOFUC5KEAE2sDfpOYadsCwfC4VtTRQn8gms4DCdXb3Fh8jK9tt0BY3cgi91QkbmNtOmyN3T0ds0MxUMSQQLAEkkkKAB72AmufLyu6ner8J+A+Jv3ntcHhB/kp8Vv8AOVybVRlqsqORTpipciwa4Jt2HmmbKm0qSNTR2yvUAIHv3frLz5eTdW1OpSXRQF9y2nv0le3ulCu26BFwWIAYmyk2CgEk27GHfPR2tTvaz8LZTnzZgtstu0TCLz0le3uj0le3ulLQ2rSqMqoWOawBym1yuexPQcutpFpbcBqOr08qLns2Ym+RgpuCoGt+gnttA6T0le3uj0le3ulCdsUiOYbnKGAOmha02HalIZb5gHbKpKkBj2E7xAuvSV4nunlq1M7xf3iRIgb/AOB+BfAJ7WrTG4Ae5ZFiF3Uw4pALk2Amn1rRIur5vy631y6W366SqxuZnCgqLZSAwupZiwFx2ZR3yJj6a4gAnOvJnlQGOWxVTuA3i9r++EdP6SvE90ekr290r6aBQAqhRwA3dM9wJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdHpK9vdIUQJvpK9vdNGNxK8jU3/Ybo7JpmnF/dVPyN8oEjkjwmtsCpVlKAhjmYcTpr79B3SZMwKzEbJSohQrzSVzbjmCm4Bvf957OzKZbMaYzXvftuGv3qD8JYRArm2VSLlzSUsdSTrc2y3tuvbSZGzUAAyDQW1N9Lhuk8QD8JYRAq/U1G1uRXX9iO6zNp2njPbbMpm16a6G47DcNccDdQfhLGIFb6ppZcnJLl3W6Ps5f9pIknkjwkmIFadlU7AckugAFtCLXtY+4kfEz36uS9+TW9wfiGzD9QDJ8QK07JpXB5Jbhco92ot+p7zPT7NpsSTTBJAB7QN3yGu/SWEQK87NQ76YPv16CvyZh8YGzkBvyY3g9l1IINuNwO6WEQK9dmoL2pgZlyHtXXQ9575insumtstMC27U92/UdksYgVq7JpAECkuoKntBABHcqj4Ce/V6Zs3JjNe9+24N+8CT4gVKbGRay1QLFBZVFrDTLwvuPGe/VFG5bklubknpuTckcNQDpLOIFd6rp6fwxoLDXdrfj+seqqXVixbNa+l9+6/HW0sYgR+SbhMckeEkxAjckeEckeEkxApcdsyrUqo6u10zEAMFQ7gEYjXjrNx2cWIzhcq6KBcsRwLE7uI6ZaRAjck3COSbhJMQI3JHhHJHhJMQI3JNwjkm4STECNyTcI5JuEkxAjckeEckeEkxAjckeEckeEkxAjckeEck3CSYgRuSbhHJNwkmIEbkm4RyR4STECNyR4RyR4STECNyR4RyR4STECNyTcI5JuEkxAjck3COSbhJMQI3JHhHJHhJMQI3JHhNWLpHkqmn8jfKTppxn3NT8jfIwN0T5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpcT5p7QsZ1eH8L+ePaFjOrw/hfzwPpc04z7mp+RvkZ869oWM6vD+F/PPNT6f4tlZTToWYEHmt0i34oHKxEQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERA//9k=\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_dab83d8651f34352914dbe31b66446ff",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "7ce3a4bc948e4f3fab5dc8b92799e834": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1Mo4y1Q7yD\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1Mo4y1Q7yD&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f07c3fed0>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_010ef7325c084215b86f6ab44f1d77a4",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "dab83d8651f34352914dbe31b66446ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "010ef7325c084215b86f6ab44f1d77a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a1568b7745245b8a4c9d930509f4f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7c73fa0c0a948ed870fc1ac331637dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cb4d96231af45c3a9f0da58e1c92d1c",
              "IPY_MODEL_56bd96f3600c4b5d92895dbfb33ba5bf"
            ]
          }
        },
        "d7c73fa0c0a948ed870fc1ac331637dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cb4d96231af45c3a9f0da58e1c92d1c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=1N4Jm9loJx4\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/1N4Jm9loJx4?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f0776f750>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_1f75bbbd763743eeacf7228baaa7deab",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "56bd96f3600c4b5d92895dbfb33ba5bf": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV14w411977Y\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV14w411977Y&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f066745d0>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_a5f6a8028001459499023268e4f57e60",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "1f75bbbd763743eeacf7228baaa7deab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5f6a8028001459499023268e4f57e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd0a059e3fd44dc9b082b634cf43f20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5501078a93754e359f226f249e3d2efa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53a707f62ba1455292927059337d2d5d",
              "IPY_MODEL_5ce456791ed64fb5be81c94349e61122"
            ]
          }
        },
        "5501078a93754e359f226f249e3d2efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53a707f62ba1455292927059337d2d5d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=5kBtiW88QVw\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/5kBtiW88QVw?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f06658ad0>",
                "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhsaGRoeHRsfIyomIiIiIjIrMSguMjc1MjI3LzI3QlBCNThLPS0tRWFFS1NWW1xbNUFlbWRYbFBZW1cBERISGRYZMBsbMFc/NUJXV1dXV1dXV1dXWldXXVdXV1dXV1deV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXXf/AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAABAUBAwYHAv/EAEoQAAEDAgMEBgYGBwYGAgMAAAEAAgMEERIhMQUTQVEGImFxktIUFzJTgZEjQqGxwdEHFTNScuHwVGJzk7LCFiRDgqLxNIMlRHT/xAAYAQEBAQEBAAAAAAAAAAAAAAAAAQIDBP/EACwRAQEAAgICAQIFAgcAAAAAAAABAhEhMQMSQVFxEyJhgfAyoQQjQpHB0eH/2gAMAwEAAhEDEQA/APP0REBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEXX+rit97T+J/kT1cVvvafxP8iDkEV3W9F54JDG98RItoTbPPkortjSDVzPmfyU2K5FMOzXji37fyWBs5/NvzVERFN/VUtiQAba2K+DQScvvQRUV7/wAJ1FrmSEA83Efgtb+jkjdZqf8AzP5KbHsyIsKjKKum21Cx72WlcWGzsEL3AGwOoFtCFLpalk0bZI3BzHaEIurG5FhZRBFppqlkrS5huA5zTlbNpLT9oK2oMosIgyiwtVPUtkxYDfC4sOVsxqg3ItL6lgkZET13hzmi3Btr5/8AcFrrq+Ona10mLrOwtDWlxJIJtYZ8Ci6qUig0m1YZn7tpc19r4XscwkcwHAXU5CyzsRamVDXPewG7mWxCxyvmFtRBFEi2hG+V0TcZLbhzgx2EEajFa189FLRbNCLCIjKLCIMoiICIviWVrGl7yGtaLknQAc0H2iwDcXC001UyUOLDcNc5hytm02KDeiwsoCIsIMotc8zY2Oe82a0EuNr2A7AvprgQCNDmEH0iwiDKLCrJukFMx7mOe7E0kHqHUfBaxxyy6m0tk7WiLTS1LZY2yMN2u0Nrdi2rNmlZRFhBlEWEGUWhtWwyuiB67QCRbge1bks0MosIgyiIg4vpE3/m5O5v3KjqW2Cvtvt/5uT/ALfuCqJ3NABeCRfMBY+WlDVP6wAFyt2xKZs03W9luZXztFzTI4x3DQAbWU3orExxe517g9WxI+5LeFxm66Cv2Qx0d47MeB1bG17f1qtWxanfwyNcBjju12Wt+P3/ACVhStbI2MkvBaOBLf8A2qTYkzRXVTW+y9zr/Am34rOPLec0dIY8oiP3FQOae1dTt5n0cP8AD+S557DbioTp66sLKLs4uZNdPTyV8kcLZGNlBcTIQR1GXyDTcAZrAEkLaeEOc/0h0s0hgsL6OwsJIsOtre9gughpWMdI5ozkdifne5sB9wCj/qiDdNiwkMa7EyziCw/3TqNSs6dZnEGKokgbUOeJ2U7Y8TXSFrnNdmCGm5vwIvxWunMsVTTC07RKXNeJZA8GzC4HXquuOGWqtY9mxBkjHYpBILP3jy4kcs9BmdF8xbKja6N95HOjvgL5HOtcFvE8imk9ogbIqXR07rRSS3nn9i2X0jtbkL5qqySN9RHicHTNjdBfVpf9GQP4SA74q5pqZkTS1gsC5zjnfNxLj9pK+J6GOSWOV7bvivgPK+R71dHtNqqmqpHvp4MbscRkMxGrt31W3/ixNd8FpiEklCa01EjZiwyizuo21zhw6EZWN8+1XcVFGyWSZrbSSBoeeeHRRn7DgLiSH4S7EY8bsBOtyy9tc1NHtEaNz6iqaDJJGz0eOQsabdYl2vH81F3rwx0bHmPfVr2OeNWjU25E2tftV+KZglMoHXLQwm/AEkZfErS/ZkLo3xlt2veXnM3xE3uDqDfkmiZxAFLuq+nAfI5pimsHuxWzjvYnPNfXSMuHohY0Of6S2wJsD1X6mxt8lLp9lRRyCUY3SAFuJ73ONjbLM9i31FKyQsLxfdvD252s4Aj8Sro9puVRsnlmqXSSsZG6ja8iNri4vLm5G9h1bfb3LVBJUOgZOxtU+dwa++Ju7dexLcOKwbbIG110DqNhmbNb6RrS24OrTwPMKOzY0LSMO8DQ7EIxI4MBvf2b21ztoppfeK/alVI1m0S17gY2Rllj7JLc7clumhdBU01ppXb5z2SBzrg9QuBA0abt4W1U+fZ0UgmDmkiYASZnO2Q7ltmpmPdG9wu6Mlzc9CQW/cSrpn2jm6cugpqh0cjw51W6LE52LCDIG4rH61jrzVjLG6lnpsEsj2yvMb2yPLr9VzsQvoRh4ZZqeNnxbuSPACyRznPBzuXG5Wul2VFE8SDG94FmmR7n4Rybc5KaaucqpiqJY6SpqjI974zOGNceq0B5Ay42tx4Kzp6AxWk38z3AEuu+4fl+7oOzDZSoaSNjHMa3qOLiQc74iS7XvKj0uyIonNc3edT2GukcWs4dUE2GSukuUqkp5qiWnbOxtS6oe3G0hzd3nmG4cVsPDS/xVg6N09ZNG6SVjGwxuwMfh6xL87jPgpQ2NCHEjeNaXYixsjgy+vsg214aKU2mYJXSgdd7WtJvwbe2XxKaLnPhz8LpfRqSoM8rpHSxMdd3VLXOwkFummd9brYZnzzVGJtSRHJu2CF4aG2ANz1hcm988rWVuNnRCKOLCcEbmuaLnItOIZ96+KjZcb3mS8jHuFnGORzMVtL2OffqppfeK/FUP9CZK+SJ7t4JMJALg0ZXtcC+Ry0uou0IyINow7yRzI4w9mJ5JF2kkE6ltxoV0AoowYiB+yBDMzlcW+OXNfMlBE4y4m33zQ2TM5gAj4ZEppJnN/z6vuiiwRMaC52Wrjc/MqB0d/Zzf/0zf6yrCkphEwMaXEDi9xcfmVBOwYLuIMzcTi4hsz2i5NybA2VTc5QpJ3zVFQ1zagticGMELg0Dqh1z1gSTfusF9OnlMMEUom3z3vGFjmsc9rb5vcPZywk2Oqsp9lxvfju9j7BpdG9zS4DTFY5pLsyJzI29Zu6zY5ryHN4Hram/G+qml9opXVErKeuYHyNMRZgxuxObiDSRivmL3t3qbWQPY+libPN9JI7G7FmeoTbSwGXAZKYNkw4ZWkOIltvCXkl1shmT2KRLTNe+N7h1oyS3PQkEHvyJTRc5/PsoqiR8A2hGyWQtjgbIwucXFpIfezjn9UFScDpqoRulkaz0dji1jsNySRqMx8FYTbPieZS5pO+YI35nNovYdntFfbKVjZN4B1sAZe/1RmPvV0e0UTaiXcthErhiq3Qb36wYC468yBhv2qW2J0NbDG2WUxuikOF78WYLM7nPjxW+s2e3cyMZEJA9+NzS8tuSbktdwPEafBRdnbNd6SJnRvja2NzPpJd49xcRqbmwFshfiVF3KtqWDdxtYXvfhHtPN3HvK56hFRv6vcGK29OLeX5m1rLoaWnbFG2Nl8LdMRJPzOagzdH6Z73PcwlziSesdT8V38Wcx3L8/u4Zy28I+05poIoZi9u8a7C6NpOF976DmtTaoijbI6aRz5ni27sSCT7Db6K0i2VCwxkNP0V8FySBfXLnmvl2x4C1zMJwudjsCcncxy+C3M8NaZ9araGeVk8sRdLh3JeBKQXA9hHBRBJOKann9IkLnvDbHSxJ4cdOKv4dlxMcXgOLi3CS5xJI+JWf1XDumRYTgY4OaLnIi/H4q/i473r6J61WMdJFUzRb5727gvBccwezkohfM2iZV+kyF4t1Seqeta1uJV/UUTXOfIB9K6Msvfh3Kv2dsCIRxmZn0jdRiyJvxGhysrj5Mdbv6fH3LjWiSqdHU1UoHWFO1wB55LXSSVP0UjPSHlxBfiw4HNOuEXyV8KOPePkw9Z7cLrnIju0UeDYsEbw9rXAtN2jEbA9gupPLjrr+aX1qqrJJo5ZHzOqGxh/UfEQWNbfLE1dG03AIzBUCTYlO5xcWnrHE5uI4SeZF7KwAXPyZY5SaaxljKIi5NPP+kNU8bUkZlu8LfnhuoNS7qlWu3Nj1E20pJGBrWWZ1naHq2yAzKl0mxooiHSF0j+ZyaO5v53WariayJ/WcGEMOQJBF7cua17LqDG8NzwvyNuC7XaNHFM4k4yQMwXE31y/kuLoaZ2/aC1wAOfVKtnC43l1M9Uaale+M4jbK97XOXFV3RSmDq1jQ4lpaXF3eMx81MrqZ0zmwta7Da7jb+s/zX1sOifTMleQQ4HI9guphi15MuVn0moHxwsLes1mRcOGlrrkXuJ5rvNlba3gs8Gx1uOfBQttdGDITJSutfMxnT/tPDuUyx+hjl8OtREW3MREQFhZRAREQEWuKdj74HtdY2OEg2PbZfaDKIsIMovljw4BzSCCLgg3BHYheAQCRc3sL5m2tkH0iIgIiICIiAiIgIiICIiAsLKIMLKIgIiICIiAiIgwiyiAiIgIiICIiDCLDnAWuQLmwvzRrgdCDnbLmNUH0iIgIiICIviSVrPacG35m3C/3An4IPtFgG+YWHvDRdxAHMm2uSD6REQEREBYWUQEREBERARFzrdqyxxl7Wtke51Q9+N5bhERIwgWPAAfag6JaK6AywSxtdgc9jmh37pIIB+CpJukT2BwdHE1zXWu6Qhv7MSAA4faOK1rcCexfU/SCRjXvMLWsEojBc+1iWh5L7gBozA11+0NQ2fVNLjFDHEN01mFrm6tcL4S0NNrYrXOp+qvuPZ1aQ3eSuBG6HVlIFg9287zgLRc5/HNb6/bjoYYJN21plYXkSPsAQAcAcAbuN8u4rbTbVe+cMdG1rHPewHEcV2tDsxa3Ma8EEVlBWh8V5Tga4/XzDRI49b968eEZg6cNV9TRVL6yTAXhjXx2JeQ0NsC8YPrXGV+B5Wz0Ha1SX2G6LmyztLMRHVa0luLIkG1j8VlnSIg3wjC+Vres8XaCyJwDQBc/tDzN+w5B802y6xu4jL93E2Jsby2Q5DdkGw0uH2N7cNeCzFBWzwMlxFssjHmwdbBcNDMNxlk0nvKlbR2vJBUStIjMbYWvaCSCSXFriTb2W5E8h3rS7pDLgLmRRvwtc4neGzg1+C7DhNwb3v8Afqgj7RbURzRR45t0XuILXOc7DijsLgi5zfqTYE5Gwt1CoJ+kMkZDXRx4g54PXIDi1zQGx5ZuIde3Z8Rti2xM5zQIWWdJM0dc3wxOwk2w+0bZD7UF2i5uPpK9zMQiY4ktaMDy4Y3glrCbZEEAHlcHsW+n2m6Z9LK0FokkfHhuc2BhJcRwIey1+3tQXqIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIi479I8744KcxvewmQ3LXEcOxB2KLxMVlRYH0qX/Md+aNrKguw+lSDtMrgPmi2WPX9pwPe2N0bQ50cjX4SbXAuCL87FVkGzqpj4nNIAMkj3txnC3G9zjkLXIDhzBtoNV5oauosT6W82Om+dc93YsmqqLgelvz4751h3oj0ij2bW2YJpn2xt3mGTMgNfiI4gEluWWmgW2pjqX1r92XhjTCQcZDQLnH1bWdcC3Z2LzP0mo/tjv8AOcsGrqBb/m3m5tlM7LvQek02zq3SWZ2b2Yy19rgYsRbrhBu0Wy7ha5+jR1l5hdxYXtIG9Ic5uJ1wHaNFi3gNCP7x8zkrKho/+W938Mzitf6xqP7RN/mO/NB6jFQ1gLHOlJc0w5Y+rYOO9uLZnCQL8SL5KG3Zde7OQg2OJoL72cY5WuIJvqXM7OwLzr9Y1H9om/zHfmn6xqP7RN/mO/NB6c6iq7zEYxiwBo3xthBGIgXBDjnoQLADmviPZdX7bzeR0UTXHeGwLH3OR1u3j3815p+saj+0Tf5jvzT9Y1H9om/zHfmg9PFDWkuBkcAXtxHee0N4CS0fU+juLflc2uzYpGRYZSXODn2JNzhxHDc8ThsvG/1jUf2ib/Md+a2tq6g4P+beMZsbyuGHTN3IZ6oPakXjgFUYpJRWEsY/Afp3XOmYF7kZ6q//AEd1UslZKJJZHgQk2c8nPE3mg9EREQEREBERBhfDImtLi1oBcbusNTpc9uQWxEGqdt2myqoNqWdherlcrtiLBMeRzUyuosdNFM14yK2Lj6aucw5HJXtHtVrxY6qTLZpZrAIPLJRairAaXE2aP6+K5in6Qskmdu3OY+/suFr/AAP3arSOySyraTbDHZSdV3PgfyVi51mki2l89EGUUOgc/MOkbJ2g9/D5fJTUGF8mJpeH4RjAIDrZgGxIHfYfJfaICIiAiIgIioOklHNK5hiaSGxSXIJuCSyxbYjr2xEX5IL9FzVX6c8TMwyObZ1hhbYWe3d4DkSS25IPHkszTbQDOoJCAZMDiyPG4gM3YkGjWkmQEixsBog6RFzro61r3lofI4TSOZjw4Q0xOw4SLZYrD/2vp81aI4yzfuIk62KONrnCwyNrgC+LOw01GRIX91lV5aX1oJBwwxZHgXSHh2gM/wDJUjNnVmFjSX7sVAlti62cti0/3A27vjbgg6pZXN08u0XvLXY42Oe3rFrCWA7zEBlbK0f72upXxJUVbHRY8bHSuY1zmRtLjaOUusDcXu1pQdOsKhbUVpDWvjdiduySGtsBY4wc8je3zyUaIV9mRNEjGbkMv1cnbu4cDa98eWvw4oOoWFzY9MbYjegFsIfJgYZMhJisDkTiwDTQ/FSKV9eXxuluBijD4w1uGxju831yflrz1QXqIiAiIgLiv0mfsKf/ABD/AKV2q4r9Jn7Cn/xD/pQcJHShzQd9E2/BzjcfYvo0Wf7aHxHyqZQMa6MYpWs11spNDTtllALyI72c+2ncOK7TxzW7TlVihv8A9eHxO8qi4TyK62rpooKiLcSYutfHpawudVbtfJJUWkiabjINJabXzOIZHLu0yXnzymN4ak43XneE8j8lhejvnMDJXMdGwZ+0DibraxN73yXB7yIkhxkLs72A5/NTDL2q3HXKJZLK22XUQRVLHdcGxzdaw6q+JJm1FQ4tGp42Hd3LpeEwx9rIrLJZXjtnYS03sToMTfzU6Cja3iHA9ov9ixt1vixls25bCeR+SYTyPyXoLHNaG87DmtcswbIDnZw5ZZLyz/FW3Ux/ut8Ek3twWE8j8kwnkfkuwlqCDTlpc0kueCRxHG1jwcdVpm2q6nYCXXuxzWg2PWGbSbAZdZ9+9ejDye3w5ZY6cqWHkfkuu/RqP+dm/wAH/c1bNm7Y9IlewXBEYc3F2e1meyx+B5qb0Gjw1Dza14v9zVvbNjuERFUEREBERB8PdZanVFltkbdRJY7A30Vg+/TmDUqm6RTRvDHNcC4ZEL4rqgC4bn2rlK3aLQ+2LE6/DgpRP3ueS2xzEKsbMt7JfkuTS8hrb5PzHNaa/Y8NQMQFncHDUKDHIpUNQRobKzLRpWufU0htIDNF+8NR/XarvZO3MrxPD28Wnh+S3R1DZBZwsVTba2KImmeElj2i/V0K3LL0jt6PaEcuQNnfun8Oalry+g6QaNmyPB4/EcF1+z9tkAYjvGHRwOf81UdCi1QVDJG3Y4Efd3ragIiICIiAsLKICIiAsLXUTsiYXyODWt1JXOVm3J5Qdw0xRe8cLud3DQI3jhcufh0skjWi7nBo5k2UU7XpRrUQ/wCY381zJ2DLL1343k53e9bo+i7uJYPiSquvHPm10sNbDJ+zljf/AAvB+5by0ZZaaLits7CbT07psQLmkaNtqba3W/ZUlSyjiqIpsYI60UmYyJBwnUaIeuF6v+7r0Vds3a7JyWEGOZvtRu17xzCsFGMsbjdVlEREEREBERAXFfpN/YU/+If9K7Vcf+kWIPhpwTb6Q/6UHnGIjjZbIqhzNFedHtmzVhkiEzmxx2Dm4rXDr5DI9qrduUDKeYsieXgZEOGbTyNsj3jmnvetrp8HacmJjupdgIALbjPmCpn/ABJPiDi2IkC18HD5qBBTg4N6XMBOZtwzt9oVmdjwG2Cckk2F2jszOeWqlkvZutU3SSofmd3f+Hv7eF1W085jlEgDSQSbOFxmpFTQmO4OZDha3EG9rDXgr2Do7C6OIlkoc9gc7raX+5Z4x6i81zG8+k3lhfFita4v3clmOYteXgAE8LZDuXQDo/AXtZvrOJI4kdijs2RFumPcXgkuBtnexystye10m7h+ZUvqnkk3tfkttPtCSO9iDfnmrql2DA9j3Evy0u61zryPJYm2PS7rHG57je18Y15EcNQt/hXfqn4t/qRG9JqgAC0WX90/mjuk1QRYtiPe0/mtEGzg8ZYnHPIFfTdivMjWmzQ4XFzn8AvN+H45d6jpc8/q2u6TTuZIx0cLmvbhILDkOzPIrJ6TzFmF8NM/Jt3OjN3YdCbG11Fds0tcWkOdbkp0nR4uiL4rktGbSbl3cusxknHTncudVrf0mlcbmClvhc2+7Ojtfrdiu/0eVb5KuQOtlDw/iaq2l6OtdT43h7ZCCRc27rhWP6OosNXL2w/7mq60kyleiIiIoiIgIiINU82Adq5zbe3Iof2j7u4Mbmflw7yulkjDmlp0Pw+R4Lg9u9CJGl0lK4ygm5Y49f4E+18c+9BQbR21LPcewz90HXvKrV9vjLXFrgQ4ZEEWI7wvlBYxSXAK3teq+mdlZSGvWLOVlT45VJZMqwOW1kiz0q5ikVvGBNC5h5LmYaiyutl1NnBMbrIvTg5oyx7mHVpI+WS20lbJCbsdYcQdD8FY9K6XdVr7aPAePj/6VMurLrdl7ea5w6xik78j3H8CurottA2bKLH94afHkvPdj9HKmssWNwRcZH5D4DV3wy7V6NsfYcdIwNxOkcPrvz+Q4BBZrKIgIiICIiAvmR4a0ucbNAuSeAX0uc6ZVpbCyBvtSnPO3VHb2kj7Uawx9rpQ7R6StlqQ58ZfHGfo4ybD+J3M/crBu0mVMDntBacebTw/NcnHI0SOD8LTzAFrq0oSxz2Mhc5ziOsCdcjmB32WtLnn7ddO+pj9Gz+ELaqs1zoo23jOQAve/wByiHbWM4CcLTqQSD8xosZXUtYTekTC6jlAF8h9hBVF0cmJoJI3ZGN5sOw5/mviurmYG4JXveJSC0SOJLRiyNza2ipdpzOuX4HtvbC63dxC5ePze/xr7t3CzH2XlXTul2i1rXljsALXDgQLhdLsjaBma5kgwzxHDI37iOwrzig2lJFM2QPuQRm7PLiM+xdvVTbuSnrW5NeGsl/hdofgV2l27XC69Ld/T+fq6FFhZR5hERAREQFxn6SXkQU9jb6Q/wCldmuP/SNAXwQWIykOvcg43Y21RSuc8F5c/wBoC1jbRfUu04nVAnAdiN8YcAQ4Ead+gXy3ZwEbHOjab5FwmOX8QsbfBb9p7H9FMQfE128FwWTkggWv9XtCmp2s30jbSro5cIZcBoyOEDPW2Wg/ErdsHbYppPpI2yMPE6t7ueixBsreNNoLW4mY692FRZtlSMbiJZbkCb/cpuLqx91W1C+d7wbMcTo0AkWsLka8FZx7eibTMjBOPA1pNjYZaBQz0Yqcv2eYv7Wn2LW/o9OBe8Z7A4/klk6JucrWTalGIAxkj8RN3HdnrZaZ5DPvWifadLuY2xueXBzi7E2xz7svkqKendG4tdYEdqzR0rp34GFt7XzNgtY8WWGduXa2dtzBC9kRu5xBBI0I4jtUePajbva4NLTbrhtnE9o+a+KLY8znEkBuBu9IdcYmg54cs1avc0adbMg5aW1+9dfe3L3rnMZJpX0u1GMaMrPH1v5dy2S7WZI/eOe5sjW2bZuuv5lT4ZIyQJMieItbsvyKntp4xbLUjUNUx8eOXO0yysUrNrx4CS92Oxw5G+fapGyNuRRuaZpTkcRsw/LIdqtfR4yPZHyb9io9vxsEbQ054s72HArd8frjeUllvS7rOlNG49UuIIIJLXC32Zr76C1rZKqRrRpF9l2rhjF2rrP0bMIrJSRYGH/c1efTp09HREVBERAREQERR6reWbugCb9a54ch2oIe2Ng09YPpW2eNJG5OH5jsK4LbXRaopLutvYv32jT+IcO/Rd/HJVWuWtyBFjliN7c+Wd/sWQ+q1wC5sC0kWHMixv8APkg8lYbaLayVd3tLoi2pL3tDYJOBaOq/W923NuGYtqdVxm09lTUr8MzC2+jtWu7j/RQfDXcltD1CDiFtbKs2KltcpdLVlhUKmifK8Mja57joALldbsnoho6qd/8AW0/6j+XzWfVdq/a1BJtGKnfTtxSMcY3Z2s0i4JPIW+1WmxehMENn1BE8gzt9QfD63x+S6aGFkbQ1jQ1o0AFlsXRlgCwsMgsoiAiIgIiICIiAuF6YPxVljo1jQPjc/ku5XA9M2ltbcD2ms/EfgrHTx/6vs+HVNJhG8wFwDbYWjPL62XbnnqqyrlAmeYQ1rb2aW8R39qg2zuVPoaNzhjIbgH330P8AXBVzao6maNrXXc3HniJIv/JSKasMby8Oe0tAwG1wT28uKuX9FRNEx7JLEi+F2YF+Srp9jVUH/TxNHFnWHy1QfdJA6qle8vAJDpCQL58cr5aqvrqt+CNrg0jENL8B/NDVzPBiZhjsSSWizjfUE8Qoro3l1pHWDdLZnPkuH4Vvk9reHa+X2w9b+z7dXYY5mWPWBtyva111tdtOA0IguS8xNyGdiACLn4LiHRkvsMyTpquso9jCnopZph9Lu3Bo/dxC3zzXSYyW1nD+rHTtKGTHDE86uY0/MLeo9BGWQRNOrWNHyAUhVjLu6EREQREQFUdINkOq2xBpbZjiSHXzytwVuiDk6Tocf+vIC0fVZcX7yc/krCu2EXug3e7ayIYcJB0ysB8leIl54Xak/VMwlc9pisdBnl8VErej00kTWNfE0gEE2Jvf7l0yLHpF9q5p/R2UiPrsuyMM1Nr5m+nd9qgwdE6prml07CQCDm4jM3va2vDVdmi38aTbj63oaZpQ5+7LQAPacLa34ZrVJ0Hw5w7sPGhLnCx7gM12qIjjR0YrbD6aD9m6MizrEG2nLQLaOi0+ZLoC43scLsvzXWog409D5SMzTtdzDXEH4XFlsZ0XqW2GOnLeWFwt3ZnLsXXIkuruF5cjL0YqXZB8A7QHXUSXoXVOeHCaH4gn7wu5RaudvaSSOHquhU72tDZIALNxDCcyNTe2V+Stuj3R+SklL3uY68eHq3uTcHlyFvguiRZUREQEREBERAWuSFr/AGmh1uYutiIMNaAAALAaBFlEGF8TwMlYWSND2nUOFwVsRBxW2ehOr6Q//U4/6XfgfmoWyOhU0pDqg7ln7urz+Dft7l6EsIIuz9mw0zMELA0cTxPedSpSyiAiIgIiICIiAiIgIiIC5fpxQGSJkw1YcLu46H4H711C1zQtkY5jxdrgQR2FG8MvW7ecUvR2R8zY8bLEFznM6wYOFzkLnkrWbZscELmtzLSOtxKkxRTUkno+87YS/wBmQfu3+q5aNqPle14Me7Fxiu4H5WWjPH1qRQVtXJTtMMcXUOHruN3W1sNB81th6RMDxHUsdBLe1jm35qXstoFPFYAdUJtKgbUx7uTS4OVicu9Rh8yGnmdfAyQ2PWw3+1Vtb0diIx3c3U4Rayu4YWRizGtaOQFlrrPYKDn6ahii2iwNblhBzzzsVb7RG+lhpRnjcHydjGm/2nJVNZUiKuD7F1mizRqSQQAPiuk2LQOjDpps55bF390cGjuR1w/L+e/t9/8AxZrKIo5CIiAiLla7ZFU9lUGEhksj3luLMlvsBvIOOG9/3e1B1SLnZX7QMsgaHtYXAA/RmwErBdvfHjOd/msyO2g10bWh7g2Q3ccHWZvLdb/6+Vvmg6FFydBVVFSS7FjLZGuDLNOBpEtnXt1SeqMNyRbXNZ2hWVtPG0OkN37vruwNscDzIAbaAtabWN8xxuA6tFS7RdV4YPRnOc0s6zg1ty7q4S4Ot1faJtZaZBtAB5aSSd9ZpDLNAeN3h7SzFa/ZeyDoEXOSzVscD5Xve0RwyuF2suXXODF8M8rcLrXDWVLmQ4JcTpnyRO9k7s64gcIDsLWuF7WJIQdOiqdoPqhLhia5zHbmzhhs2z/pb3zzZ3qE9+0N28BspdvMnfRg4bO0GYtfCNePeg6NFyY2jWPmlja/DK2OzY+rnJu2OItbKxcTcmxuBwur7ZBm3R3+LFiOHEAHYeF8Jtz+FkE5ERAREQEREBERAREQEREBERARFhBlRa2vjgDceIl5Ia1rS4kgFxsB2AlSlC2pQGoYG4g2xv1mBwORHeCL3BBCD7nr4mMc9zxZsZkI+thAvfDqs0lbHMZBGb7t2F3fYH8VUSdF2OLyZXuxMIxOuXYjFucV72PVz01OvBT49kRgPDsRxPL+q5zNQB9Ui+nFBIkromyCMvGI3yvpYXz5L6ZVxuLgHDLjcZiwNxzGYVRUdGhIX3l6rt7bqC/0ubru1NuH4rdV7AZJis8sDnh1mtHs4AxzO4gILBlZGfrgdYtFyBcg2y5rY2dhcWB7S4atBFx3hVT+jzCXkvzcH26o6uN+PLusvjYuzpYpqh0rQA8us4HOznvdYWOnWvmAb3QW3pUeEu3jMLTYnELA8ieBWX1Mbb4pGC2t3AW01+Y+aqB0e+ibHvRZpaAREBdrQWjERmT1r3uNNNQdX6khjhdGZmYzu+u4C/Ua1o0IP1b5EaoOgBWVDpaiJkbGb5ji1obfE0XsLXsMvkpYIOYNwptNsoiKqIiICIiCPW0cc8ZjlbiafmDzB4Fc1tHZdTExzReojNrOHti3MfW+C61YRvHPXF5jm9lbRh3TIzI1r2ixa7qkfNWO8HAg/FTKiiil/aRsf/E0FQj0do/cAdxcPxVX/Lv1n9/+mqasjYLvkY3vcFCdWuqAWUsTpL/XcMLB8Tr8FcQbFpYzdsEYPMi/3qcAhvCdTf3/AJ/yqtm7FET99M7ezn61sm9jRw71arKKM5ZXK7oiIjKl6T7cNBFHI2MSY34bF2G2RPI8lTUnTl0geXU4GEXFn3ub2zy/NbP0jxudTQYWkne8Bf6rlxuzm5PDnFlg3Kx62eQ/9qJvl2tB0xdKAXU9gb+y+5+0BfNV05bH/wDrP1tcuFvsXN7PazdsxybsXdZ1jrlyU6d8b45Gul3rmx3vgPLK5/NZ/N8crVvD04jfII93gcbWxutr22Uqp6SyMeAIA5v72I3+VlQQU0RaGte19wOGnYVEp9qlsz4pQN37LTY3bwt/Wi14fJM8rhrr5ZzlxksdTF0kJLmiEYrYg3rDF3ZKNSdMN/EXinva+Rdra1+Haq00bQRM6aRov1HADIjnfjktNNBTxBsbZJHOa4kXa3EcjcDPMEXWusuelx3cXS/8QSmYRtgBLs2EuIBABJvlwUtu0piR9BbncnTU2yzKoNl1Qklic03GOSMHsc0kfaF0sjiATlkCf/H+al4qzqKmu6SyxucI6UyRj6xfhv8AAi6jP6WStexjaRlzl+1GXPQKtqqprnPmLnOY05Dm7gAPtUOnpN3E4PeRJJcucct2wnP4n8+SmV1j+tdfHjMrz1HSHpVJcgUw6v7Q7wWb2DmVqZ0xe512014rkYi+xNuQtmqJtI2ZzGAERC+7ZmC+2rnDl3/mt9LPfFgbieC4Yi2zGBpLRnodFLl6Y7vNMpjbx0uIulpwvfJAGkG1gSXHW3AZZHXksDpk50O9FMWjgHusT9i5+CTdiSd/0ha5wI4HXPt1K+658hiJlycbWGWQz4DRcsMsrz8Hkxkv0X0/TPCQGQF1+ZIz7MtO02X1RdKZpXtb6M0AuAJxnK5tkMNyqano42RtlMgYTewd1uJFw0Z/cplNXgvjbGHykvF3ObgGudmixPxK7SyTXblbvqadsiIqCIiAiIgIiICIiAiIg1zyiNjnuya1pce4C5VFsPbDjHC6qf8ASVj3OgjDfZYBkDbhYXv2qz25C6SiqWN9p0TwO/CVz2zXF8uyqhjS+M07oSWi+7cBqeXskIOl2jtCKmj3kxwsxNbe2hJtnyHaq/Y9bL6VVUtQ7E+Nwkjda1436C3ZouWo6KVuztoxgyTvkqdy0a2IcBjPK9xfuCv6FuLbMpBuIaRkTz/eLsQ+wIOkREQEREBV21NsR04Nzd3Ll3/kte3trCmiNvbIy7P5rz/eS1M2tydTwYPxK55ZXqM73xFxU7dqKl+BhLQdTbIDnb81iSWUD6MNv/fHD81Z0tC2JuFvxN8z3qDXWbLgaAMrnMm6uOOuz1jU2ondbebvIaNZb5m+alUtS8E4SWkX0Nsu1aqandJfPhfM2XzBVGIlpja69xcutbO3IrXrKlkdBQ7bvYSjL98fiFdNcCLg3B0K4KlL3g2ABbrnzV3siudEQyT2HaZ6X/BT+n7G9dujRYWVpsREQEREBERAREQEREBERByf6QpXsp4N24tJltl/C5c1TyPkhhx5kuNzYXyIA+wBdh0x/Yxm7BZ/19NDp2qkoYomwgGQFzb2wWIOZ+WijO+VAcQgAZbFiNr6cFiOVxjIsWutmQLAi2l+KlMaBG7K9sWdr2zUiCCF0Ra8PDg29mgW04pZ+Sfdqd18Uch37sgPZvbjlrZaKd7ZZJiRc5nTT4K0fRxskG7Ml3e0HjQ5Wso2zKC7pGSiQhtjZuoOf8lPDxnll8rZLJKhuqXNlwXJaNGtAyJW+GcNILHA5G9z3WtYcNQrCSiphIRabeFoPWAta41K1inYcsBc1rSBhF7Z9yznbbN8l4t00UbxGA1rrk3diAtnfHfT+IfEKxpa6V9PKXPe4EBgzGpuOAVa2JrRcMwkZA3BV1V1DN1ELNZfrgsHLIHTXVW5bSKvdC4vmyO+ROTn8z2DILVKXGxcMi6+E6l3MjiRwboFvc4OIDWl1smi+fMZfH7VqmiIiaREWXIAub2zta+vFN34dLeNPiaW7mCTrWxAsaczfmRztopFA28Ra84I8cvVv/eOWfepIomtdEW9frYiGtvY2Oq3bPm3bnARguxyG7hh43zv3pMdY1j2tqmhhcIZ3NJAG8Abaw09ok8Fv2yTh69gA1os3Xjrmc1IqjLJHVWawEtkBANuH2lfdXSyFtpcFyy4wjhbj2rOE1j+7p5LvLaPQQF+MgABrrZ3N8geFuasYYnsey5iAxt+qR9uJaKGkilYXMM4xE3aH2zGWg7lup9g00ckbnB2PE0guzzByzIuukk+axa7JERVkREQEREBERAREQFCq9r00DsEtREx37rngH5KW5wAJOgFyvMqKOhdTTV+0WPe6adwjDXG548CO3XkEHd/8R0P9rh8YUPZu0dm0okbFVxBr3l+EyCzSdQ0cAoOzOjOyauBs8MLix19ZHggjUEXVV0L6N0lXTyvnjLnNmcwHG4ZANPA9pQdD0Nma9lWWODgauUgg3yNrH4q12dsyOm3mC5Mr3Pe5xuST28houQ2lQO2LUNq6UONI+zZo7k2+J+w8DlxXa0dXHPEyWJ2JjxcH+uKDeiIgLDjYEnQLKibUfhp5D2W+eSluoluo4PbjpaypIBswa5/1oPxUyioWRNAGQGfaTzKRNGZAyJv396+Kme3VGbjy4BTCa7TXC4dtmmGO87Ba/HMZcFX1EjJZy5jg4WbYjRU7oGkkWADtdM+Cl0kQYQA0kHM24hdIl3YtKhj4I8TJoxoHWdiJKpTiJAceZ0txKlSUlNCMUMN3A5AFxsOORK+3NL3MIaL6AOHNNJuRrx7oOIaS6xFhqVri2i9zxjY+2E6Z/NXMzI90cbZd5a+UZcL20uNRpmqtsTm2eDYnP8APsKi39XYbGqt7A0k3Lcj+H2Keud6LSkmQHlf5H+a6JYx6XHoREWmhERAREQEREBERAREQcr0/beng/xf9rlQ7FaME1x7LQR33suh6dNJggsCfpf9pXObNacMgsLEAm55G+XNYvblb+Z90Ngx/c4WtcHrKc+mxF4DjcxjO5GZGnctNPHeFrQM8Tv6+xS3VbA5uEcrEAWyGef9FXLnGa+rcy1ld/R8zl7p7Pdctw2PLILVsskTS3fexyzyyPAL7opzO4ycSc+Gihwy9dxaD1nWBH33WPBz5M41llxjpYvJ9KbY2vHf7b5fLRfJcd4MXWuCMxfQ6/YomN2/JzOG+buA7O691sppnzSMAsHXwgk3vcE52GWi1ZdxLfzWJU8rCcLwXG9gALn4WWyagcyxc3E1rbDIHtUzZ+yhG/eyEOlzAI0A7Fa4Rl2hXTTlmztErmAANAGg7L527lukLIy3EwC5uSAMwMypNZshoeXtvckAgHgcj9/2L6qaXBgdicTjYM7c7clMe+Wsta4DM1skYubOzPwB05FaaZrXiVztQ+UDLtFvwWqGKMyQgtBc7eOcOYBdYnmqsbQdTxutfOaQHictO7JbymsMmPHjc89ROgmBp6wkjFaXDe3AZKXtNouwt03Sp9myBzDcBwdIQQc7tIuQR8ArarcDYgW6tlw8N/Lfu7+eazsStmxARNIIb1nfirCINcRYtJBF8u1chPUMAAZI5xBdiBJsAbfDVTaauiL47P612DMHmF6MvHlJuTbze0dqiIo0IiICIiAiIgLCysIOa6WdJYKeKanxk1DoyAGi+EuFhc8Oa491bQS7Mp6V8skcsRLsQjxC7iSRqL6/Yq/pgf8A8nVfx/gF8M6M1zmbwUsmG19M/lqg67YXSjZ1FStga+V9rkuMdrk65XyULof0ppaOnljmL8TpnPGFt8iGj8CuJe0tJBBBBsQdQVhB6nP052bIxzHiRzHAhwMeRB+K5ro90mjoKmSNr3yUTyS246zDwy+w89VyK3UlHLO8RwsdI88Gi6D1D/j+g5y+D+audj7agrWF8D7hps4EWI7wvIa/YVXTNxzQPY3961x8SNF1P6Lj9LU/wM+8oPRVD2s29PJ3X+RCmL4kYHNLToRZSzcSzccJS04kDrucS05gC/dovuWBjM35H+uF1qrampppXMYY2tvxYcz2nELqqpKl09S50rsTuQuARoMuS1jeGPjayFOH5tBAH1uCkGVkcgLsYAHAX0W6KYNaXOIsBZx79B2rmdrVz5Jg2MEm3Am6tMbv7Ogr9pRPbZhlBPNn9ZrTUlwYzC4iwGZ1zJN/t0XLvq5I5RjBBBBsXFdDLO6VrcIycL3OgAuLfMIWa6XDdrzkf9AngQ0i3wuquWSQXDnB1yTkLDPUDsUinmONsTrBztM7fYplbFhjBFiTlm7+rpTlM6KMzeez7z/JdGqzYFPggxHV+fw4K0XPHprHoREWmhERAREQEREBERAREQct09J3EFiR9LwP91y5ajJD28jcHLnp+K6jp7+xp/8AF/2uXNUz92cRc0CxFiL3v/6WL25Zf1MbVY800QiBLt67TjqFp2PUzNLGvya72ibW7zfuSXaETY2bxmIlzjcDTP8AmvuofTG+ABzjkCWWt8bqxrPXyvdnVoeZHy4GOyvo34qn9MYSGNb1gc8OgbxJsc7j71HMTTYuwucONszy+Smbao44I6dzWhry4hxGV+qTnzzWcPH6Z5Z77JnLqfRFjqHMrJXNa1zL3AJ6rri1iVd9GaMh7pMLQMVxbgbWsPmfmsUGwMUUb8TWl4Djlnmuiggaxoa0WA0Vntb+j05+mtztvLlsedO5aV9yHRbcSTPNRK9jnMGAXIcDbuKlsNxZfByQc9VOmiML8A6lwcIBPWHK97KgnlLmmNzC1zpHHMZWJ7suHFdptDZzJmjg7n+aqHdG3H67B8CufMlx7dvH6y+29VS7PlG8iu7AMRzP8PJXpmD2Ag31BystP/Cx4yM14sJ/FbJKH0aMMu0536rbahSb1rTXluOVuUu7VTs+VjjFG7J2/cL4RmCSdT+SvXbLLCHBzCA5p60YB9oaOFrfJVmxdmPmjDw5oGN+Zbf6x7QrZ1DNHa8wLQ5twGnmO1d/JfbPVny4THGY726tERZQREQEREBERAWufFgdh9rCcPfbJbFhB5hsaOSI1e0q6NzpIgMAkbhxSOyBtbhl81ujpNszw+ntqHAEF7YxIQS3sZbDbsOq7XpNs11XRTQs9sgFvaQbgfGy4ql6Yz09J6E6md6Qxu7aTlbgLtte4+1BH2xGdpUUVdHETUtfupxG2+KwuHWHZb59i579U1P9nm/y3fkvUuhGyX0lEBKC2SRxeWn6twAB8h9q6FB4Z+qqn+zzf5bvyXVPM1DBS0NGMNZVND5X6OF9G34Wz7rdq9JXFdNKWaCrp9pQMx7oYXjla+vYQSL8EFbI/aGypIzWSioppjheC8vFjr7QuDbPkVu2Vsyoo9tGOna/0V5xFwb1cFsQBdbgTZRto7Vl25LBTQwFkbXYnuJvbgSToABfvXpDW2AA0AsgysrCyg5vpdsT0iIvZk9ud+7j+BXnVJTytlOJpDmnO+d/zC9oVFtbYAku+IAH938vyWeYzZpycjyY2Mvc5ud3nID4AfavuNsVs2gd4v8AbqvuaikjJBBB7vwWmxGRK1Mt9HFhUU8Lh7APLK1vxUpmFrIWi1wCf/I5KK6QCy+d0556rSrvXNS4yTTZV1EcczC4XyJyyIy4371cbGpPSSHBpDNSTy+QzK17P6LmZzHzDJuYv+R1+OS6+ngbG0NYLALNvt9kk3NNjWgAAZAaLKIq6CIiAiIgIiICIiAiIgIiIOS/SH/8en/xv9rlylPTbwAuLrA37113T4jc04PGb/a5UkfVFhkrMZby5Z52dK/aVJGyFpdiLQ++RF8/gq2GOG4wukB4XII+5WHSCYbpsZNsRufgqKIYXgtBKzdS8Ovjlyw3U57yw+12/krSSv8ATHxh0V7eyL8TqVVRQZ3I1XXbB2Zu2iRw67tOwLFtyuo9E8ePjx9r2t9n0zYWW+sc3Ht/JTQ5aGhbAtyacLd3dbLr7cVqC+iVUZBRy+boCgyCsFCvm6CjrayqhdZzm2PsuDRY/kexaZKp8kIdIbnHbS3BX00TZGlrgCDqCuf2hE2CINDsQMlxfuOX2LlcbLvbt743HWuWrZVXLBTswluFz3kZXPtFT/TpZC1pkZYubfLtHYqV8mCjiIP13fe4rRTVOKaIYv8AqM5/vBYx8mWWVv610xwlwepIiL0PKIiICIiDVv2c09IZzUFRamvZFIGPvmxz7gXyBa21hnq8ILj0hnNPSGc1R/ren4yAC17kG1sOPW1r4bm3Ysv2nGI2yA3YXhhOmEnLMHTOw+IQXfpDOa+TLHe+V+dlz8G3YXNxODmCzSS4aF1+qbaEWz71v/WsFyMZuDa2F2ZuW5ZZ5tOnJBd+kM5p6Qzmqf0+O8IGJwm9ghptpfM8FEG3ot8+N3VwFwJxA+yQM2g4hckWyzQdH6Qzmm/ZzVEdsQC5LurYEEAm+RJyAuLYTe6wzbERc5pu2zi0Eg52tc6ZNBcBc5ZoL1ssY0sO4LPpDOapW7ThP1jxN8LrAC9yTbIZHM5ZL4/XFPYHeam3suy01FsvabrzCC99IZzT0hnNUZ2xTgC8gHVLswdACTfLI2a7LXIr6h2nE+VsTcRc4OPskAYSAQb6HrD+iEF16QzmnpDOapP1pEImyvdga69r56XvpwyvdfX6zhxFuPrAhpGE6m9rZZ6HPsQW0ronizwHDtChSbMpXcLdxP4qCdswWxB/V1JIIsMJdfMZizTpyX3+tYcusczb2HZG+HPLLMgZqWSpZL2kN2RSg8T/AF2BS4IaeP2WtB52ufmVTy7YY2q9HLTiuBe44txXw3vbLVbGbWgdYNfdxvYYTfKxN8stRrzCesPWLz0hnNPSGc1R/reHDiLiB1b9UkXdawuBYnMZdqmg3F1VT/SGc09IZzUFEE70hnNPSGc1BRBO9IZzT0hnNQUQTt+zmtclfC295BkC63Gzdctcrj5hVG0HnJoIAtiOI4QRdosT/wB33KDU07Klu5jc6IgjEIwG4TchxvxyGg4WQdT6Qzn9iekM5qpoiDE14BGMB5uScyAeKkIJ3pDOaekM5qCiCd6QzmnpDOagog+9o0dNVNa2duMMdibm4WPPKy0/qqj/AHB4nfmvtESyVFk6O7Oe7E6EEnm5/wCay3o/s8aQjxP/ADUlFNRuZWdVobsOgBBEQuM/ad+anCKDl960IkkiXK3tIwQ/1dMMP9XUdFUScMP9XT6L+rqMiCTaH+rpaH+rqMiCTaH+rrGGH+rqOiCRgh/q60VNBSSi0jA4A31KwiDYylp26NHLUr6EFPe9hf4rSikknQnekM5p6QzmoKKid6QzmnpDOagognekM5p6QzmoKIM4DyUSbZMcjnOexxcbZlzsrEHq59XNoOXJWqIKj9TQ4cO6u3kST9Us/wBJIWx+y43QmBzC6M6gkm+d9dVZogqJNiwuxXi9pznOsSLl1gdDxsPkk+yGub1QWOvcOFyRdxcbZ83H5q3RBApaXdRMjbchjQ0X42yzWmTZETr4o74r3zOdyHfeARy4K1RBVfqmL9w+zh1OliOfJxR+yYnEExnIk6kXvYkHPMdUZHLJWqIKs7LjNuocgW2xGxBvk4X6wzOvNYZsmJoADDlpdxPFrufNrfkrVEFQ7YsJveM9Zpa7rHMG975/3itzdnsEm8DSH9bO5+thvcf9rfkrFEFR+pYrAYH2BxDruyJve2eQN9AvqHZETH42xkOvi1Ot3HTve75q1RBUP2LCW4TGbYMGp9kBzba8nu+a+anYzZHtf1m9bE4D6xuHZ56XAVyiCrl2VG95e5jiTYkYnYSQLAlt7Xt2LW3YkIsN2bB2LNztbAAnPP2R8lcIgqf1PFhc0NeGuABAe4DKw0vrYDPipbIcLQ1rbAAADsClogi4DyTAeRUpEEXAeRTAeRUpEEXAeRTAeRUpEFHtOhnkdHu34cL7izOAFy1xJ4kDhy1Wx1DLJhDmloZmHbwudmM+AAOZF7nJXCIIrYiAAG2AyAWd2eSkogjbs8k3Z5KSiCNuzyTdnkpKII27PJN2eSkogjbs8k3Z5KSiCNuzyTdnkpKII27PJN2eSkogjbs8k3Z5KSiCNuzyTdnkpKII27PJN2eSkogjbs8k3Z5KSiCNuzyTdnkpKII27PJN2eSkogjbs8k3Z5KSiCNuzyTdnkpKICLzT1hVnu6fwv8AMnrCrPd0/hf5kHpaLzT1hVnu6fwv8yesKs93T+F/mQelovNPWFWe7p/C/wAyesKs93T+F/mQelovNPWFWe7p/C/zJ6wqz3dP4X+ZB6Wi809YVZ7un8L/ADJ6wqz3dP4X+ZB6Wi809YVZ7un8L/MnrCrPd0/hf5kHpaLzT1hVnu6fwv8AMnrCrPd0/hf5kHpaLzT1hVnu6fwv8yesKs93T+F/mQelovNPWFWe7p/C/wAyesKs93T+F/mQelovNPWFWe7p/C/zJ6wqz3dP4X+ZB6Wi809YVZ7un8L/ADJ6wqz3dP4X+ZB6Wi809YVZ7un8L/MnrCrPd0/hf5kHpaLzT1hVnu6fwv8AMnrCrPd0/hf5kHpaLzT1hVnu6fwv8yesKs93T+F/mQelovNPWFWe7p/C/wAyesKs93T+F/mQelovNPWFWe7p/C/zJ6wqz3dP4X+ZB6Wi809YVZ7un8L/ADJ6wqz3dP4X+ZB6Wi809YVZ7un8L/MnrCrPd0/hf5kHpaLzT1hVnu6fwv8AMnrCrPd0/hf5kHpaLzT1hVnu6fwv8yesKs93T+F/mQelovNPWFWe7p/C/wAyesKs93T+F/mQelovNPWFWe7p/C/zJ6wqz3dP4X+ZB6Wi809YVZ7un8L/ADJ6wqz3dP4X+ZB6Wi809YVZ7un8L/MnrCrPd0/hf5kHpaLzT1hVnu6fwv8AMnrCrPd0/hf5kHpaLzT1hVnu6fwv8yesKs93T+F/mQelovNPWFWe7p/C/wAyesKs93T+F/mQelovNPWFWe7p/C/zJ6wqz3dP4X+ZB6Wi809YVZ7un8L/ADJ6wqz3dP4X+ZB6Wi809YVZ7un8L/MnrCrPd0/hf5kHJoiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg//Z\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_f42011b31b884199bb94d273b5837c8b",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "5ce456791ed64fb5be81c94349e61122": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1Nq4y1X7AF\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1Nq4y1X7AF&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f0663cc90>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_9c4589b30b8f45829017ed9ddc9ee452",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "f42011b31b884199bb94d273b5837c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c4589b30b8f45829017ed9ddc9ee452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6bf8154b2b24b06bbf3b96f79bf8f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5f86358cc394424864aaa487affaf6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a77803a3b7e4aa48dacb9bea954cba8",
              "IPY_MODEL_260d539b672e42f5be296d4f09ceca74"
            ]
          }
        },
        "f5f86358cc394424864aaa487affaf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a77803a3b7e4aa48dacb9bea954cba8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=dKaOpgor5Ek\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/dKaOpgor5Ek?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8f0531af10>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_7e3ef32ba7534aecb29567e1e43891cf",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "260d539b672e42f5be296d4f09ceca74": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1WM4y1T7G5\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1WM4y1T7G5&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8f06601ad0>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_1b2058db7a9940f3882abb0f46b2224f",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "7e3ef32ba7534aecb29567e1e43891cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b2058db7a9940f3882abb0f46b2224f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/w3d2_updates/tutorials/W3D2_BasicReinforcementLearning/W3D2_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "qO5gauUZnnFp"
      },
      "source": [
        "# Tutorial 1: Introduction to Reinforcement Learning\n",
        "**Week 3, Day 2: Basic Reinforcement Learning (RL)**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__  Matthew Sargent, Anoop Kulkarni, Sowmya Parthiban, Feryal Behbahani, Jane Wang\n",
        "\n",
        "__Content reviewers:__ Ezekiel Williams, Mehul Rastogi, Lily Cheng, Roberto Guidotti, Arush Tagade\n",
        "\n",
        "__Content editors:__ Spiros Chavlis \n",
        "\n",
        "__Production editors:__ Spiros Chavlis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6v88FeUXnnFq"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "I5hxl_urnnFr"
      },
      "source": [
        "---\n",
        "#Tutorial Objectives\n",
        "\n",
        "By the end of the tutorial, you should be able to:\n",
        "\n",
        "1. Within the RL framework, be able to identify the different components: environment, agent, states, and actions. \n",
        "2. Understand the Bellman equation and components involved. \n",
        "3. Implement tabular value-based model-free learning (Q-learning and SARSA).\n",
        "4. Run a DQN agent and experiment with different hyperparameters.\n",
        "5. Have a high-level understanding of other (nonvalue-based) RL methods.\n",
        "6. Discuss real-world applications and ethical issues of RL.\n",
        "\n",
        "Note: There is an issue with some images not showing up if you're using a Safari browser. Please switch to Chrome if this is the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "BKkCQmdinnFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "cbd5e893-8f55-4d0b-c5dd-3871583d773e"
      },
      "source": [
        "# @title Tutorial slides\n",
        "\n",
        "# @markdown These are the slides for the videos in this tutorial\n",
        "from IPython.display import IFrame\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/m3kqy/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/m3kqy/?direct%26mode=render%26action=download%26mode=render\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8fd773a490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9sBv_fgsnnFs"
      },
      "source": [
        "---\n",
        "\n",
        "# Setup\n",
        "\n",
        "Run the following 5 cells in order to set up needed functions. Don't worry about the code for now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heGPmT8looqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "cbdfc0ee-8908-4652-982a-26c8226224d8"
      },
      "source": [
        "# @title Install requirements\n",
        "\n",
        "# @markdown we install the acme library, see [here](https://github.com/deepmind/acme) for more info\n",
        "!sudo apt-get install -y xvfb ffmpeg --quiet\n",
        "!pip install einops --quiet\n",
        "!pip install dm-acme --quiet\n",
        "!pip install dm-acme[reverb] --quiet\n",
        "!pip install dm-acme[tf] --quiet\n",
        "!pip install dm-acme[envs] --quiet\n",
        "!pip install dm-env --quiet\n",
        "!pip install imageio --quiet\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install gym --quiet\n",
        "!pip install enum --quiet\n",
        "!pip install dm-env --quiet\n",
        "!pip install pandas --quiet\n",
        "!pip install tensorflow --quiet\n",
        "!pip install dm-sonnet --quiet\n",
        "!pip install typing --quiet\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 1s (705 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     || 219 kB 8.9 MB/s \n",
            "\u001b[?25h  Building wheel for dm-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     || 14.7 MB 194 kB/s \n",
            "\u001b[K     || 254 kB 9.6 MB/s \n",
            "\u001b[K     || 5.5 MB 13.6 MB/s \n",
            "\u001b[K     || 99 kB 12.1 MB/s \n",
            "\u001b[K     || 446.9 MB 16 kB/s \n",
            "\u001b[K     || 12.8 MB 150 kB/s \n",
            "\u001b[K     || 1.3 MB 54.6 MB/s \n",
            "\u001b[K     || 5.5 MB 27.8 MB/s \n",
            "\u001b[K     || 463 kB 72.7 MB/s \n",
            "\u001b[K     || 4.3 MB 58.5 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.39.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires keras-nightly~=2.5.0.dev, but you have keras-nightly 2.7.0.dev2021072300 which is incompatible.\u001b[0m\n",
            "\u001b[K     || 88 kB 5.0 MB/s \n",
            "\u001b[K     || 18.8 MB 64 kB/s \n",
            "\u001b[K     || 4.9 MB 63.1 MB/s \n",
            "\u001b[K     || 205 kB 73.1 MB/s \n",
            "\u001b[?25h  Building wheel for bsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.4-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     || 26.9 MB 88 kB/s \n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.4\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/02/a0/32e1d5a21b703f600183e205aafc6773577e16429af5ad3c3f9b956b07ca/enum-0.4.7.tar.gz#sha256=8c7cf3587eda51008bcc1eed99ea2c331ccd265c231dbaa95ec5258d3dc03100 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/0c/4e/1ea357e7783c756bb579333c1e4a026fb331371ee771f616ffedc781e531/enum-0.4.6.tar.gz#sha256=54e78526b166982b36884613f35a76d9a6711c49810d3ec1a05b10c9b31f938e (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/8b/e8/9ab0fa69b64b96d6af51c9a148047afdadad80e76a4aa364adc800537a12/enum-0.4.5.tar.gz#sha256=3f6fa69eda5ff2b6242414ea6a6770f2a01cab3417cdceaeac1e51af8dfbab80 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/80/8e/5e00e5378d5ad8ef08a5092be5b44887fb12f463d663c6d0901e38b0ef88/enum-0.4.4.tar.gz#sha256=9bdfacf543baf2350df7613eb37f598a802f346985ca0dc1548be6494140fdff (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b1/d2/683c57f678721b90971fcf464241acd50067ea1e5f1eae2efac0c0bc9aab/enum-0.4.3.tar.gz#sha256=04349209897f2efd009ba8a66586c510b5195f69397284f2b2d99cb95a9e411b (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/fd/4c/bcd8d97668916d1514c6b9c7a4abda12254da43e278838b635feeefed6bb/enum-0.4.2.tar.gz#sha256=2e0ee95a88774b9a74f92875149c6e57573fe9da412b27750df3ca81987f4f12 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/6e/f4/7bf1dcb67fba9356da534820fb7e1a5d5a0b0ba7751dc13cbf0719ccb690/enum-0.4.1.tar.gz#sha256=679d9eead5cb3c5e59163375c58eadc85b33ad3cf90caae7ac596d039338ba3b (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/3a/92/de9217b21961433d49cce0e2ef076e4ca29636a57313847670cb4a3fb779/enum-0.4.tar.gz#sha256=0c4bff0403b9cd95ec88399e1ef439bc49c123d9650124aaa02e250a9b7d12c4 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/08/40/cc51c52ade9e5f191342ab0e825d768dc7ea81bbf90ffbcf3571335133e4/enum-0.3.1.tar.gz#sha256=df02acb036cf12320ae3d8ead195f0ce64449ee5fcab85c314a8634cac573969 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/53/10/9798036cb407d1365a2bac6e5f3b516c14b9cedcad766aa7c4042212dbce/enum-0.3.tar.gz#sha256=5030e1725e8bec16450cd657aa508e430f2cd4dabb1ca57191ee0578d0f62e96 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/38/44/8fa67f83724931ca76906b3db62df82cd1afcf9a873a85619da4ac2c96f7/enum-0.2.tar.gz#sha256=cbb768b8af610491af1e2bcd261298dc32c70aa8ab7ab7506cd21b0f187fb882 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/5c/e2/630fc2ce1ce462260aaf5c6e3da496c00c2585bf57bf3852f753a9821ee7/enum-0.1.1.tar.gz#sha256=e6469b807ba4ba68d1823cc85faa5703cea0ffb18220ff5df7e4f4395b3a6a29 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/bb/65/0e9de2344b8285d62fe5853b159110cd349bc16333c5dfc0bc3c1dc047d5/enum-0.1.tar.gz#sha256=08089f638c278e8bd29bc68d87708da719bffd4bb176aa78b08b31dd029bf751 (from https://pypi.org/simple/enum/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement enum (from versions: 0.1, 0.1.1, 0.2, 0.3, 0.3.1, 0.4, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.4.7)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for enum\u001b[0m\n",
            "\u001b[K     || 4.0 MB 8.1 MB/s \n",
            "\u001b[K     || 1.2 MB 56.9 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.7.0.dev20210723 requires grpcio<2.0,>=1.37.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "tf-nightly 2.7.0.dev20210723 requires keras-nightly~=2.7.0.dev, but you have keras-nightly 2.5.0.dev2021032900 which is incompatible.\u001b[0m\n",
            "\u001b[K     || 78 kB 4.5 MB/s \n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "1Pb6IK87nnFs"
      },
      "source": [
        "# Import modules\n",
        "import gym\n",
        "import enum\n",
        "import copy\n",
        "import time\n",
        "import acme\n",
        "import torch\n",
        "import base64\n",
        "import dm_env\n",
        "import IPython\n",
        "import imageio\n",
        "import warnings\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sonnet as snt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from acme import environment_loop\n",
        "from acme import specs\n",
        "from acme import wrappers\n",
        "from acme.utils import tree_utils\n",
        "from acme.utils import loggers\n",
        "from tqdm import tqdm, trange\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import Categorical\n",
        "from typing import Callable, Optional, Sequence\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(precision=3, suppress=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "nZxQU-chnnFu"
      },
      "source": [
        "# @title Figure Settings\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
        "\n",
        "mpl.rc('image', cmap='Blues')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "kJi6AQ5pnnFu"
      },
      "source": [
        "# @title Helper Functions\n",
        "# @markdown Implement helpers for value visualisation\n",
        "\n",
        "map_from_action_to_subplot = lambda a: (2, 6, 8, 4)[a]\n",
        "map_from_action_to_name = lambda a: (\"up\", \"right\", \"down\", \"left\")[a]\n",
        "\n",
        "\n",
        "def plot_values(values, colormap='pink', vmin=-1, vmax=10):\n",
        "  plt.imshow(values, interpolation=\"nearest\", cmap=colormap, vmin=vmin,\n",
        "             vmax=vmax)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])\n",
        "  plt.colorbar(ticks=[vmin, vmax])\n",
        "\n",
        "\n",
        "def plot_state_value(action_values, epsilon=0.1):\n",
        "  q = action_values\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "  vmin = np.min(action_values)\n",
        "  vmax = np.max(action_values)\n",
        "  v = (1 - epsilon) * np.max(q, axis=-1) + epsilon * np.mean(q, axis=-1)\n",
        "  plot_values(v, colormap='summer', vmin=vmin, vmax=vmax)\n",
        "  plt.title(\"$v(s)$\")\n",
        "\n",
        "\n",
        "def plot_action_values(action_values, epsilon=0.1):\n",
        "  q = action_values\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
        "  vmin = np.min(action_values)\n",
        "  vmax = np.max(action_values)\n",
        "  dif = vmax - vmin\n",
        "  for a in [0, 1, 2, 3]:\n",
        "    plt.subplot(3, 3, map_from_action_to_subplot(a))\n",
        "\n",
        "    plot_values(q[..., a], vmin=vmin - 0.05*dif, vmax=vmax + 0.05*dif)\n",
        "    action_name = map_from_action_to_name(a)\n",
        "    plt.title(r\"$q(s, \\mathrm{\" + action_name + r\"})$\")\n",
        "\n",
        "  plt.subplot(3, 3, 5)\n",
        "  v = (1 - epsilon) * np.max(q, axis=-1) + epsilon * np.mean(q, axis=-1)\n",
        "  plot_values(v, colormap='summer', vmin=vmin, vmax=vmax)\n",
        "  plt.title(\"$v(s)$\")\n",
        "\n",
        "\n",
        "def smooth(x, window=10):\n",
        "  return x[:window*(len(x)//window)].reshape(len(x)//window, window).mean(axis=1)\n",
        "\n",
        "\n",
        "def plot_stats(stats, window=10):\n",
        "  plt.figure(figsize=(16,4))\n",
        "  plt.subplot(121)\n",
        "  xline = range(0, len(stats.episode_lengths), window)\n",
        "  plt.plot(xline, smooth(stats.episode_lengths, window=window))\n",
        "  plt.ylabel('Episode Length')\n",
        "  plt.xlabel('Episode Count')\n",
        "  plt.subplot(122)\n",
        "  plt.plot(xline, smooth(stats.episode_rewards, window=window))\n",
        "  plt.ylabel('Episode Return')\n",
        "  plt.xlabel('Episode Count')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "Xa6x5pjgnnFw"
      },
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "CNIFeSy8nnFx"
      },
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "IHsgjoE4nnFy",
        "outputId": "138869e1-4651-4f1a-98a1-67c5ee20e3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "282CRS9rnnFy"
      },
      "source": [
        "---\n",
        "# Section 1: Introduction to Reinforcement Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ruNInSE-nnFy",
        "cellView": "form",
        "outputId": "14ff9610-5f09-4005-e189-2d033a1f3acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "a11859f704fe48a3bfb5e16e3dd11c31",
            "bc9d1629df3a4cdd80e0b76ac4a98a4e",
            "030000630dfa4ea78227009c9dca0e21",
            "66cbcd695c994568b7255430aeaf007f",
            "f9a160a9fb6d47e6b9334bbab55a057b",
            "9a387a69da0c44f2a0d8adf2a596830b"
          ]
        }
      },
      "source": [
        "# @title Video 1: Introduction to RL\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV18V411p7iK\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"BWz3scQN50M\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a11859f704fe48a3bfb5e16e3dd11c31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8im2WGwnxF14"
      },
      "source": [
        "## Acme: a research framework for reinforcement learning\n",
        "\n",
        "**Acme** is a library of reinforcement learning (RL) agents and agent building blocks by Google DeepMind. Acme strives to expose simple, efficient, and readable agents, that serve both as reference implementations of popular algorithms and as strong baselines, while still providing enough flexibility to do novel research. The design of Acme also attempts to provide multiple points of entry to the RL problem at differing levels of complexity.\n",
        "\n",
        "For more information see [github repository](https://github.com/deepmind/acme)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VWvEwIvcnnFz"
      },
      "source": [
        "---\n",
        "# Section 2: General Formulation of RL Problems and Gridworlds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "cSaPyXfAnnF0",
        "cellView": "form",
        "outputId": "502ec272-fbc3-444c-bd9c-057a5d3c0518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "1e1484224fb14ac9939c6439f3e4aad1",
            "ac663fc3a25840559d25d3ad347a8c1b",
            "a42549d21f9b4485b6eb6dae1adce9bd",
            "838348de4afd46b5b79bf30b169b7027",
            "2c05237b9eba48f1bc29cb574142a240",
            "2f27f3bf95a54755ad7a879c133247af"
          ]
        }
      },
      "source": [
        "# @title Video 2: General Formulation and MDPs\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1k54y1E7Zn\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"h6TxAALY5Fc\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e1484224fb14ac9939c6439f3e4aad1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "V4tyNP4nnnF1"
      },
      "source": [
        "The agent interacts with the environment in a loop corresponding to the following diagram. The environment defines a set of <font color='blue'>**actions**</font>  that an agent can take.  The agent takes an action informed by the <font color='redorange'>**observations**</font> it receives, and will get a <font color='green'>**reward**</font> from the environment after each action. The goal in RL is to find an agent whose actions maximize the total accumulation of rewards obtained from the environment. \n",
        "\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1KktLm5mdWx1ORotxeYCq1WcQHkXzRT4F\" width=\"500\" /></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OWPIlL0knnF4"
      },
      "source": [
        "## Section 2.1: The Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RIgsEsg9nnF4"
      },
      "source": [
        "\n",
        "For this practical session we will focus on a **simple grid world** environment,which consists of a 9 x 10 grid of either wall or empty cells, depicted in black and white, respectively. The smiling agent starts from an initial location and needs to navigate to reach the goal square.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=163QdCqrPybJVVO0NhDxpun5O0YZmCnsI\" width=\"500\" />\n",
        "</center>\n",
        "\n",
        "Below you will find an implementation of this Gridworld as a ```dm_env.Environment```.\n",
        "\n",
        "There is no coding in this section, but if you want, you can look over the provided code so that you can familiarize yourself with an example of how to set up a **grid world** environment.\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "nASnXAWVnnF5"
      },
      "source": [
        "# @title Implement GridWorld { form-width: \"30%\" }\n",
        "# @markdown *Double-click* to inspect the contents of this cell.\n",
        "\n",
        "class ObservationType(enum.IntEnum):\n",
        "  STATE_INDEX = enum.auto()\n",
        "  AGENT_ONEHOT = enum.auto()\n",
        "  GRID = enum.auto()\n",
        "  AGENT_GOAL_POS = enum.auto()\n",
        "\n",
        "\n",
        "class GridWorld(dm_env.Environment):\n",
        "\n",
        "  def __init__(self,\n",
        "               layout,\n",
        "               start_state,\n",
        "               goal_state=None,\n",
        "               observation_type=ObservationType.STATE_INDEX,\n",
        "               discount=0.9,\n",
        "               penalty_for_walls=-5,\n",
        "               reward_goal=10,\n",
        "               max_episode_length=None,\n",
        "               randomize_goals=False):\n",
        "    \"\"\"Build a grid environment.\n",
        "\n",
        "    Simple gridworld defined by a map layout, a start and a goal state.\n",
        "\n",
        "    Layout should be a NxN grid, containing:\n",
        "      * 0: empty\n",
        "      * -1: wall\n",
        "      * Any other positive value: value indicates reward; episode will terminate\n",
        "\n",
        "    Args:\n",
        "      layout: NxN array of numbers, indicating the layout of the environment.\n",
        "      start_state: Tuple (y, x) of starting location.\n",
        "      goal_state: Optional tuple (y, x) of goal location. Will be randomly\n",
        "        sampled once if None.\n",
        "      observation_type: Enum observation type to use. One of:\n",
        "        * ObservationType.STATE_INDEX: int32 index of agent occupied tile.\n",
        "        * ObservationType.AGENT_ONEHOT: NxN float32 grid, with a 1 where the\n",
        "          agent is and 0 elsewhere.\n",
        "        * ObservationType.GRID: NxNx3 float32 grid of feature channels.\n",
        "          First channel contains walls (1 if wall, 0 otherwise), second the\n",
        "          agent position (1 if agent, 0 otherwise) and third goal position\n",
        "          (1 if goal, 0 otherwise)\n",
        "        * ObservationType.AGENT_GOAL_POS: float32 tuple with\n",
        "          (agent_y, agent_x, goal_y, goal_x)\n",
        "      discount: Discounting factor included in all Timesteps.\n",
        "      penalty_for_walls: Reward added when hitting a wall (should be negative).\n",
        "      reward_goal: Reward added when finding the goal (should be positive).\n",
        "      max_episode_length: If set, will terminate an episode after this many\n",
        "        steps.\n",
        "      randomize_goals: If true, randomize goal at every episode.\n",
        "    \"\"\"\n",
        "    if observation_type not in ObservationType:\n",
        "      raise ValueError('observation_type should be a ObservationType instace.')\n",
        "    self._layout = np.array(layout)\n",
        "    self._start_state = start_state\n",
        "    self._state = self._start_state\n",
        "    self._number_of_states = np.prod(np.shape(self._layout))\n",
        "    self._discount = discount\n",
        "    self._penalty_for_walls = penalty_for_walls\n",
        "    self._reward_goal = reward_goal\n",
        "    self._observation_type = observation_type\n",
        "    self._layout_dims = self._layout.shape\n",
        "    self._max_episode_length = max_episode_length\n",
        "    self._num_episode_steps = 0\n",
        "    self._randomize_goals = randomize_goals\n",
        "    if goal_state is None:\n",
        "      # Randomly sample goal_state if not provided\n",
        "      goal_state = self._sample_goal()\n",
        "    self.goal_state = goal_state\n",
        "\n",
        "  def _sample_goal(self):\n",
        "    \"\"\"Randomly sample reachable non-starting state.\"\"\"\n",
        "    # Sample a new goal\n",
        "    n = 0\n",
        "    max_tries = 1e5\n",
        "    while n < max_tries:\n",
        "      goal_state = tuple(np.random.randint(d) for d in self._layout_dims)\n",
        "      if goal_state != self._state and self._layout[goal_state] == 0:\n",
        "        # Reachable state found!\n",
        "        return goal_state\n",
        "      n += 1\n",
        "    raise ValueError('Failed to sample a goal state.')\n",
        "\n",
        "  @property\n",
        "  def layout(self):\n",
        "    return self._layout\n",
        "\n",
        "  @property\n",
        "  def number_of_states(self):\n",
        "    return self._number_of_states\n",
        "\n",
        "  @property\n",
        "  def goal_state(self):\n",
        "    return self._goal_state\n",
        "\n",
        "  @property\n",
        "  def start_state(self):\n",
        "    return self._start_state\n",
        "\n",
        "  @property\n",
        "  def state(self):\n",
        "    return self._state\n",
        "\n",
        "  def set_state(self, x, y):\n",
        "    self._state = (y, x)\n",
        "\n",
        "  @goal_state.setter\n",
        "  def goal_state(self, new_goal):\n",
        "    if new_goal == self._state or self._layout[new_goal] < 0:\n",
        "      raise ValueError('This is not a valid goal!')\n",
        "    # Zero out any other goal\n",
        "    self._layout[self._layout > 0] = 0\n",
        "    # Setup new goal location\n",
        "    self._layout[new_goal] = self._reward_goal\n",
        "    self._goal_state = new_goal\n",
        "\n",
        "  def observation_spec(self):\n",
        "    if self._observation_type is ObservationType.AGENT_ONEHOT:\n",
        "      return specs.Array(\n",
        "          shape=self._layout_dims,\n",
        "          dtype=np.float32,\n",
        "          name='observation_agent_onehot')\n",
        "    elif self._observation_type is ObservationType.GRID:\n",
        "      return specs.Array(\n",
        "          shape=self._layout_dims + (3,),\n",
        "          dtype=np.float32,\n",
        "          name='observation_grid')\n",
        "    elif self._observation_type is ObservationType.AGENT_GOAL_POS:\n",
        "      return specs.Array(\n",
        "          shape=(4,), dtype=np.float32, name='observation_agent_goal_pos')\n",
        "    elif self._observation_type is ObservationType.STATE_INDEX:\n",
        "      return specs.DiscreteArray(\n",
        "          self._number_of_states, dtype=int, name='observation_state_index')\n",
        "\n",
        "  def action_spec(self):\n",
        "    return specs.DiscreteArray(4, dtype=int, name='action')\n",
        "\n",
        "  def get_obs(self):\n",
        "    if self._observation_type is ObservationType.AGENT_ONEHOT:\n",
        "      obs = np.zeros(self._layout.shape, dtype=np.float32)\n",
        "      # Place agent\n",
        "      obs[self._state] = 1\n",
        "      return obs\n",
        "    elif self._observation_type is ObservationType.GRID:\n",
        "      obs = np.zeros(self._layout.shape + (3,), dtype=np.float32)\n",
        "      obs[..., 0] = self._layout < 0\n",
        "      obs[self._state[0], self._state[1], 1] = 1\n",
        "      obs[self._goal_state[0], self._goal_state[1], 2] = 1\n",
        "      return obs\n",
        "    elif self._observation_type is ObservationType.AGENT_GOAL_POS:\n",
        "      return np.array(self._state + self._goal_state, dtype=np.float32)\n",
        "    elif self._observation_type is ObservationType.STATE_INDEX:\n",
        "      y, x = self._state\n",
        "      return y * self._layout.shape[1] + x\n",
        "\n",
        "  def reset(self):\n",
        "    self._state = self._start_state\n",
        "    self._num_episode_steps = 0\n",
        "    if self._randomize_goals:\n",
        "      self.goal_state = self._sample_goal()\n",
        "    return dm_env.TimeStep(\n",
        "        step_type=dm_env.StepType.FIRST,\n",
        "        reward=None,\n",
        "        discount=None,\n",
        "        observation=self.get_obs())\n",
        "\n",
        "  def step(self, action):\n",
        "    y, x = self._state\n",
        "\n",
        "    if action == 0:  # up\n",
        "      new_state = (y - 1, x)\n",
        "    elif action == 1:  # right\n",
        "      new_state = (y, x + 1)\n",
        "    elif action == 2:  # down\n",
        "      new_state = (y + 1, x)\n",
        "    elif action == 3:  # left\n",
        "      new_state = (y, x - 1)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          'Invalid action: {} is not 0, 1, 2, or 3.'.format(action))\n",
        "\n",
        "    new_y, new_x = new_state\n",
        "    step_type = dm_env.StepType.MID\n",
        "    if self._layout[new_y, new_x] == -1:  # wall\n",
        "      reward = self._penalty_for_walls\n",
        "      discount = self._discount\n",
        "      new_state = (y, x)\n",
        "    elif self._layout[new_y, new_x] == 0:  # empty cell\n",
        "      reward = 0.\n",
        "      discount = self._discount\n",
        "    else:  # a goal\n",
        "      reward = self._layout[new_y, new_x]\n",
        "      discount = 0.\n",
        "      new_state = self._start_state\n",
        "      step_type = dm_env.StepType.LAST\n",
        "\n",
        "    self._state = new_state\n",
        "    self._num_episode_steps += 1\n",
        "    if (self._max_episode_length is not None and\n",
        "        self._num_episode_steps >= self._max_episode_length):\n",
        "      step_type = dm_env.StepType.LAST\n",
        "    return dm_env.TimeStep(\n",
        "        step_type=step_type,\n",
        "        reward=np.float32(reward),\n",
        "        discount=discount,\n",
        "        observation=self.get_obs())\n",
        "\n",
        "  def plot_grid(self, add_start=True):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(self._layout <= -1, interpolation='nearest')\n",
        "    ax = plt.gca()\n",
        "    ax.grid(0)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # Add start/goal\n",
        "    if add_start:\n",
        "      plt.text(\n",
        "          self._start_state[1],\n",
        "          self._start_state[0],\n",
        "          r'$\\mathbf{S}$',\n",
        "          fontsize=16,\n",
        "          ha='center',\n",
        "          va='center')\n",
        "    plt.text(\n",
        "        self._goal_state[1],\n",
        "        self._goal_state[0],\n",
        "        r'$\\mathbf{G}$',\n",
        "        fontsize=16,\n",
        "        ha='center',\n",
        "        va='center')\n",
        "    h, w = self._layout.shape\n",
        "    for y in range(h - 1):\n",
        "      plt.plot([-0.5, w - 0.5], [y + 0.5, y + 0.5], '-w', lw=2)\n",
        "    for x in range(w - 1):\n",
        "      plt.plot([x + 0.5, x + 0.5], [-0.5, h - 0.5], '-w', lw=2)\n",
        "\n",
        "  def plot_state(self, return_rgb=False):\n",
        "    self.plot_grid(add_start=False)\n",
        "    # Add the agent location\n",
        "    plt.text(\n",
        "        self._state[1],\n",
        "        self._state[0],\n",
        "        u'',\n",
        "        # fontname='symbola',\n",
        "        fontsize=18,\n",
        "        ha='center',\n",
        "        va='center',\n",
        "    )\n",
        "    if return_rgb:\n",
        "      fig = plt.gcf()\n",
        "      plt.axis('tight')\n",
        "      plt.subplots_adjust(0, 0, 1, 1, 0, 0)\n",
        "      fig.canvas.draw()\n",
        "      data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "      w, h = fig.canvas.get_width_height()\n",
        "      data = data.reshape((h, w, 3))\n",
        "      plt.close(fig)\n",
        "      return data\n",
        "\n",
        "  def plot_policy(self, policy):\n",
        "    action_names = [\n",
        "        r'$\\uparrow$', r'$\\rightarrow$', r'$\\downarrow$', r'$\\leftarrow$'\n",
        "    ]\n",
        "    self.plot_grid()\n",
        "    plt.title('Policy Visualization')\n",
        "    h, w = self._layout.shape\n",
        "    for y in range(h):\n",
        "      for x in range(w):\n",
        "        # if ((y, x) != self._start_state) and ((y, x) != self._goal_state):\n",
        "        if (y, x) != self._goal_state:\n",
        "          action_name = action_names[policy[y, x]]\n",
        "          plt.text(x, y, action_name, ha='center', va='center')\n",
        "\n",
        "  def plot_greedy_policy(self, q):\n",
        "    greedy_actions = np.argmax(q, axis=2)\n",
        "    self.plot_policy(greedy_actions)\n",
        "\n",
        "\n",
        "def build_gridworld_task(task,\n",
        "                         discount=0.9,\n",
        "                         penalty_for_walls=-5,\n",
        "                         observation_type=ObservationType.STATE_INDEX,\n",
        "                         max_episode_length=200):\n",
        "  \"\"\"Construct a particular Gridworld layout with start/goal states.\n",
        "\n",
        "  Args:\n",
        "      task: string name of the task to use. One of {'simple', 'obstacle',\n",
        "        'random_goal'}.\n",
        "      discount: Discounting factor included in all Timesteps.\n",
        "      penalty_for_walls: Reward added when hitting a wall (should be negative).\n",
        "      observation_type: Enum observation type to use. One of:\n",
        "        * ObservationType.STATE_INDEX: int32 index of agent occupied tile.\n",
        "        * ObservationType.AGENT_ONEHOT: NxN float32 grid, with a 1 where the\n",
        "          agent is and 0 elsewhere.\n",
        "        * ObservationType.GRID: NxNx3 float32 grid of feature channels.\n",
        "          First channel contains walls (1 if wall, 0 otherwise), second the\n",
        "          agent position (1 if agent, 0 otherwise) and third goal position\n",
        "          (1 if goal, 0 otherwise)\n",
        "        * ObservationType.AGENT_GOAL_POS: float32 tuple with\n",
        "          (agent_y, agent_x, goal_y, goal_x).\n",
        "      max_episode_length: If set, will terminate an episode after this many\n",
        "        steps.\n",
        "  \"\"\"\n",
        "  tasks_specifications = {\n",
        "      'simple': {\n",
        "          'layout': [\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "          ],\n",
        "          'start_state': (2, 2),\n",
        "          'goal_state': (7, 2)\n",
        "      },\n",
        "      'obstacle': {\n",
        "          'layout': [\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, -1, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "          ],\n",
        "          'start_state': (2, 2),\n",
        "          'goal_state': (2, 8)\n",
        "      },\n",
        "      'random_goal': {\n",
        "          'layout': [\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, -1, -1, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, 0, 0, 0, 0, 0, 0, 0, 0, -1],\n",
        "              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "          ],\n",
        "          'start_state': (2, 2),\n",
        "          # 'randomize_goals': True\n",
        "      },\n",
        "  }\n",
        "  return GridWorld(\n",
        "      discount=discount,\n",
        "      penalty_for_walls=penalty_for_walls,\n",
        "      observation_type=observation_type,\n",
        "      max_episode_length=max_episode_length,\n",
        "      **tasks_specifications[task])\n",
        "\n",
        "\n",
        "def setup_environment(environment):\n",
        "  \"\"\"Returns the environment and its spec.\"\"\"\n",
        "\n",
        "  # Make sure the environment outputs single-precision floats.\n",
        "  environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "  # Grab the spec of the environment.\n",
        "  environment_spec = specs.make_environment_spec(environment)\n",
        "\n",
        "  return environment, environment_spec"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rIDQCGIQnnF-"
      },
      "source": [
        "\n",
        "We will use two distinct tabular GridWorlds:\n",
        "* `simple` where the goal is at the bottom left of the grid, little navigation required.\n",
        "* `obstacle` where the goal is behind an obstacle the agent must avoid.\n",
        "\n",
        "You can visualize the grid worlds by running the cell below. \n",
        "\n",
        "Note that **S** indicates the start state and **G** indicates the goal. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "L_si9LnfnnF-",
        "outputId": "09667125-a1c6-4583-fb5b-4b1b2a67ae1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Visualise GridWorlds\n",
        "\n",
        "# Instantiate two tabular environments, a simple task, and one that involves\n",
        "# the avoidance of an obstacle.\n",
        "simple_grid = build_gridworld_task(\n",
        "    task='simple', observation_type=ObservationType.GRID)\n",
        "obstacle_grid = build_gridworld_task(\n",
        "    task='obstacle', observation_type=ObservationType.GRID)\n",
        "\n",
        "# Plot them.\n",
        "simple_grid.plot_grid()\n",
        "plt.title('Simple')\n",
        "\n",
        "obstacle_grid.plot_grid()\n",
        "plt.title('Obstacle')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Obstacle')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kmeadbxOnnF-"
      },
      "source": [
        "\n",
        "In this environment, the agent has four possible  <font color='blue'>**actions**</font>: `up`, `right`, `down`, and `left`.  The <font color='green'>**reward**</font> is `-5` for bumping into a wall, `+10` for reaching the goal, and `0` otherwise. The episode ends when the agent reaches the goal, and otherwise continues. The **discount** on continuing steps, is $\\gamma = 0.9$. \n",
        "\n",
        "Before we start building an agent to interact with this environment, let's first look at the types of objects the environment either returns (e.g. <font color='redorange'>**observations**</font>) or consumes (e.g. <font color='blue'>**actions**</font>). The `environment_spec` will show you the form of the <font color='redorange'>**observations**</font>, <font color='green'>**rewards**</font> and **discounts** that the environment exposes and the form of the <font color='blue'>**actions**</font> that can be taken.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "PDnZwbMPnnF_",
        "outputId": "1c0e3d61-7658-45aa-b6c0-c6e8c353e12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Look at environment_spec { form-width: \"30%\" }\n",
        "\n",
        "# Note: setup_environment is implemented in the same cell as GridWorld.\n",
        "environment, environment_spec = setup_environment(simple_grid)\n",
        "\n",
        "print('actions:\\n', environment_spec.actions, '\\n')\n",
        "print('observations:\\n', environment_spec.observations, '\\n')\n",
        "print('rewards:\\n', environment_spec.rewards, '\\n')\n",
        "print('discounts:\\n', environment_spec.discounts, '\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actions:\n",
            " DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=3, num_values=4) \n",
            "\n",
            "observations:\n",
            " Array(shape=(9, 10, 3), dtype=dtype('float32'), name='observation_grid') \n",
            "\n",
            "rewards:\n",
            " Array(shape=(), dtype=dtype('float32'), name='reward') \n",
            "\n",
            "discounts:\n",
            " BoundedArray(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mVHenXz0nnF_"
      },
      "source": [
        "\n",
        "We first set the environment to its initial state by calling the `reset()` method which returns the first observation and resets the agent to the starting location.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "vc4JIEyMnnF_"
      },
      "source": [
        "environment.reset()\n",
        "environment.plot_state()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "0KVveiCdnnF_"
      },
      "source": [
        "Now we want to take an action to interact with the environment. We do this by passing a valid action to the `dm_env.Environment.step()` method which returns a `dm_env.TimeStep` namedtuple with fields `(step_type, reward, discount, observation)`.\n",
        "\n",
        "Let's take an action and visualise the resulting state of the grid-world. (You'll need to rerun the cell if you pick a new action.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twwTODNrzKUP"
      },
      "source": [
        "**Note for kaggle users:** As kaggle does not render the forms automatically the students should be careful to notice the various instructions and manually play around with the values for the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "n-G7VpQMnnGA"
      },
      "source": [
        "# @title Pick an action and see the state changing\n",
        "action = \"left\" #@param [\"up\", \"right\", \"down\", \"left\"] {type:\"string\"}\n",
        "\n",
        "action_int = {'up': 0,\n",
        "              'right': 1,\n",
        "              'down': 2,\n",
        "              'left':3 }\n",
        "action = int(action_int[action])\n",
        "timestep = environment.step(action)  # pytype: dm_env.TimeStep\n",
        "environment.plot_state()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "dwGjhrIinnGA"
      },
      "source": [
        "# @title Run loop  { form-width: \"30%\" }\n",
        "# @markdown This function runs an agent in the environment for a number of\n",
        "# @markdown episodes, allowing it to learn.\n",
        "\n",
        "# @markdown *Double-click* to inspect the `run_loop` function.\n",
        "\n",
        "\n",
        "def run_loop(environment,\n",
        "             agent,\n",
        "             num_episodes=None,\n",
        "             num_steps=None,\n",
        "             logger_time_delta=1.,\n",
        "             label='training_loop',\n",
        "             log_loss=False,\n",
        "             ):\n",
        "  \"\"\"Perform the run loop.\n",
        "\n",
        "  We are following the Acme run loop.\n",
        "\n",
        "  Run the environment loop for `num_episodes` episodes. Each episode is itself\n",
        "  a loop which interacts first with the environment to get an observation and\n",
        "  then give that observation to the agent in order to retrieve an action. Upon\n",
        "  termination of an episode a new episode will be started. If the number of\n",
        "  episodes is not given then this will interact with the environment\n",
        "  infinitely.\n",
        "\n",
        "  Args:\n",
        "    environment: dm_env used to generate trajectories.\n",
        "    agent: acme.Actor for selecting actions in the run loop.\n",
        "    num_steps: number of steps to run the loop for. If `None` (default), runs\n",
        "      without limit.\n",
        "    num_episodes: number of episodes to run the loop for. If `None` (default),\n",
        "      runs without limit.\n",
        "    logger_time_delta: time interval (in seconds) between consecutive logging\n",
        "      steps.\n",
        "    label: optional label used at logging steps.\n",
        "  \"\"\"\n",
        "  logger = loggers.TerminalLogger(label=label, time_delta=logger_time_delta)\n",
        "  iterator = range(num_episodes) if num_episodes else itertools.count()\n",
        "  all_returns = []\n",
        "\n",
        "  num_total_steps = 0\n",
        "  for episode in iterator:\n",
        "    # Reset any counts and start the environment.\n",
        "    start_time = time.time()\n",
        "    episode_steps = 0\n",
        "    episode_return = 0\n",
        "    episode_loss = 0\n",
        "\n",
        "    timestep = environment.reset()\n",
        "\n",
        "    # Make the first observation.\n",
        "    agent.observe_first(timestep)\n",
        "\n",
        "    # Run an episode.\n",
        "    while not timestep.last():\n",
        "      # Generate an action from the agent's policy and step the environment.\n",
        "      action = agent.select_action(timestep.observation)\n",
        "      timestep = environment.step(action)\n",
        "\n",
        "      # Have the agent observe the timestep and let the agent update itself.\n",
        "      agent.observe(action, next_timestep=timestep)\n",
        "      agent.update()\n",
        "\n",
        "      # Book-keeping.\n",
        "      episode_steps += 1\n",
        "      num_total_steps += 1\n",
        "      episode_return += timestep.reward\n",
        "\n",
        "      if log_loss:\n",
        "        episode_loss += agent.last_loss\n",
        "\n",
        "      if num_steps is not None and num_total_steps >= num_steps:\n",
        "        break\n",
        "\n",
        "    # Collect the results and combine with counts.\n",
        "    steps_per_second = episode_steps / (time.time() - start_time)\n",
        "    result = {\n",
        "        'episode': episode,\n",
        "        'episode_length': episode_steps,\n",
        "        'episode_return': episode_return,\n",
        "    }\n",
        "    if log_loss:\n",
        "      result['loss_avg'] = episode_loss/episode_steps\n",
        "\n",
        "    all_returns.append(episode_return)\n",
        "\n",
        "    # Log the given results.\n",
        "    logger.write(result)\n",
        "\n",
        "    if num_steps is not None and num_total_steps >= num_steps:\n",
        "      break\n",
        "  return all_returns"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "X1yETnKennGB"
      },
      "source": [
        "# @title Implement the evaluation loop { form-width: \"30%\" }\n",
        "# @markdown This function runs the agent in the environment for a number of\n",
        "# @markdown episodes, without allowing it to learn, in order to evaluate it.\n",
        "\n",
        "# @markdown *Double-click* to inspect the `evaluate` function.\n",
        "\n",
        "def evaluate(environment: dm_env.Environment,\n",
        "             agent: acme.Actor,\n",
        "             evaluation_episodes: int):\n",
        "  frames = []\n",
        "\n",
        "  for episode in range(evaluation_episodes):\n",
        "    timestep = environment.reset()\n",
        "    episode_return = 0\n",
        "    steps = 0\n",
        "    while not timestep.last():\n",
        "      frames.append(environment.plot_state(return_rgb=True))\n",
        "\n",
        "      action = agent.select_action(timestep.observation)\n",
        "      timestep = environment.step(action)\n",
        "      steps += 1\n",
        "      episode_return += timestep.reward\n",
        "    print(\n",
        "        f'Episode {episode} ended with reward {episode_return} in {steps} steps'\n",
        "    )\n",
        "  return frames\n",
        "\n",
        "def display_video(frames: Sequence[np.ndarray],\n",
        "                  filename: str = 'temp.mp4',\n",
        "                  frame_rate: int = 12):\n",
        "  \"\"\"Save and display video.\"\"\"\n",
        "  # Write the frames to a video.\n",
        "  with imageio.get_writer(filename, fps=frame_rate) as video:\n",
        "    for frame in frames:\n",
        "      video.append_data(frame)\n",
        "\n",
        "  # Read video and display the video.\n",
        "  video = open(filename, 'rb').read()\n",
        "  b64_video = base64.b64encode(video)\n",
        "  video_tag = ('<video  width=\"320\" height=\"240\" controls alt=\"test\" '\n",
        "               'src=\"data:video/mp4;base64,{0}\">').format(b64_video.decode())\n",
        "  return IPython.display.HTML(video_tag)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8VkhrepTnnGB"
      },
      "source": [
        "## Section 2.2: The Agent\n",
        "\n",
        "We will be implementing Tabular & Function Approximation agents. Tabular agents are purely in Python.\n",
        "\n",
        "All agents will share the same interface from the Acme `Actor`. Here we borrow a figure from Acme to show how this interaction occurs:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3gzAuYWInnGC"
      },
      "source": [
        "### Agent interface\n",
        "\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1T7FTpA9RgDYFkciDFZK4brNyURZN_ZGp\" width=\"500\" /></center>\n",
        "\n",
        "Each agent implements the following functions:\n",
        "\n",
        "```python\n",
        "class Agent(acme.Actor):\n",
        "  def __init__(self, number_of_actions, number_of_states, ...):\n",
        "    \"\"\"Provides the agent the number of actions and number of states.\"\"\"\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    \"\"\"Generates actions from observations.\"\"\"\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    \"\"\"Records the initial timestep in a trajectory.\"\"\"\n",
        "  \n",
        "  def observe(self, action, next_timestep):\n",
        "    \"\"\"Records the transition which occurred from taking an action.\"\"\"\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Updates the agent's internals to potentially change its behavior.\"\"\"\n",
        "```\n",
        "\n",
        "Remarks on the `observe()` function:\n",
        "\n",
        "1. In the last method, the `next_timestep` provides the `reward`, `discount`, and `observation` that resulted from selecting `action`.\n",
        "\n",
        "2. The `next_timestep.step_type` will be either `MID` or `LAST` and should be used to determine whether this is the last observation in the episode.\n",
        "\n",
        "3. The `next_timestep.step_type` cannot be `FIRST`; such a timestep should only ever be given to `observe_first()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7a-lXJVMnnGC"
      },
      "source": [
        "### Coding Exercise 2.1: Random Agent\n",
        "\n",
        "Below is a partially complete implemention of an agent that follows a random (non-learning) policy. Fill in the ```select_action``` method.\n",
        "\n",
        "The ```select_action``` method should return a random **integer** between 0 and ```self._num_actions``` (not a tensor or an array!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "uFaiCwh2nnGC"
      },
      "source": [
        "class RandomAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self, environment_spec):\n",
        "    \"\"\"Gets the number of available actions from the environment spec.\"\"\"\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    \"\"\"Selects an action uniformly at random.\"\"\"\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete the select action method\")\n",
        "    #################################################\n",
        "    # TODO return a random integer beween 0 and self._num_actions.\n",
        "    # HINT: see the reference for how to sample a random integer in numpy:\n",
        "    #   https://numpy.org/doc/1.16/reference/routines.random.html\n",
        "    action = ...\n",
        "    return action\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    \"\"\"Does not record as the RandomAgent has no use for data.\"\"\"\n",
        "    pass\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    \"\"\"Does not record as the RandomAgent has no use for data.\"\"\"\n",
        "    pass\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Does not update as the RandomAgent does not learn from data.\"\"\"\n",
        "    pass"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "4DF5tJV8nnGD"
      },
      "source": [
        "# to_remove solution\n",
        "class RandomAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self, environment_spec):\n",
        "    \"\"\"Gets the number of available actions from the environment spec.\"\"\"\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    \"\"\"Selects an action uniformly at random.\"\"\"\n",
        "    # TODO return a random integer beween 0 and self._num_actions.\n",
        "    # HINT: see the reference for how to sample a random integer in numpy:\n",
        "    #   https://numpy.org/doc/1.16/reference/routines.random.html\n",
        "    action = np.random.randint(self._num_actions)\n",
        "    return action\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    \"\"\"Does not record as the RandomAgent has no use for data.\"\"\"\n",
        "    pass\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    \"\"\"Does not record as the RandomAgent has no use for data.\"\"\"\n",
        "    pass\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Does not update as the RandomAgent does not learn from data.\"\"\"\n",
        "    pass"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "F-kdmXCRnnGD",
        "cellView": "form",
        "outputId": "bb792af2-75f6-45cf-a959-e27f24e3477c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "# @title Visualisation of a random agent in GridWorld { form-width: \"30%\" }\n",
        "\n",
        "# Create the agent by giving it the action space specification.\n",
        "agent = RandomAgent(environment_spec)\n",
        "\n",
        "# Run the agent in the evaluation loop, which returns the frames.\n",
        "frames = evaluate(environment, agent, evaluation_episodes=1)\n",
        "\n",
        "# Visualize the random agent's episode.\n",
        "display_video(frames)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0 ended with reward -115.0 in 102 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video  width=\"320\" height=\"240\" controls alt=\"test\" src=\"data:video/mp4;base64,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\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "5lrHinFunnGE"
      },
      "source": [
        "---\n",
        "# Section 3: The Bellman Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "J_ZDQruGnnGE",
        "cellView": "form",
        "outputId": "a810519f-546d-48db-e0ce-e221527fbc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "e6d0aaebd52b4c768f942dc819b6cf23",
            "33139b1fc28c404ab1c0e5b3364c94c1",
            "f7b2612127534df5bb648e3e9a902cea",
            "fa9b677c832f4b06831b70a838ca47f3",
            "336a9f475719417abfbcc878f7cd3d63",
            "8126febbc65f445d80c003114aacd82c"
          ]
        }
      },
      "source": [
        "# @title Video 3: The Bellman Equation\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1Lv411E7CB\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"cLCoNBmYUns\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6d0aaebd52b4c768f942dc819b6cf23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3jFJMIZonnGE"
      },
      "source": [
        "\n",
        "\n",
        "In this tutorial we focus mainly on <font color='green'>**value based methods**</font>, where agents maintain a value for all state-action pairs and use those estimates to choose actions that maximize that <font color='green'>**value**</font> (instead of maintaining a policy directly, like in <font color='blue'>**policy gradient methods**</font>). \n",
        "\n",
        "We represent the <font color='green'>**action-value function**</font> (otherwise known as $\\color{green}Q$-function associated with following/employing a policy $\\pi$ in a given MDP as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\color{green}Q^{\\color{blue}{\\pi}}(\\color{red}{s},\\color{blue}{a}) = \\mathbb{E}_{\\tau \\sim P^{\\color{blue}{\\pi}}} \\left[ \\sum_t \\gamma^t \\color{green}{r_t}| s_0=\\color{red}s,a_0=\\color{blue}{a} \\right]\n",
        "\\end{equation}\n",
        "\n",
        "where $\\tau = \\{\\color{red}{s_0}, \\color{blue}{a_0}, \\color{green}{r_0}, \\color{red}{s_1}, \\color{blue}{a_1}, \\color{green}{r_1}, \\cdots \\}$\n",
        "\n",
        "\n",
        "Recall that efficient value estimations are based on the famous **_Bellman Expectation Equation_**:\n",
        "\n",
        "\\begin{equation}\n",
        "\\color{green}Q^\\color{blue}{\\pi}(\\color{red}{s},\\color{blue}{a}) =    \\sum_{\\color{red}{s'}\\in \\color{red}{\\mathcal{S}}} \n",
        "\\color{purple}P(\\color{red}{s'} |\\color{red}{s},\\color{blue}{a})\n",
        "\\left(\n",
        "  \\color{green}{R}(\\color{red}{s},\\color{blue}{a}, \\color{red}{s'}) \n",
        "  + \\gamma \\color{green}V^\\color{blue}{\\pi}(\\color{red}{s'}) \n",
        "  \\right)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\color{green}V^\\color{blue}{\\pi}$ is the expected $\\color{green}Q^\\color{blue}{\\pi}$ value for a particular state, i.e. $\\color{green}V^\\color{blue}{\\pi}(\\color{red}{s}) = \\sum_{\\color{blue}{a} \\in \\color{blue}{\\mathcal{A}}} \\color{blue}{\\pi}(\\color{blue}{a} |\\color{red}{s}) \\color{green}Q^\\color{blue}{\\pi}(\\color{red}{s},\\color{blue}{a})$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "JUGGwX21nnGF"
      },
      "source": [
        "---\n",
        "# Section 4: Policy Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "1rBjNRbunnGF",
        "cellView": "form",
        "outputId": "81780df0-3f29-4be1-a15a-50bf7ee5741e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "ec7d8e59ec1b4e3997be73c73f23e07e",
            "6f3e74468ea04940947aa23d35df0f62",
            "ee2c43bee8ae45b991070da90642b78a",
            "b900d95177c5456cb11779b6595695fe",
            "565fb67ce4324c83a9d48546703eada4",
            "9090b6b4b95d449881fb11e97efabbdd"
          ]
        }
      },
      "source": [
        "# @title Video 4: Policy Evaluation\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV15f4y157zA\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"HAxR4SuaZs4\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec7d8e59ec1b4e3997be73c73f23e07e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ddLdiGe6nnGG"
      },
      "source": [
        "### Lecture footnotes: \n",
        "\n",
        "**Episodic vs non-episodic environments:** Up until now, we've mainly been talking about episodic environments, or environments that terminate and reset (resampled) after a finite number of steps. However, there are also *non-episodic* environments, in which an agent cannot count on the environment resetting. Thus, they are forced to learn in a *continual* fashion.\n",
        "\n",
        "**Policy iteration vs value iteration:** Compare the two equations below, noting that the only difference is that in value iteration, the second sum is replaced by a max.\n",
        "\n",
        "*Policy iteration (using Bellman expectation equation)*\n",
        "\\begin{equation}\n",
        "\\color{green}Q_\\color{green}{k}(\\color{red}{s},\\color{blue}{a}) \\leftarrow  \\color{green}{R}(\\color{red}{s},\\color{blue}{a}) +\\gamma \\sum_{\\color{red}{s'}\\in \\color{red}{\\mathcal{S}}} \n",
        "\\color{purple}P(\\color{red}{s'} |\\color{red}{s},\\color{blue}{a})\n",
        "\\sum_{\\color{blue}{a'} \\in \\color{blue}{\\mathcal{A}}} \\color{blue}{\\pi_{k-1}}(\\color{blue}{a'} |\\color{red}{s'}) \\color{green}{Q_{k-1}}(\\color{red}{s'},\\color{blue}{a'})\n",
        "\\end{equation}\n",
        "\n",
        "*Value iteration (using Bellman optimality equation)*\n",
        "\\begin{equation}\n",
        "\\color{green}Q_\\color{green}{k}(\\color{red}{s},\\color{blue}{a}) \\leftarrow  \\color{green}{R}(\\color{red}{s},\\color{blue}{a}) +\\gamma \\sum_{\\color{red}{s'}\\in \\color{red}{\\mathcal{S}}} \n",
        "\\color{purple}P(\\color{red}{s'} |\\color{red}{s},\\color{blue}{a})\n",
        "\\max_{\\color{blue}{a'}} \\color{green}{Q_{k-1}}(\\color{red}{s'},\\color{blue}{a'})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "XYq0SA82nnGG"
      },
      "source": [
        "### Coding Exercise 4.1 Policy Evaluation Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "F7Jd5LWLnnGG"
      },
      "source": [
        "\n",
        "Tabular agents implement a function `q_values()` returning a matrix of Q values\n",
        "of shape: (`number_of_states`, `number_of_actions`)\n",
        "\n",
        "In this section, we will implement a `PolicyEvalAgent` as an ACME actor: given an `evaluation_policy` $\\pi_e$ and a `behaviour_policy` $\\pi_b$, it will use the `behaviour_policy` to choose actions, and it will use the corresponding trajectory data to evaluate the `evaluation_policy` (i.e. compute the Q-values as if you were following the `evaluation_policy`). \n",
        "\n",
        "Algorithm:\n",
        "\n",
        "**Initialize** $Q(\\color{red}{s}, \\color{blue}{a})$ for all $\\color{red}{s}$  $\\mathcal{\\color{red}S}$ and $\\color{blue}a$  $\\mathcal{\\color{blue}A}(\\color{red}s)$\n",
        "\n",
        "**Loop forever**:\n",
        "\n",
        "1. $\\color{red}{s} \\gets{}$current (nonterminal) state\n",
        " \n",
        "2. $\\color{blue}{a} \\gets{} \\text{behaviour_policy }\\pi_b(\\color{red}s)$\n",
        " \n",
        "3. Take action $\\color{blue}{a}$; observe resulting reward $\\color{green}{r}$, discount $\\gamma$, and state, $\\color{red}{s'}$\n",
        "\n",
        "4. Compute TD-error: $\\delta = \\color{green}R + \\gamma Q(\\color{red}{s'}, \\underbrace{\\pi_e(\\color{red}{s'}}_{\\color{blue}{a'}}))  Q(\\color{red}s, \\color{blue}a)$\n",
        "\n",
        "4. Update Q-value with a small $\\alpha$ step: $Q(\\color{red}s, \\color{blue}a) \\gets Q(\\color{red}s, \\color{blue}a) + \\alpha \\delta$\n",
        "\n",
        "\n",
        "We will use a uniform `random policy` as our `evaluation policy` here, but you could replace this with any policy you want, such as a greedy one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "JgO91JwDnnGH"
      },
      "source": [
        "# Uniform random policy\n",
        "def random_policy(q):\n",
        "  return np.random.randint(4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "idvFGsh6nnGH"
      },
      "source": [
        "class PolicyEvalAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self, environment_spec, evaluated_policy,\n",
        "               behaviour_policy=random_policy, step_size=0.1):\n",
        "\n",
        "    self._state = None\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._number_of_states = environment_spec.observations.num_values\n",
        "    self._number_of_actions = environment_spec.actions.num_values\n",
        "    self._step_size = step_size\n",
        "    self._behaviour_policy = behaviour_policy\n",
        "    self._evaluated_policy = evaluated_policy\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Initialize your Q-values!\")\n",
        "    #################################################\n",
        "    # TODO Initialize the Q-values to be all zeros.\n",
        "    # (Note: can also be random, but we use zeros here for reproducibility)\n",
        "    # HINT: This is a table of state and action pairs, so needs to be a 2-D\n",
        "    #   array. See the reference for how to create this in numpy:\n",
        "    #   https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
        "    self._q = ...\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    # return the Q values\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Select an action\n",
        "    return self._behaviour_policy(self._q[observation])\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "\n",
        "    # Compute TD-Error.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Need to select the next action\")\n",
        "    #################################################\n",
        "    # TODO Select the next action from the evaluation policy\n",
        "    # HINT: Refer to step 4 of the algorithm above.\n",
        "    next_a = ...\n",
        "    self._td_error = r + g * self._q[next_s, next_a] - self._q[s, a]\n",
        "\n",
        "  def update(self):\n",
        "    # Updates\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    # Q-value table update.\n",
        "    self._q[s, a] += self._step_size * self._td_error\n",
        "    # Update the state\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "BbJi-mn1nnGI"
      },
      "source": [
        "# to_remove solution\n",
        "class PolicyEvalAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self, environment_spec, evaluated_policy,\n",
        "               behaviour_policy=random_policy, step_size=0.1):\n",
        "\n",
        "    self._state = None\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._number_of_states = environment_spec.observations.num_values\n",
        "    self._number_of_actions = environment_spec.actions.num_values\n",
        "    self._step_size = step_size\n",
        "    self._behaviour_policy = behaviour_policy\n",
        "    self._evaluated_policy = evaluated_policy\n",
        "    # TODO Initialize the Q-values to be all zeros.\n",
        "    # (Note: can also be random, but we use zeros here for reproducibility)\n",
        "    # HINT: This is a table of state and action pairs, so needs to be a 2-D\n",
        "    #   array. See the reference for how to create this in numpy:\n",
        "    #   https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
        "    self._q = np.zeros((self._number_of_states, self._number_of_actions))\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    # return the Q values\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Select an action\n",
        "    return self._behaviour_policy(self._q[observation])\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "\n",
        "    # Compute TD-Error.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    # TODO Select the next action from the evaluation policy\n",
        "    # HINT: Refer to step 4 of the algorithm above.\n",
        "    next_a = self._evaluated_policy(self._q[next_s])\n",
        "    self._td_error = r + g * self._q[next_s, next_a] - self._q[s, a]\n",
        "\n",
        "  def update(self):\n",
        "    # Updates\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    # Q-value table update.\n",
        "    self._q[s, a] += self._step_size * self._td_error\n",
        "    # Update the state\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "Rm6OGqTInnGI",
        "outputId": "f1fc8cc2-9357-4464-8ae6-f03656cb567d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Perform policy evaluation { form-width: \"30%\" }\n",
        "# @markdown Here you can visualize the state value and action-value functions for the \"simple\" task.\n",
        "num_steps = 1e3\n",
        "\n",
        "# Create the environment\n",
        "grid = build_gridworld_task(task='simple')\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# Create the policy evaluation agent to evaluate a random policy.\n",
        "agent = PolicyEvalAgent(environment_spec, evaluated_policy=random_policy)\n",
        "\n",
        "# run experiment and get the value functions from agent\n",
        "returns = run_loop(environment=environment, agent=agent, num_steps=int(num_steps))\n",
        "\n",
        "# get the q-values\n",
        "q = agent.q_values.reshape(grid._layout.shape + (4,))\n",
        "\n",
        "# visualize value functions\n",
        "print('AFTER {} STEPS ...'.format(num_steps))\n",
        "plot_action_values(q, epsilon=1.)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER 1000.0 STEPS ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "E-B6pcVDnnGI"
      },
      "source": [
        "---\n",
        "# Section 5: Tabular Value-Based Model-Free Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "pKfgJb7GnnGJ",
        "cellView": "form",
        "outputId": "774d6f37-d1ea-46d0-a5d0-c6b7cb22bf8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "4a344b026c8e445f9a14ace7210c76f0",
            "2f3281569bc64259b42df2267a751573",
            "2ce1a49aa4a944b99b380e62cfd56b42",
            "15653d47eae44707a9ac64c80671c872",
            "0fd5189873c74a91abc7a990b09e2d4d",
            "e9fca183305b4e0eb79ea5b279c06019"
          ]
        }
      },
      "source": [
        "# @title Video 5: Model-Free Learning\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1iU4y1n7M6\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"Y4TweUYnexU\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a344b026c8e445f9a14ace7210c76f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "uJ2thgIhnnGJ"
      },
      "source": [
        "### Lecture footnotes: \n",
        "\n",
        "**On-policy (SARSA) vs off-policy (Q-learning) TD control:** Compare the two equations below and see that the only difference is that for Q-learning, the update is performed assuming that a greedy policy is followed, which is not the one used to collect the data, hence the name *off-policy*. \n",
        "\n",
        "*SARSA*\n",
        "\\begin{equation}\n",
        "\\color{green}Q(\\color{red}{s},\\color{blue}{a}) \\leftarrow  \\color{green}Q(\\color{red}{s},\\color{blue}{a}) +\\alpha(\\color{green}{r} + \\gamma\\color{green}{Q}(\\color{red}{s'},\\color{blue}{a'}) - \\color{green}{Q}(\\color{red}{s},\\color{blue}{a}))\n",
        "\\end{equation}\n",
        "\n",
        "*Q-learning*\n",
        "\\begin{equation}\n",
        "\\color{green}Q(\\color{red}{s},\\color{blue}{a}) \\leftarrow  \\color{green}Q(\\color{red}{s},\\color{blue}{a}) +\\alpha(\\color{green}{r} + \\gamma\\max_{\\color{blue}{a'}} \\color{green}{Q}(\\color{red}{s'},\\color{blue}{a'}) - \\color{green}{Q}(\\color{red}{s},\\color{blue}{a}))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BF0kjOlsnnGJ"
      },
      "source": [
        "## Section 5.1: On-policy control: SARSA Agent\n",
        "In this section, we are focusing on control RL algorithms, which perform the **evaluation** and **improvement** of the policy synchronously. That is, the policy that is being evaluated improves as the agent is using it to interact with the environent.\n",
        "\n",
        "\n",
        "The first algorithm we are going to be looking at is SARSA. This is an **on-policy algorithm** -- i.e: the data collection is done by leveraging the policy we're trying to optimize. \n",
        "\n",
        "As discussed during lectures, a greedy policy with respect to a given $\\color{Green}Q$ fails to explore the environment as needed; we will use instead an $\\epsilon$-greedy policy with respect to $\\color{Green}Q$.\n",
        "\n",
        "### SARSA Algorithm\n",
        "\n",
        "**Input:**\n",
        "- $\\epsilon \\in (0, 1)$ the probability of taking a random action , and\n",
        "- $\\alpha > 0$ the step size, also known as learning rate.\n",
        "\n",
        "**Initialize:** $\\color{green}Q(\\color{red}{s}, \\color{blue}{a})$ for all $\\color{red}{s}$  $\\mathcal{\\color{red}S}$ and $\\color{blue}a$  $\\mathcal{\\color{blue}A}$\n",
        "\n",
        "**Loop forever:**\n",
        "\n",
        "1. Get $\\color{red}s \\gets{}$current (non-terminal) state\n",
        " \n",
        "2. Select $\\color{blue}a \\gets{} \\text{epsilon_greedy}(\\color{green}Q(\\color{red}s, \\cdot))$\n",
        " \n",
        "3. Step in the environment by passing the selected action $\\color{blue}a$\n",
        "\n",
        "4. Observe resulting reward $\\color{green}r$, discount $\\gamma$, and state $\\color{red}{s'}$\n",
        "\n",
        "5. Compute TD error: $\\Delta \\color{green}Q \\gets \n",
        "\\color{green}r + \\gamma \\color{green}Q(\\color{red}{s'}, \\color{blue}{a'})  \\color{green}Q(\\color{red}s, \\color{blue}a)$, <br> where $\\color{blue}{a'} \\gets \\text{epsilon_greedy}(\\color{green}Q(\\color{red}{s'}, \\cdot))$\n",
        "\n",
        "5. Update $\\color{green}Q(\\color{red}s, \\color{blue}a) \\gets \\color{green}Q(\\color{red}s, \\color{blue}a) + \\alpha \\Delta \\color{green}Q$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "CTDEAKWdnnGK"
      },
      "source": [
        "### Coding Exercise 5.1: Implement $\\epsilon$-greedy\n",
        "Below you will find incomplete code for sampling from an $\\epsilon$-greedy policy, to be used later when we implement an agent that learns values according to the SARSA algorithm.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "RHEKwP2WnnGK"
      },
      "source": [
        "def epsilon_greedy(\n",
        "    q_values_at_s: np.ndarray,  # Q-values in state s: Q(s, a).\n",
        "    epsilon: float = 0.1  # Probability of taking a random action.\n",
        "    ):\n",
        "  \"\"\"Return an epsilon-greedy action sample.\"\"\"\n",
        "  #################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your implementation\n",
        "  raise NotImplementedError(\"Student exercise: complete epsilon greedy policy function\")\n",
        "  #################################################\n",
        "  # TODO generate a uniform random number and compare it to epsilon to decide if\n",
        "  # the action should be greedy or not\n",
        "  # HINT: Use np.random.random() to generate a random float from 0 to 1.\n",
        "  if ...:\n",
        "    #TODO Greedy: Pick action with the largest Q-value.\n",
        "    action = ...\n",
        "  else:\n",
        "    # Get the number of actions from the size of the given vector of Q-values.\n",
        "    num_actions = np.array(q_values_at_s).shape[-1]\n",
        "    # TODO else return a random action\n",
        "    # HINT: Use np.random.randint() to generate a random integer.\n",
        "    action = ...\n",
        "\n",
        "  return action"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "1_fjmPh_nnGK"
      },
      "source": [
        "# to_remove solution\n",
        "def epsilon_greedy(\n",
        "    q_values_at_s: np.ndarray,  # Q-values in state s: Q(s, a).\n",
        "    epsilon: float = 0.1  # Probability of taking a random action.\n",
        "    ):\n",
        "  \"\"\"Return an epsilon-greedy action sample.\"\"\"\n",
        "  # TODO generate a uniform random number and compare it to epsilon to decide if\n",
        "  # the action should be greedy or not\n",
        "  # HINT: Use np.random.random() to generate a random float from 0 to 1.\n",
        "  if epsilon < np.random.random():\n",
        "    #TODO Greedy: Pick action with the largest Q-value.\n",
        "    action = np.argmax(q_values_at_s)\n",
        "  else:\n",
        "    # Get the number of actions from the size of the given vector of Q-values.\n",
        "    num_actions = np.array(q_values_at_s).shape[-1]\n",
        "    # TODO else return a random action\n",
        "    # HINT: Use np.random.randint() to generate a random integer.\n",
        "    action = np.random.randint(num_actions)\n",
        "\n",
        "  return action"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "0Xg_GDFJnnGL",
        "outputId": "092a7b2b-acd8-4852-bff0-b7cc45d7d7ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Sample action from $\\epsilon$-greedy { form-width: \"30%\" }\n",
        "# @markdown With $\\epsilon=0.5$, you should see that about half the time, you will get back the optimal\n",
        "# @markdown action 3, but half the time, it will be random.\n",
        "\n",
        "# Create fake q-values\n",
        "q_values = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Set epsilon = 0.5\n",
        "epsilon = 0.5\n",
        "action = epsilon_greedy(q_values, epsilon=epsilon)\n",
        "print(action)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cQ6Idmv1nnGL"
      },
      "source": [
        "### Coding Exercise 5.2: Run your SARSA agent on the `obstacle` environment\n",
        "\n",
        "This environment is similar to the Cliff-walking example from [Sutton & Barto](http://incompleteideas.net/book/RLbook2018.pdf) and allows us to see the different policies learned by on-policy vs off-policy methods. Try varying the number of steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "f4Jc3lAannGL"
      },
      "source": [
        "class SarsaAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               epsilon: float,\n",
        "               step_size: float = 0.1\n",
        "               ):\n",
        "\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._num_states = environment_spec.observations.num_values\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "    # Create the table of Q-values, all initialized at zero.\n",
        "    self._q = np.zeros((self._num_states, self._num_actions))\n",
        "\n",
        "    # Store algorithm hyper-parameters.\n",
        "    self._step_size = step_size\n",
        "    self._epsilon = epsilon\n",
        "\n",
        "    # Containers you may find useful.\n",
        "    self._state = None\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    return epsilon_greedy(self._q[observation], self._epsilon)\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    # Set current state.\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    # Unpacking the timestep to lighten notation.\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "    # Compute the action that would be taken from the next state.\n",
        "    next_a = self.select_action(next_s)\n",
        "    # Compute the on-policy Q-value update.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete the on-policy Q-value update\")\n",
        "    #################################################\n",
        "    # TODO complete the line below to compute the temporal difference error\n",
        "    # HINT: see step 5 in the pseudocode above.\n",
        "    self._td_error = ...\n",
        "\n",
        "  def update(self):\n",
        "    # Optional unpacking to lighten notation.\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete value update\")\n",
        "    #################################################\n",
        "    # Update the Q-value table value at (s, a).\n",
        "    # TODO: Update the Q-value table value at (s, a).\n",
        "    # HINT: see step 6 in the pseudocode above, remember that alpha = step_size!\n",
        "    self._q[s, a] += ...\n",
        "    # Update the current state.\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "DeQ3Q6T-nnGM"
      },
      "source": [
        "# to_remove solution\n",
        "class SarsaAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               epsilon: float,\n",
        "               step_size: float = 0.1\n",
        "               ):\n",
        "\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._num_states = environment_spec.observations.num_values\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "    # Create the table of Q-values, all initialized at zero.\n",
        "    self._q = np.zeros((self._num_states, self._num_actions))\n",
        "\n",
        "    # Store algorithm hyper-parameters.\n",
        "    self._step_size = step_size\n",
        "    self._epsilon = epsilon\n",
        "\n",
        "    # Containers you may find useful.\n",
        "    self._state = None\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    return epsilon_greedy(self._q[observation], self._epsilon)\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    # Set current state.\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    # Unpacking the timestep to lighten notation.\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "    # Compute the action that would be taken from the next state.\n",
        "    next_a = self.select_action(next_s)\n",
        "    # Compute the on-policy Q-value update.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    # Compute the on-policy Q-value update.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    # TODO complete the line below to compute the temporal difference error\n",
        "    # HINT: see step 5 in the pseudocode above.\n",
        "    self._td_error = r + g * self._q[next_s, next_a] - self._q[s, a]\n",
        "\n",
        "  def update(self):\n",
        "    # Optional unpacking to lighten notation.\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    # Update the Q-value table value at (s, a).\n",
        "    # TODO: Update the Q-value table value at (s, a).\n",
        "    # HINT: see step 6 in the pseudocode above, remember that alpha = step_size!\n",
        "    self._q[s, a] += self._step_size * self._td_error\n",
        "    # Update the current state.\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "QieDymNYnnGM",
        "outputId": "42cb5cef-1fd6-48a8-ff0a-0e877ddafbc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Run SARSA agent and visualize value function\n",
        "\n",
        "num_steps = 1e5 # @param {type:\"number\"}\n",
        "num_steps = int(num_steps)\n",
        "\n",
        "# Create the environment.\n",
        "grid = build_gridworld_task(task='obstacle')\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# Create the agent.\n",
        "agent = SarsaAgent(environment_spec, epsilon=0.1, step_size=0.1)\n",
        "\n",
        "# Run the experiment and get the value functions from agent\n",
        "returns = run_loop(environment=environment, agent=agent, num_steps=num_steps)\n",
        "print('AFTER {0:,} STEPS ...'.format(num_steps))\n",
        "\n",
        "# Get the Q-values and reshape them to recover grid-like structure of states.\n",
        "q_values = agent.q_values\n",
        "grid_shape = grid.layout.shape\n",
        "q_values = q_values.reshape([*grid_shape, -1])\n",
        "\n",
        "# Visualize the value and Q-value tables.\n",
        "plot_action_values(q_values, epsilon=1.)\n",
        "\n",
        "# Visualize the greedy policy.\n",
        "environment.plot_greedy_policy(q_values)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER 100,000 STEPS ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cbjxKW2_nnGN"
      },
      "source": [
        "##Section 5.2 Off-policy control: Q-learning Agent\n",
        "Reminder: $\\color{green}Q$-learning is a very powerful and general algorithm, that enables control (figuring out the optimal policy/value function) both on and off-policy.\n",
        "\n",
        "**Initialize** $\\color{green}Q(\\color{red}{s}, \\color{blue}{a})$ for all $\\color{red}{s} \\in \\color{red}{\\mathcal{S}}$ and $\\color{blue}{a} \\in \\color{blue}{\\mathcal{A}}$\n",
        "\n",
        "**Loop forever**:\n",
        "\n",
        "1. Get $\\color{red}{s} \\gets{}$current (non-terminal) state\n",
        " \n",
        "2. Select $\\color{blue}{a} \\gets{} \\text{behaviour_policy}(\\color{red}{s})$\n",
        " \n",
        "3. Step in the environment by passing the selected action $\\color{blue}{a}$\n",
        "\n",
        "4. Observe resulting reward $\\color{green}{r}$, discount $\\gamma$, and state, $\\color{red}{s'}$\n",
        "\n",
        "5. Compute the TD error: $\\Delta \\color{green}Q \\gets \\color{green}{r} + \\gamma \\color{green}Q(\\color{red}{s'}, \\color{blue}{a'})  \\color{green}Q(\\color{red}{s}, \\color{blue}{a})$, <br>\n",
        "where $\\color{blue}{a'} \\gets \\arg\\max_{\\color{blue}{\\mathcal A}} \\color{green}Q(\\color{red}{s'}, \\cdot)$\n",
        "\n",
        "6. Update $\\color{green}Q(\\color{red}{s}, \\color{blue}{a}) \\gets \\color{green}Q(\\color{red}{s}, \\color{blue}{a}) + \\alpha \\Delta \\color{green}Q$\n",
        "\n",
        "Notice that the actions $\\color{blue}{a}$ and $\\color{blue}{a'}$ are not selected using the same policy, hence this algorithm being **off-policy**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6ipK7Ur4nnGN"
      },
      "source": [
        "### Coding Exercise 5.3: Implement Q-Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "NF7E2WKKnnGN"
      },
      "source": [
        "QValues = np.ndarray\n",
        "Action = int\n",
        "# A value-based policy takes the Q-values at a state and returns an action.\n",
        "ValueBasedPolicy = Callable[[QValues], Action]\n",
        "\n",
        "\n",
        "class QLearningAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               behaviour_policy: ValueBasedPolicy,\n",
        "               step_size: float = 0.1):\n",
        "\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._num_states = environment_spec.observations.num_values\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "    # Create the table of Q-values, all initialized at zero.\n",
        "    self._q = np.zeros((self._num_states, self._num_actions))\n",
        "\n",
        "    # Store algorithm hyper-parameters.\n",
        "    self._step_size = step_size\n",
        "\n",
        "    # Store behavior policy.\n",
        "    self._behaviour_policy = behaviour_policy\n",
        "\n",
        "    # Containers you may find useful.\n",
        "    self._state = None\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    return self._behaviour_policy(self._q[observation])\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    # Set current state.\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    # Unpacking the timestep to lighten notation.\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "\n",
        "    # Compute the TD error.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete the off-policy Q-value update\")\n",
        "    #################################################\n",
        "    # TODO complete the line below to compute the temporal difference error\n",
        "    # HINT: This is very similar to what we did for SARSA, except keep in mind\n",
        "    # that we're now taking a max over the q-values (see lecture footnotes above).\n",
        "    # You will find the function np.max() useful.\n",
        "    self._td_error = ...\n",
        "\n",
        "  def update(self):\n",
        "    # Optional unpacking to lighten notation.\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete value update\")\n",
        "    #################################################\n",
        "    # Update the Q-value table value at (s, a).\n",
        "    # TODO: Update the Q-value table value at (s, a).\n",
        "    # HINT: see step 6 in the pseudocode above, remember that alpha = step_size!\n",
        "    self._q[...] += ...\n",
        "    # Update the current state.\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Sgw-aANlnnGO"
      },
      "source": [
        "# to_remove solution\n",
        "QValues = np.ndarray\n",
        "Action = int\n",
        "# A value-based policy takes the Q-values at a state and returns an action.\n",
        "ValueBasedPolicy = Callable[[QValues], Action]\n",
        "\n",
        "\n",
        "class QLearningAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               behaviour_policy: ValueBasedPolicy,\n",
        "               step_size: float = 0.1):\n",
        "\n",
        "    # Get number of states and actions from the environment spec.\n",
        "    self._num_states = environment_spec.observations.num_values\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "\n",
        "    # Create the table of Q-values, all initialized at zero.\n",
        "    self._q = np.zeros((self._num_states, self._num_actions))\n",
        "\n",
        "    # Store algorithm hyper-parameters.\n",
        "    self._step_size = step_size\n",
        "\n",
        "    # Store behavior policy.\n",
        "    self._behaviour_policy = behaviour_policy\n",
        "\n",
        "    # Containers you may find useful.\n",
        "    self._state = None\n",
        "    self._action = None\n",
        "    self._next_state = None\n",
        "\n",
        "  @property\n",
        "  def q_values(self):\n",
        "    return self._q\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    return self._behaviour_policy(self._q[observation])\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    # Set current state.\n",
        "    self._state = timestep.observation\n",
        "\n",
        "  def observe(self, action, next_timestep):\n",
        "    # Unpacking the timestep to lighten notation.\n",
        "    s = self._state\n",
        "    a = action\n",
        "    r = next_timestep.reward\n",
        "    g = next_timestep.discount\n",
        "    next_s = next_timestep.observation\n",
        "\n",
        "    # Compute the TD error.\n",
        "    self._action = a\n",
        "    self._next_state = next_s\n",
        "    # TODO complete the line below to compute the temporal difference error\n",
        "    # HINT: This is very similar to what we did for SARSA, except keep in mind\n",
        "    # that we're now taking a max over the q-values (see lecture footnotes above).\n",
        "    # You will find the function np.max() useful.\n",
        "    self._td_error = r + g * np.max(self._q[next_s]) - self._q[s, a]\n",
        "\n",
        "  def update(self):\n",
        "    # Optional unpacking to lighten notation.\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    # Update the Q-value table value at (s, a).\n",
        "    # TODO: Update the Q-value table value at (s, a).\n",
        "    # HINT: see step 6 in the pseudocode above, remember that alpha = step_size!\n",
        "    self._q[s, a] += self._step_size * self._td_error\n",
        "    # Update the current state.\n",
        "    self._state = self._next_state"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "xYOW3u7onnGO"
      },
      "source": [
        "### Run your Q-learning agent on the `obstacle` environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "3l72iVdPnnGP",
        "outputId": "46525a14-e61e-42b8-cb46-53128da3ae48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Run your Q-learning\n",
        "epsilon =   1. # @param {type:\"number\"}\n",
        "num_steps = 1e5  # @param {type:\"number\"}\n",
        "num_steps = int(num_steps)\n",
        "\n",
        "# environment\n",
        "grid = build_gridworld_task(task='obstacle')\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# behavior policy\n",
        "behavior_policy = lambda qval: epsilon_greedy(qval, epsilon=epsilon)\n",
        "\n",
        "# agent\n",
        "agent = QLearningAgent(environment_spec, behavior_policy, step_size=0.1)\n",
        "\n",
        "# run experiment and get the value functions from agent\n",
        "returns = run_loop(environment=environment, agent=agent, num_steps=num_steps)\n",
        "\n",
        "# get the q-values\n",
        "q = agent.q_values.reshape(grid.layout.shape + (4,))\n",
        "\n",
        "# visualize value functions\n",
        "print('AFTER {:,} STEPS ...'.format(num_steps))\n",
        "plot_action_values(q, epsilon=0)\n",
        "\n",
        "# visualise the greedy policy\n",
        "grid.plot_greedy_policy(q)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER 100,000 STEPS ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1vYU3nf1nnGP"
      },
      "source": [
        "### Experiment with different levels of greediness\n",
        "* The default was $\\epsilon=1.$, what does this correspond to?\n",
        "* Try also $\\epsilon =0.1, 0.5$. What do you observe? Does the behaviour policy affect the training in any way?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "A-wpFXr2nnGP",
        "outputId": "695a094b-dd2e-4f33-a6e3-1299a4345ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Run the cell\n",
        "epsilon = 0.1  # @param {type:\"number\"}\n",
        "num_steps = 1e5  # @param {type:\"number\"}\n",
        "num_steps = int(num_steps)\n",
        "\n",
        "# environment\n",
        "grid = build_gridworld_task(task='obstacle')\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# behavior policy\n",
        "behavior_policy = lambda qval: epsilon_greedy(qval, epsilon=epsilon)\n",
        "\n",
        "# agent\n",
        "agent = QLearningAgent(environment_spec, behavior_policy, step_size=0.1)\n",
        "\n",
        "# run experiment and get the value functions from agent\n",
        "returns = run_loop(environment=environment, agent=agent, num_steps=num_steps)\n",
        "\n",
        "# get the q-values\n",
        "q = agent.q_values.reshape(grid.layout.shape + (4,))\n",
        "\n",
        "# visualize value functions\n",
        "print('AFTER {:,} STEPS ...'.format(num_steps))\n",
        "plot_action_values(q, epsilon=epsilon)\n",
        "\n",
        "# visualise the greedy policy\n",
        "grid.plot_greedy_policy(q)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER 100,000 STEPS ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "27WW9YZUnnGP"
      },
      "source": [
        "---\n",
        "# Section 6: Function Approximation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Lq5kCjrhnnGQ",
        "cellView": "form",
        "outputId": "1d7faf1a-edb8-49c0-c2d4-fcbdef26e01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "6fbc379b9fe54250a2b1b30c82dbcc09",
            "60911565deb6479497fcb2074c06beae",
            "d105442c65614eaaad3ca7b0458d6005",
            "9de2efc1133e4bbfa035a29d3f1a28ef",
            "3938eb5b459b4a179b8392cefd4bc503",
            "1bfd2e94148846bd9ac7f8c7ff060559"
          ]
        }
      },
      "source": [
        "# @title Video 6: Function approximation\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1sg411M7cn\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"7_MYePyYhrM\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbc379b9fe54250a2b1b30c82dbcc09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "F9oNeQYCnnGQ"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1XIj68U3eB1bKYfIEHAcVbfwobmMYQQ4X\" width=\"500\" />\n",
        "</center>\n",
        "\n",
        "So far we only considered look-up tables for value-functions. In all previous cases every state and action pair $(\\color{red}{s}, \\color{blue}{a})$, had an entry in our $\\color{green}Q$-table. Again, this is possible in this environment as the number of states is equal to the number of cells in the grid. But this is not scalable to situations where, say, the goal location changes or the obstacles are in different locations at every episode (consider how big the table could be in this situation?).\n",
        "\n",
        "An example (not covered in this tutorial) is ATARI from pixels, where the number of possible frames an agent can see is exponential in the number of pixels on the screen.\n",
        "\n",
        "<center><img width=\"200\" alt=\"portfolio_view\" src=\"https://miro.medium.com/max/1760/1*XyIpmXXAjbXerDzmGQL1yA.gif\"></center>\n",
        "\n",
        "But what we **really** want is just to be able to *compute* the Q-value, when fed with a particular $(\\color{red}{s}, \\color{blue}{a})$ pair. So if we had a way to get a function to do this work instead of keeping a big table, we'd get around this problem.\n",
        "\n",
        "To address this, we can use **function approximation** as a way to generalize Q-values over some representation of the very large state space, and **train** them to output the values they should. In this section, we will explore $\\color{green}Q$-learning with function approximation, which (although it has been theoretically proven to diverge for some degenerate MDPs) can yield impressive results in very large environments. In particular, we will look at [Neural Fitted Q (NFQ) Iteration](http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf) and [Deep Q-Networks (DQN)](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "oguvHCuFnnGQ"
      },
      "source": [
        "## Section 6.1 Replay Buffers\n",
        "An important property of off-policy methods like $\\color{green}Q$-learning is that they involve two policies: one for exploration and one that is being optimized (via the $\\color{green}Q$-function updates). This means that we can generate data from the **behavior** policy and insert that data into some form of data storage---usually referred to as **replay**.\n",
        "\n",
        "In order to optimize the $\\color{green}Q$-function we can then sample data from the replay <font color='purple'>**dataset**</font> and use that data to perform an update. An illustration of this learning loop is shown below.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1ivTQBHWkYi_J9vWwXFd2sSWg5f2TB5T-\" width=\"400\" /></center> \n",
        "\n",
        "In the next cell we will show how to implement a simple replay buffer. This can be as simple as a python list containing transition data. In more complicated scenarios we might want to have a more performance-tuned variant, we might have to be more concerned about how large replay is and what to do when its full, and we might want to sample from replay in different ways. But a simple python list can go a surprisingly long way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "KgU3fnnOnnGR"
      },
      "source": [
        "# Simple replay buffer\n",
        "\n",
        "# Create a convenient container for the SARS tuples required by deep RL agents.\n",
        "Transitions = collections.namedtuple(\n",
        "    'Transitions', ['state', 'action', 'reward', 'discount', 'next_state'])\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "  \"\"\"A simple Python replay buffer.\"\"\"\n",
        "\n",
        "  def __init__(self, capacity: int = None):\n",
        "    self.buffer = collections.deque(maxlen=capacity)\n",
        "    self._prev_state = None\n",
        "\n",
        "  def add_first(self, initial_timestep: dm_env.TimeStep):\n",
        "    self._prev_state = initial_timestep.observation\n",
        "\n",
        "  def add(self, action: int, timestep: dm_env.TimeStep):\n",
        "    transition = Transitions(\n",
        "        state=self._prev_state,\n",
        "        action=action,\n",
        "        reward=timestep.reward,\n",
        "        discount=timestep.discount,\n",
        "        next_state=timestep.observation,\n",
        "    )\n",
        "    self.buffer.append(transition)\n",
        "    self._prev_state = timestep.observation\n",
        "\n",
        "  def sample(self, batch_size: int) -> Transitions:\n",
        "    # Sample a random batch of Transitions as a list.\n",
        "    batch_as_list = random.sample(self.buffer, batch_size)\n",
        "\n",
        "    # Convert the list of `batch_size` Transitions into a single Transitions\n",
        "    # object where each field has `batch_size` stacked fields.\n",
        "    return tree_utils.stack_sequence_fields(batch_as_list)\n",
        "\n",
        "  def flush(self) -> Transitions:\n",
        "    entire_buffer = tree_utils.stack_sequence_fields(self.buffer)\n",
        "    self.buffer.clear()\n",
        "    return entire_buffer\n",
        "\n",
        "  def is_ready(self, batch_size: int) -> bool:\n",
        "    return batch_size <= len(self.buffer)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BgnyQEOCnnGR"
      },
      "source": [
        "## Section 6.2: NFQ Agent\n",
        "[Neural Fitted Q Iteration](http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf) was one of the first papers to demonstrate how to leverage recent advances in Deep Learning to approximate the Q-value by a neural network.$^1$\n",
        "In other words, the value $\\color{green}Q(\\color{red}{s}, \\color{blue}{a})$ are approximated by the output of a neural network $\\color{green}{Q_w}(\\color{red}{s}, \\color{blue}{a})$ for each possible action $\\color{blue}{a} \\in \\color{blue}{\\mathcal{A}}$.$^2$\n",
        "\n",
        "When introducing function approximations, and neural networks in particular, we need to have a loss to optimize. But looking back at the tabular setting above, you can see that we already have some notion of error: the **TD error**.\n",
        "\n",
        "By training our neural network to output values such that the *TD error is minimized*, we will also satisfy the Bellman Optimality Equation, which is a good sufficient condition to enforce, to obtain an optimal policy.\n",
        "Thanks to automatic differentiation, we can just write the TD error as a loss, e.g., with an $\\ell^2$ loss, but others would work too:\n",
        "\n",
        "\\begin{equation}\n",
        "L(\\color{green}w) = \\mathbb{E}\\left[ \\left( \\color{green}{r} + \\gamma \\max_\\color{blue}{a'} \\color{green}{Q_w}(\\color{red}{s'}, \\color{blue}{a'})  \\color{green}{Q_w}(\\color{red}{s}, \\color{blue}{a})  \\right)^2\\right].\n",
        "\\end{equation}\n",
        "\n",
        "Then we can compute the gradient with respect to the parameters of the neural network and improve our Q-value approximation incrementally.\n",
        "\n",
        "NFQ builds on $\\color{green}Q$-learning, but if one were to update the Q-values online directly, the training can be unstable and very slow.\n",
        "Instead, NFQ uses a replay buffer, similar to what we see implemented above (Section 6.1), to update the Q-value in a batched setting.\n",
        "\n",
        "When it was introduced, it also was entirely off-policy using a uniformly random policy to collect data, which was prone to instability when applied to more complex environments (e.g. when the input are pixels or the tasks are longer and more complicated).\n",
        "But it is a good stepping stone to the more complex agents used today. Here, we will look at a slightly different and modernised implementation of NFQ.\n",
        "\n",
        "Below you will find an incomplete NFQ agent that takes in observations from a gridworld. Instead of receiving a tabular state, it receives an observation in the form of its (x,y) coordinates in the gridworld, and the (x,y) coordinates of the goal.\n",
        "<br />\n",
        "\n",
        "The goal of this coding exercise is to complete this agent by implementing the loss, using mean squared error.\n",
        "\n",
        "---\n",
        "\n",
        "<sub>$^1$ If you read the NFQ paper, they use a \"control\" notation, where there is a \"cost to minimize\", instead of \"rewards to maximize\", so don't be surprised if signs/max/min do not correspond.</sub>\n",
        "\n",
        "<sub>$^2$ We could feed it $\\color{blue}{a}$ as well and ask $Q_w$ for a single scalar value, but given we have a fixed number of actions and we usually need to take an $argmax$ over them, it's easiest to just output them all in one pass.</sub>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hFHP_jmhnnGS"
      },
      "source": [
        "### Coding Exercise 6.1: Implement NFQ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "bl2b9MTbnnGS"
      },
      "source": [
        "# Create a convenient container for the SARS tuples required by NFQ.\n",
        "Transitions = collections.namedtuple(\n",
        "    'Transitions', ['state', 'action', 'reward', 'discount', 'next_state'])\n",
        "\n",
        "\n",
        "class NeuralFittedQAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               q_network: nn.Module,\n",
        "               replay_capacity: int = 100_000,\n",
        "               epsilon: float = 0.1,\n",
        "               batch_size: int = 1,\n",
        "               learning_rate: float = 3e-4):\n",
        "\n",
        "    # Store agent hyperparameters and network.\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "    self._epsilon = epsilon\n",
        "    self._batch_size = batch_size\n",
        "    self._q_network = q_network\n",
        "\n",
        "    # Container for the computed loss (see run_loop implementation above).\n",
        "    self.last_loss = 0.0\n",
        "\n",
        "    # Create the replay buffer.\n",
        "    self._replay_buffer = ReplayBuffer(replay_capacity)\n",
        "\n",
        "    # Setup optimizer that will train the network to minimize the loss.\n",
        "    self._optimizer = torch.optim.Adam(self._q_network.parameters(),lr = learning_rate)\n",
        "    self._loss_fn = nn.MSELoss()\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Compute Q-values.\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))  # Adds batch dimension.\n",
        "    q_values = q_values.squeeze(0)   # Removes batch dimension\n",
        "\n",
        "    # Select epsilon-greedy action.\n",
        "    if self._epsilon < torch.rand(1):\n",
        "      action = q_values.argmax(axis=-1)\n",
        "    else:\n",
        "      action = torch.randint(low=0, high=self._num_actions , size=(1,), dtype=torch.int64)\n",
        "    return action\n",
        "\n",
        "  def q_values(self, observation):\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))\n",
        "    return q_values.squeeze(0).detach()\n",
        "\n",
        "  def update(self):\n",
        "\n",
        "    if not self._replay_buffer.is_ready(self._batch_size):\n",
        "      # If the replay buffer is not ready to sample from, do nothing.\n",
        "      return\n",
        "\n",
        "    # Sample a minibatch of transitions from experience replay.\n",
        "    transitions = self._replay_buffer.sample(self._batch_size)\n",
        "\n",
        "    # Note: each of these tensors will be of shape [batch_size, ...].\n",
        "    s = torch.tensor(transitions.state)\n",
        "    a = torch.tensor(transitions.action,dtype=torch.int64)\n",
        "    r = torch.tensor(transitions.reward)\n",
        "    d = torch.tensor(transitions.discount)\n",
        "    next_s = torch.tensor(transitions.next_state)\n",
        "\n",
        "    # Compute the Q-values at next states in the transitions.\n",
        "    with torch.no_grad():\n",
        "      q_next_s = self._q_network(next_s)  # Shape [batch_size, num_actions].\n",
        "      max_q_next_s = q_next_s.max(axis=-1)[0]\n",
        "      # Compute the TD error and then the losses.\n",
        "      target_q_value = r + d * max_q_next_s\n",
        "\n",
        "    # Compute the Q-values at original state.\n",
        "    q_s = self._q_network(s)\n",
        "\n",
        "    # Gather the Q-value corresponding to each action in the batch.\n",
        "    q_s_a = q_s.gather(1, a.view(-1,1)).squeeze(0)\n",
        "    #################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your implementation\n",
        "    raise NotImplementedError(\"Student exercise: complete the NFQ Agent\")\n",
        "    #################################################\n",
        "    # TODO Average the squared TD errors over the entire batch using\n",
        "    # self._loss_fn, which is defined above as nn.MSELoss()\n",
        "    # HINT: Take a look at the reference for nn.MSELoss here:\n",
        "    #  https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html\n",
        "    #  What should you put for the input and the target?\n",
        "    loss = ...\n",
        "\n",
        "    # Compute the gradients of the loss with respect to the q_network variables.\n",
        "    self._optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    # Apply the gradient update.\n",
        "    self._optimizer.step()\n",
        "\n",
        "    # Store the loss for logging purposes (see run_loop implementation above).\n",
        "    self.last_loss = loss.detach().numpy()\n",
        "\n",
        "  def observe_first(self, timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add_first(timestep)\n",
        "\n",
        "  def observe(self, action: int, next_timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add(action, next_timestep)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "L6OoVLwnnnGS"
      },
      "source": [
        "# to_remove solution\n",
        "# Create a convenient container for the SARS tuples required by NFQ.\n",
        "Transitions = collections.namedtuple(\n",
        "    'Transitions', ['state', 'action', 'reward', 'discount', 'next_state'])\n",
        "\n",
        "\n",
        "class NeuralFittedQAgent(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               q_network: nn.Module,\n",
        "               replay_capacity: int = 100_000,\n",
        "               epsilon: float = 0.1,\n",
        "               batch_size: int = 1,\n",
        "               learning_rate: float = 3e-4):\n",
        "\n",
        "    # Store agent hyperparameters and network.\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "    self._epsilon = epsilon\n",
        "    self._batch_size = batch_size\n",
        "    self._q_network = q_network\n",
        "\n",
        "    # Container for the computed loss (see run_loop implementation above).\n",
        "    self.last_loss = 0.0\n",
        "\n",
        "    # Create the replay buffer.\n",
        "    self._replay_buffer = ReplayBuffer(replay_capacity)\n",
        "\n",
        "    # Setup optimizer that will train the network to minimize the loss.\n",
        "    self._optimizer = torch.optim.Adam(self._q_network.parameters(),lr = learning_rate)\n",
        "    self._loss_fn = nn.MSELoss()\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Compute Q-values.\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))  # Adds batch dimension.\n",
        "    q_values = q_values.squeeze(0)   # Removes batch dimension\n",
        "\n",
        "    # Select epsilon-greedy action.\n",
        "    if self._epsilon < torch.rand(1):\n",
        "      action = q_values.argmax(axis=-1)\n",
        "    else:\n",
        "      action = torch.randint(low=0, high=self._num_actions , size=(1,), dtype=torch.int64)\n",
        "    return action\n",
        "\n",
        "  def q_values(self, observation):\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))\n",
        "    return q_values.squeeze(0).detach()\n",
        "\n",
        "  def update(self):\n",
        "\n",
        "    if not self._replay_buffer.is_ready(self._batch_size):\n",
        "      # If the replay buffer is not ready to sample from, do nothing.\n",
        "      return\n",
        "\n",
        "    # Sample a minibatch of transitions from experience replay.\n",
        "    transitions = self._replay_buffer.sample(self._batch_size)\n",
        "\n",
        "    # Note: each of these tensors will be of shape [batch_size, ...].\n",
        "    s = torch.tensor(transitions.state)\n",
        "    a = torch.tensor(transitions.action,dtype=torch.int64)\n",
        "    r = torch.tensor(transitions.reward)\n",
        "    d = torch.tensor(transitions.discount)\n",
        "    next_s = torch.tensor(transitions.next_state)\n",
        "\n",
        "    # Compute the Q-values at next states in the transitions.\n",
        "    with torch.no_grad():\n",
        "      q_next_s = self._q_network(next_s)  # Shape [batch_size, num_actions].\n",
        "      max_q_next_s = q_next_s.max(axis=-1)[0]\n",
        "      # Compute the TD error and then the losses.\n",
        "      target_q_value = r + d * max_q_next_s\n",
        "\n",
        "    # Compute the Q-values at original state.\n",
        "    q_s = self._q_network(s)\n",
        "\n",
        "    # Gather the Q-value corresponding to each action in the batch.\n",
        "    q_s_a = q_s.gather(1, a.view(-1,1)).squeeze(0)\n",
        "    # TODO Average the squared TD errors over the entire batch using\n",
        "    # self._loss_fn, which is defined above as nn.MSELoss()\n",
        "    # HINT: Take a look at the reference for nn.MSELoss here:\n",
        "    #  https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html\n",
        "    #  What should you put for the input and the target?\n",
        "    loss = self._loss_fn(target_q_value, q_s_a)\n",
        "\n",
        "    # Compute the gradients of the loss with respect to the q_network variables.\n",
        "    self._optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    # Apply the gradient update.\n",
        "    self._optimizer.step()\n",
        "\n",
        "    # Store the loss for logging purposes (see run_loop implementation above).\n",
        "    self.last_loss = loss.detach().numpy()\n",
        "\n",
        "  def observe_first(self, timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add_first(timestep)\n",
        "\n",
        "  def observe(self, action: int, next_timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add(action, next_timestep)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Hr0__0MYnnGT"
      },
      "source": [
        "### Train and Evaluate the NFQ Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "Rlwgz9nsnnGT"
      },
      "source": [
        "# @title Training the NFQ Agent.  { form-width: \"30%\" }\n",
        "epsilon = 0.4 # @param {type:\"number\"}\n",
        "\n",
        "max_episode_length = 200\n",
        "\n",
        "# Create the environment.\n",
        "grid = build_gridworld_task(\n",
        "    task='simple',\n",
        "    observation_type=ObservationType.AGENT_GOAL_POS,\n",
        "    max_episode_length=max_episode_length)\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# Define the neural function approximator (aka Q network).\n",
        "q_network = nn.Sequential(nn.Linear(4, 50),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(50, 50),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(50, environment_spec.actions.num_values))\n",
        "# Build the trainable Q-learning agent\n",
        "agent = NeuralFittedQAgent(\n",
        "    environment_spec,\n",
        "    q_network,\n",
        "    epsilon=epsilon,\n",
        "    replay_capacity=100_000,\n",
        "    batch_size=10,\n",
        "    learning_rate=1e-3)\n",
        "\n",
        "returns = run_loop(\n",
        "    environment=environment,\n",
        "    agent=agent,\n",
        "    num_episodes=500,\n",
        "    logger_time_delta=1.,\n",
        "    log_loss=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "PdhdqALennGU",
        "outputId": "6a4211c3-54f6-49f4-de0d-bd1b4dce2654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# @title Evaluating the agent (set $\\epsilon=0$).  { form-width: \"30%\" }\n",
        "\n",
        "# Temporarily change epsilon to be more greedy; remember to change it back.\n",
        "agent._epsilon = 0.0\n",
        "\n",
        "# Record a few episodes.\n",
        "frames = evaluate(environment, agent, evaluation_episodes=5)\n",
        "\n",
        "# Change epsilon back.\n",
        "agent._epsilon = epsilon\n",
        "\n",
        "# Display the video of the episodes.\n",
        "display_video(frames, frame_rate=6)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0 ended with reward 10.0 in 5 steps\n",
            "Episode 1 ended with reward 10.0 in 5 steps\n",
            "Episode 2 ended with reward 10.0 in 5 steps\n",
            "Episode 3 ended with reward 10.0 in 5 steps\n",
            "Episode 4 ended with reward 10.0 in 5 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video  width=\"320\" height=\"240\" controls alt=\"test\" src=\"data:video/mp4;base64,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\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "n_dHjKGAnnGU"
      },
      "source": [
        "# @title Visualise the learned Q values { form-width: \"30%\" }\n",
        "\n",
        "# Evaluate the policy for every state, similar to tabular agents above.\n",
        "\n",
        "environment.reset()\n",
        "pi = np.zeros(grid._layout_dims, dtype=np.int32)\n",
        "q = np.zeros(grid._layout_dims + (4,))\n",
        "for y in range(grid._layout_dims[0]):\n",
        "  for x in range(grid._layout_dims[1]):\n",
        "    # Hack observation to see what the Q-network would output at that point.\n",
        "    environment.set_state(x, y)\n",
        "    obs = environment.get_obs()\n",
        "    q[y, x] = np.asarray(agent.q_values(obs))\n",
        "    pi[y, x] = np.asarray(agent.select_action(obs))\n",
        "\n",
        "plot_action_values(q)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "YwNXUHTUnnGV"
      },
      "source": [
        "Compare the Q-values approximated with the neural network with the tabular case in **Section 5.3**. Notice how the neural network is generalizing from the visited states to the unvisited similar states, while in the tabular case we updated the value of each state only when we visited that state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Lt6wZ3chnnGV"
      },
      "source": [
        "### Compare the greedy and behaviour ($\\epsilon$-greedy) policies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "Rxzc0xignnGV",
        "outputId": "0a3f5b9b-1f99-45f1-bb9e-f5be096b1dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Compare the greedy policy with the agent's policy { form-width: \"30%\" }\n",
        "# @markdown Notice that the agent's behavior policy has a lot more randomness,\n",
        "# @markdown due to the high epsilon. However, the greedy policy that's learned\n",
        "# @markdown is optimal.\n",
        "\n",
        "environment.plot_greedy_policy(q)\n",
        "plt.figtext(-.08, .95, 'Greedy policy using the learnt Q-values')\n",
        "plt.title('')\n",
        "\n",
        "environment.plot_policy(pi)\n",
        "plt.figtext(-.08, .95, \"Policy using the agent's behavior policy\")\n",
        "plt.title('')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "r8L0IuUmnnGW"
      },
      "source": [
        "---\n",
        "# Section 7: DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "MS06KGz6nnGW",
        "cellView": "form",
        "outputId": "b6bd64a9-431a-4045-be9d-2b5b1298b321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "1f952fc40591425b8def52b0dd6133f9",
            "5dc2c8dcb9d64fc59cd89a3403dcf339",
            "f65aa76f7d8949198e5b57fe6675c7b4",
            "7ce3a4bc948e4f3fab5dc8b92799e834",
            "dab83d8651f34352914dbe31b66446ff",
            "010ef7325c084215b86f6ab44f1d77a4"
          ]
        }
      },
      "source": [
        " #@title Video 7: Deep Q-Networks (DQN)\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1Mo4y1Q7yD\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"HEDoNtV1y-w\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f952fc40591425b8def52b0dd6133f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "XOkFtHRCnnGW"
      },
      "source": [
        "\n",
        "<!-- <center><img src=\"https://drive.google.com/uc?id=1ivTQBHWkYi_J9vWwXFd2sSWg5f2TB5T-\" width=\"500\" /></center>  -->\n",
        "\n",
        "<center><img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_Article_BFnature14236_Fig1_HTML.jpg\" width=\"500\" /></center> \n",
        "\n",
        "In this section, we will look at an advanced deep RL Agent based on the following publication, [Playing Atari with Deep Reinforcement Learning](https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning), which introduced the first deep learning model to successfully learn control policies directly from high-dimensional pixel inputs using RL.\n",
        "\n",
        "Here the agent will act directly on a pixel representation of the gridworld. You can find an incomplete implementation below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pff6OegHnnGX"
      },
      "source": [
        "### Coding Exercise 7.1: Run a DQN Agent \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ArS6vlKwnnGX"
      },
      "source": [
        "class DQN(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               network: nn.Module,\n",
        "               replay_capacity: int = 100_000,\n",
        "               epsilon: float = 0.1,\n",
        "               batch_size: int = 1,\n",
        "               learning_rate: float = 5e-4,\n",
        "               target_update_frequency: int = 10):\n",
        "\n",
        "    # Store agent hyperparameters and network.\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "    self._epsilon = epsilon\n",
        "    self._batch_size = batch_size\n",
        "    self._q_network = q_network\n",
        "\n",
        "    # create a second q net with the same structure and initial values, which\n",
        "    # we'll be updating separately from the learned q-network.\n",
        "    self._target_network = copy.deepcopy(self._q_network)\n",
        "\n",
        "    # Container for the computed loss (see run_loop implementation above).\n",
        "    self.last_loss = 0.0\n",
        "\n",
        "    # Create the replay buffer.\n",
        "    self._replay_buffer = ReplayBuffer(replay_capacity)\n",
        "    # Keep an internal tracker of steps\n",
        "    self._current_step = 0\n",
        "\n",
        "    # How often to update the target network\n",
        "    self._target_update_frequency = target_update_frequency\n",
        "    # Setup optimizer that will train the network to minimize the loss.\n",
        "    self._optimizer = torch.optim.Adam(self._q_network.parameters(), lr=learning_rate)\n",
        "    self._loss_fn = nn.MSELoss()\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Compute Q-values.\n",
        "    # Sonnet requires a batch dimension, which we squeeze out right after.\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))  # Adds batch dimension.\n",
        "    q_values = q_values.squeeze(0)   # Removes batch dimension\n",
        "\n",
        "    # Select epsilon-greedy action.\n",
        "    if self._epsilon < torch.rand(1):\n",
        "      action = q_values.argmax(axis=-1)\n",
        "    else:\n",
        "      action = torch.randint(low=0, high=self._num_actions , size=(1,), dtype=torch.int64)\n",
        "    return action\n",
        "\n",
        "  def q_values(self, observation):\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))\n",
        "    return q_values.squeeze(0).detach()\n",
        "\n",
        "  def update(self):\n",
        "    self._current_step += 1\n",
        "\n",
        "    if not self._replay_buffer.is_ready(self._batch_size):\n",
        "      # If the replay buffer is not ready to sample from, do nothing.\n",
        "      return\n",
        "\n",
        "    # Sample a minibatch of transitions from experience replay.\n",
        "    transitions = self._replay_buffer.sample(self._batch_size)\n",
        "\n",
        "    # Optionally unpack the transitions to lighten notation.\n",
        "    # Note: each of these tensors will be of shape [batch_size, ...].\n",
        "    s = torch.tensor(transitions.state)\n",
        "    a = torch.tensor(transitions.action,dtype=torch.int64)\n",
        "    r = torch.tensor(transitions.reward)\n",
        "    d = torch.tensor(transitions.discount)\n",
        "    next_s = torch.tensor(transitions.next_state)\n",
        "\n",
        "    # Compute the Q-values at next states in the transitions.\n",
        "    with torch.no_grad():\n",
        "      #################################################\n",
        "      # Fill in missing code below (...),\n",
        "      # then remove or comment the line below to test your implementation\n",
        "      raise NotImplementedError(\"Student exercise: complete the DQN Agent\")\n",
        "      #################################################\n",
        "      #TODO get the value of the next states evaluated by the target network\n",
        "      #HINT: use self._target_network, defined above.\n",
        "      q_next_s = ...  # Shape [batch_size, num_actions].\n",
        "      max_q_next_s = q_next_s.max(axis=-1)[0]\n",
        "      # Compute the TD error and then the losses.\n",
        "      target_q_value = r + d * max_q_next_s\n",
        "\n",
        "    # Compute the Q-values at original state.\n",
        "    q_s = self._q_network(s)\n",
        "\n",
        "    # Gather the Q-value corresponding to each action in the batch.\n",
        "    q_s_a = q_s.gather(1, a.view(-1,1)).squeeze(0)\n",
        "\n",
        "    # Average the squared TD errors over the entire batch\n",
        "    loss = self._loss_fn(target_q_value, q_s_a)\n",
        "\n",
        "    # Compute the gradients of the loss with respect to the q_network variables.\n",
        "    self._optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    # Apply the gradient update.\n",
        "    self._optimizer.step()\n",
        "\n",
        "    if self._current_step % self._target_update_frequency == 0:\n",
        "      self._target_network.load_state_dict(self._q_network.state_dict())\n",
        "    # Store the loss for logging purposes (see run_loop implementation above).\n",
        "    self.last_loss = loss.detach().numpy()\n",
        "\n",
        "  def observe_first(self, timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add_first(timestep)\n",
        "\n",
        "  def observe(self, action: int, next_timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add(action, next_timestep)\n",
        "\n",
        "\n",
        "# Create a convenient container for the SARS tuples required by NFQ.\n",
        "Transitions = collections.namedtuple(\n",
        "    'Transitions', ['state', 'action', 'reward', 'discount', 'next_state'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "dnnTmettnnGY"
      },
      "source": [
        "# to_remove solution\n",
        "class DQN(acme.Actor):\n",
        "\n",
        "  def __init__(self,\n",
        "               environment_spec: specs.EnvironmentSpec,\n",
        "               network: nn.Module,\n",
        "               replay_capacity: int = 100_000,\n",
        "               epsilon: float = 0.1,\n",
        "               batch_size: int = 1,\n",
        "               learning_rate: float = 5e-4,\n",
        "               target_update_frequency: int = 10):\n",
        "\n",
        "    # Store agent hyperparameters and network.\n",
        "    self._num_actions = environment_spec.actions.num_values\n",
        "    self._epsilon = epsilon\n",
        "    self._batch_size = batch_size\n",
        "    self._q_network = q_network\n",
        "\n",
        "    # create a second q net with the same structure and initial values, which\n",
        "    # we'll be updating separately from the learned q-network.\n",
        "    self._target_network = copy.deepcopy(self._q_network)\n",
        "\n",
        "    # Container for the computed loss (see run_loop implementation above).\n",
        "    self.last_loss = 0.0\n",
        "\n",
        "    # Create the replay buffer.\n",
        "    self._replay_buffer = ReplayBuffer(replay_capacity)\n",
        "    # Keep an internal tracker of steps\n",
        "    self._current_step = 0\n",
        "\n",
        "    # How often to update the target network\n",
        "    self._target_update_frequency = target_update_frequency\n",
        "    # Setup optimizer that will train the network to minimize the loss.\n",
        "    self._optimizer = torch.optim.Adam(self._q_network.parameters(), lr=learning_rate)\n",
        "    self._loss_fn = nn.MSELoss()\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    # Compute Q-values.\n",
        "    # Sonnet requires a batch dimension, which we squeeze out right after.\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))  # Adds batch dimension.\n",
        "    q_values = q_values.squeeze(0)   # Removes batch dimension\n",
        "\n",
        "    # Select epsilon-greedy action.\n",
        "    if self._epsilon < torch.rand(1):\n",
        "      action = q_values.argmax(axis=-1)\n",
        "    else:\n",
        "      action = torch.randint(low=0, high=self._num_actions , size=(1,), dtype=torch.int64)\n",
        "    return action\n",
        "\n",
        "  def q_values(self, observation):\n",
        "    q_values = self._q_network(torch.tensor(observation).unsqueeze(0))\n",
        "    return q_values.squeeze(0).detach()\n",
        "\n",
        "  def update(self):\n",
        "    self._current_step += 1\n",
        "\n",
        "    if not self._replay_buffer.is_ready(self._batch_size):\n",
        "      # If the replay buffer is not ready to sample from, do nothing.\n",
        "      return\n",
        "\n",
        "    # Sample a minibatch of transitions from experience replay.\n",
        "    transitions = self._replay_buffer.sample(self._batch_size)\n",
        "\n",
        "    # Optionally unpack the transitions to lighten notation.\n",
        "    # Note: each of these tensors will be of shape [batch_size, ...].\n",
        "    s = torch.tensor(transitions.state)\n",
        "    a = torch.tensor(transitions.action,dtype=torch.int64)\n",
        "    r = torch.tensor(transitions.reward)\n",
        "    d = torch.tensor(transitions.discount)\n",
        "    next_s = torch.tensor(transitions.next_state)\n",
        "\n",
        "    # Compute the Q-values at next states in the transitions.\n",
        "    with torch.no_grad():\n",
        "      #TODO get the value of the next states evaluated by the target network\n",
        "      #HINT: use self._target_network, defined above.\n",
        "      q_next_s = self._target_network(next_s)  # Shape [batch_size, num_actions].\n",
        "      max_q_next_s = q_next_s.max(axis=-1)[0]\n",
        "      # Compute the TD error and then the losses.\n",
        "      target_q_value = r + d * max_q_next_s\n",
        "\n",
        "    # Compute the Q-values at original state.\n",
        "    q_s = self._q_network(s)\n",
        "\n",
        "    # Gather the Q-value corresponding to each action in the batch.\n",
        "    q_s_a = q_s.gather(1, a.view(-1,1)).squeeze(0)\n",
        "\n",
        "    # Average the squared TD errors over the entire batch\n",
        "    loss = self._loss_fn(target_q_value, q_s_a)\n",
        "\n",
        "    # Compute the gradients of the loss with respect to the q_network variables.\n",
        "    self._optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    # Apply the gradient update.\n",
        "    self._optimizer.step()\n",
        "\n",
        "    if self._current_step % self._target_update_frequency == 0:\n",
        "      self._target_network.load_state_dict(self._q_network.state_dict())\n",
        "    # Store the loss for logging purposes (see run_loop implementation above).\n",
        "    self.last_loss = loss.detach().numpy()\n",
        "\n",
        "  def observe_first(self, timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add_first(timestep)\n",
        "\n",
        "  def observe(self, action: int, next_timestep: dm_env.TimeStep):\n",
        "    self._replay_buffer.add(action, next_timestep)\n",
        "\n",
        "\n",
        "# Create a convenient container for the SARS tuples required by NFQ.\n",
        "Transitions = collections.namedtuple(\n",
        "    'Transitions', ['state', 'action', 'reward', 'discount', 'next_state'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "DNC8klhCnnGY",
        "cellView": "form"
      },
      "source": [
        "# @title Train and evaluate the DQN agent { form-width: \"30%\" }\n",
        "epsilon = 0.25  # @param {type: \"number\"}\n",
        "num_episodes = 1000  # @param {type: \"integer\"}\n",
        "\n",
        "grid = build_gridworld_task(\n",
        "    task='simple',\n",
        "    observation_type=ObservationType.GRID,\n",
        "    max_episode_length=200)\n",
        "environment, environment_spec = setup_environment(grid)\n",
        "\n",
        "# Build the agent's network.\n",
        "class Permute(nn.Module):\n",
        "  def __init__(self, order: list):\n",
        "    super(Permute,self).__init__()\n",
        "    self.order = order\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x.permute(self.order)\n",
        "\n",
        "q_network = nn.Sequential(Permute([0, 3, 1, 2]),\n",
        "                          nn.Conv2d(3, 32, kernel_size=4, stride=2,padding=1),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                          nn.ReLU(),\n",
        "                          nn.MaxPool2d(3, 1),\n",
        "                          nn.Flatten(),\n",
        "                          nn.Linear(384, 50),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(50, environment_spec.actions.num_values)\n",
        "                          )\n",
        "\n",
        "agent = DQN(\n",
        "    environment_spec=environment_spec,\n",
        "    network=q_network,\n",
        "    batch_size=10,\n",
        "    epsilon=epsilon,\n",
        "    target_update_frequency=25)\n",
        "\n",
        "returns = run_loop(\n",
        "    environment=environment,\n",
        "    agent=agent,\n",
        "    num_episodes=num_episodes,\n",
        "    num_steps=100000)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "UdZWYbhKnnGZ"
      },
      "source": [
        "# @title Visualise the learned Q values\n",
        "# Evaluate the policy for every state, similar to tabular agents above.\n",
        "pi = np.zeros(grid._layout_dims, dtype=np.int32)\n",
        "q = np.zeros(grid._layout_dims + (4,))\n",
        "for y in range(grid._layout_dims[0]):\n",
        "  for x in range(grid._layout_dims[1]):\n",
        "    # Hack observation to see what the Q-network would output at that point.\n",
        "    environment.set_state(x, y)\n",
        "    obs = environment.get_obs()\n",
        "    q[y, x] = np.asarray(agent.q_values(obs))\n",
        "    pi[y, x] = np.asarray(agent.select_action(obs))\n",
        "\n",
        "plot_action_values(q)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "S_ssn3r-nnGZ",
        "outputId": "522199f5-0816-41b2-dc7b-2ac6f47a19aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Compare the greedy policy with the agent's policy\n",
        "\n",
        "environment.plot_greedy_policy(q)\n",
        "plt.figtext(-.08, .95, 'Greedy policy using the learnt Q-values')\n",
        "plt.title('')\n",
        "\n",
        "environment.plot_policy(pi)\n",
        "plt.figtext(-.08, .95, \"Policy using the agent's epsilon-greedy policy\")\n",
        "plt.title('')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Dhlvp_m-nnGZ"
      },
      "source": [
        "---\n",
        "# Section 8: Beyond Value Based Model-Free Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "TuVOd3SZnnGa",
        "cellView": "form",
        "outputId": "bd1c4c51-5e27-496f-c0ea-6477086c7e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "7a1568b7745245b8a4c9d930509f4f23",
            "d7c73fa0c0a948ed870fc1ac331637dd",
            "7cb4d96231af45c3a9f0da58e1c92d1c",
            "56bd96f3600c4b5d92895dbfb33ba5bf",
            "1f75bbbd763743eeacf7228baaa7deab",
            "a5f6a8028001459499023268e4f57e60"
          ]
        }
      },
      "source": [
        "# @title Video 8: Other RL Methods\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV14w411977Y\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"1N4Jm9loJx4\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a1568b7745245b8a4c9d930509f4f23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4yZj4ZgxnnGa"
      },
      "source": [
        "## Cartpole task\n",
        "\n",
        "Here we switch to training on a different kind of task, which has a continuous action space: Cartpole in [Gym](https://gym.openai.com/). As you recall from the video, policy-based methods are particularly well-suited for these kinds of tasks. We will be exploring two of those methods below.\n",
        "\n",
        "\n",
        "<center><img src=\"https://user-images.githubusercontent.com/10624937/42135683-dde5c6f0-7d13-11e8-90b1-8770df3e40cf.gif\" height=\"250\" /></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "UrvLovOunnGe",
        "outputId": "1f90de5f-e457-417e-dfda-24bbce8abf92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Make a CartPole environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "SEED=2021\n",
        "# Set seeds\n",
        "env.seed(SEED)\n",
        "set_seed(SEED)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8MgwEsF7nnGe"
      },
      "source": [
        "## Section 8.1: Policy gradient\n",
        "\n",
        "Now we will turn to policy gradient methods. Rather than defining the policy in terms of a value function, i.e. $\\color{blue}\\pi(\\color{red}s) = \\arg\\max_{\\color{blue}a}\\color{green}Q(\\color{red}s, \\color{blue}a)$, we will directly parameterize the policy and write it as the distribution\n",
        "\n",
        "\\begin{equation}\n",
        "\\color{blue}a_t \\sim \\color{blue}\\pi_{\\theta}(\\color{blue}a_t|\\color{red}s_t).\n",
        "\\end{equation}\n",
        "\n",
        "Here $\\theta$ represent the parameters of the policy. We will update the policy parameters using gradient ascent to **maximize** expected future reward.\n",
        "\n",
        "One convenient way to represent the conditional distribution above is as a function that takes a state $\\color{red}s$ and returns a distribution over actions $\\color{blue}a$.\n",
        "\n",
        "Defined below is an agent which implements the REINFORCE algorithm. \n",
        "REINFORCE (Williams 1992) is the simplest model-free general reinforcement learning technique.\n",
        "\n",
        "The **basic idea** is to use probabilistic action choice. If the reward at the end turns out to be high, we make **all** actions in this sequence **more likely** (otherwise, we do the opposite).\n",
        "\n",
        "This strategy could reinforce \"bad\" actions as well, however they will turn out to be part of trajectories with low reward and will likely not get accentuated.\n",
        "\n",
        "From the lectures, we know that we need to compute\n",
        "\n",
        "\\begin{equation}\n",
        "\\nabla J(\\theta) \n",
        "= \\mathbb{E}\n",
        "\\left[\n",
        "  \\sum_{t=0}^T \\color{green} G_t \n",
        "  \\nabla\\log\\color{blue}\\pi_\\theta(\\color{red}{s_t})\n",
        "\\right]\n",
        "\\end{equation}\n",
        "\n",
        "where $\\color{green} G_t$ is the sum over future rewards from time $t$, defined as\n",
        "\n",
        "\\begin{equation}\n",
        "\\color{green} G_t \n",
        "= \\sum_{n=t}^T \\gamma^{n-t} \n",
        "\\color{green} R(\\color{red}{s_t}, \\color{blue}{a_t}, \\color{red}{s_{t+1}}).\n",
        "\\end{equation}\n",
        "\n",
        "The algorithm below will collect the state, action, and reward data in its buffer until it reaches a full trajectory. It will then update its policy given the above gradient (and the Adam optimizer).\n",
        "\n",
        "A policy gradient trains an agent without explicitly mapping the value for every state-action pair in an environment by taking small steps and updating the policy based on the reward associated with that step. In this section, we will build a small network that trains using policy gradient using PyTorch.\n",
        "\n",
        "The agent can receive a reward immediately for an action or it can receive the award at a later time such as the end of the episode.\n",
        "\n",
        "The policy function our agent will try to learn is $\\pi_\\theta(a,s)$, where $\\theta$ is the parameter vector, $s$ is a particular state, and $a$ is an action.\n",
        "\n",
        "Monte-Carlo Policy Gradient approach will be used, which means the agent will run through an entire episode and then update policy based on the rewards obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "307e4CJ6nnGf"
      },
      "source": [
        "# @title Set the hyperparameters for Policy Gradient\n",
        "\n",
        "learning_rate = 0.01  # @param {type:\"number\"}\n",
        "gamma = 0.99  # @param {type:\"number\"}\n",
        "dropout = 0.6 # @param {type:\"number\"}\n",
        "\n",
        "# Only used in Policy Gradient Method\n",
        "hidden_neurons = 128  # @param {type:\"integer\"}\n",
        "\n",
        "num_steps = 300"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BaEVnvYAnnGf"
      },
      "source": [
        "### Coding Exercise 8.1: Creating a simple neural network\n",
        "\n",
        "Below you will find some incomplete code. Fill in the missing code to construct the specified neural network.\n",
        "\n",
        "Let us define a simple feed forward neural network with one hidden layer of 128 neurons and a dropout of 0.6. Let's use Adam as our optimizer and a learning rate of 0.01. Use the hyperparameters already defined rather than using explicit values.\n",
        "\n",
        "Using dropout will significantly improve the performance of the policy. Do compare your results with and without dropout and experiment with other hyper-parameter values as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "bVALPdgAnnGf"
      },
      "source": [
        "class PolicyGradientNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PolicyGradientNet, self).__init__()\n",
        "    self.state_space = env.observation_space.shape[0]\n",
        "    self.action_space = env.action_space.n\n",
        "    #################################################\n",
        "    ## TODO for students: Define two linear layers\n",
        "    ## from the first expression\n",
        "    raise NotImplementedError(\"Student exercise: Create FF neural network.\")\n",
        "    #################################################\n",
        "    # HINT: you can construct linear layers using nn.Linear(); what are the\n",
        "    # sizes of the inputs and outputs of each of the layers? Also remember\n",
        "    # that you need to use hidden_neurons (see hyperparameters section above).\n",
        "    #   https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "    self.l1 = ...\n",
        "    self.l2 = ...\n",
        "    self.gamma = ...\n",
        "    # Episode policy and past rewards\n",
        "    self.past_policy = Variable(torch.Tensor())\n",
        "    self.reward_episode = []\n",
        "    # Overall reward and past loss\n",
        "    self.past_reward = []\n",
        "    self.past_loss = []\n",
        "\n",
        "  def forward(self, x):\n",
        "    model = torch.nn.Sequential(\n",
        "        self.l1,\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.ReLU(),\n",
        "        self.l2,\n",
        "        nn.Softmax(dim=-1)\n",
        "    )\n",
        "    return model(x)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "CJZwhQldnnGf"
      },
      "source": [
        "#to_remove solution\n",
        "class PolicyGradientNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PolicyGradientNet, self).__init__()\n",
        "    self.state_space = env.observation_space.shape[0]\n",
        "    self.action_space = env.action_space.n\n",
        "    # HINT: you can construct linear layers using nn.Linear(); what are the\n",
        "    # sizes of the inputs and outputs of each of the layers? Also remember\n",
        "    # that you need to use hidden_neurons (see hyperparameters section above).\n",
        "    #   https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "    self.l1 = nn.Linear(self.state_space, hidden_neurons, bias=False)\n",
        "    self.l2 = nn.Linear(hidden_neurons, self.action_space, bias=False)\n",
        "    self.gamma = gamma\n",
        "    # Episode policy and past rewards\n",
        "    self.past_policy = Variable(torch.Tensor())\n",
        "    self.reward_episode = []\n",
        "    # Overall reward and past loss\n",
        "    self.past_reward = []\n",
        "    self.past_loss = []\n",
        "\n",
        "  def forward(self, x):\n",
        "    model = torch.nn.Sequential(\n",
        "        self.l1,\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.ReLU(),\n",
        "        self.l2,\n",
        "        nn.Softmax(dim=-1)\n",
        "    )\n",
        "    return model(x)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "QvJGwwLwnnGh"
      },
      "source": [
        "Now let's create an instance of the network we have defined and use Adam as the optimizer using the learning_rate as hyperparameter already defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "qA8ABTYgnnGi"
      },
      "source": [
        "policy = PolicyGradientNet()\n",
        "pg_optimizer = optim.Adam(policy.parameters(), lr=learning_rate)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ZCU33Y8annGi"
      },
      "source": [
        "### Select Action\n",
        "\n",
        "The `select_action()` function chooses an action based on our policy probability distribution using the PyTorch distributions package.  Our policy returns a probability for each possible action in our action space (move left or move right) as an array of length two such as [0.7, 0.3].  We then choose an action based on these probabilities, record our history, and return our action. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "jD7hwDlennGi"
      },
      "source": [
        "def select_action(state):\n",
        "  #Select an action (0 or 1) by running policy model and choosing based on the probabilities in state\n",
        "  state = torch.from_numpy(state).type(torch.FloatTensor)\n",
        "  state = policy(Variable(state))\n",
        "  c = Categorical(state)\n",
        "  action = c.sample()\n",
        "\n",
        "  # Add log probability of chosen action\n",
        "  if policy.past_policy.dim() != 0:\n",
        "    policy.past_policy = torch.cat([policy.past_policy, c.log_prob(action).reshape(1)])\n",
        "  else:\n",
        "    policy.past_policy = (c.log_prob(action).reshape(1))\n",
        "  return action"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "LX0-Ro3NnnGi"
      },
      "source": [
        "### Update policy\n",
        "\n",
        "This function updates the policy.\n",
        "\n",
        "### Reward $G_t$\n",
        "We update our policy by taking a sample of the action value function $Q^{\\pi_\\theta} (s_t,a_t)$ by playing through episodes of the game.  $Q^{\\pi_\\theta} (s_t,a_t)$ is defined as the expected return by taking action $a$ in state $s$ following policy $\\pi$.\n",
        "\n",
        "We know that for every step the simulation continues we receive a reward of 1.  We can use this to calculate the policy gradient at each time step, where $r$ is the reward for a particular state-action pair.  Rather than using the instantaneous reward, $r$, we instead use a long term reward $ v_{t} $ where $v_t$ is the discounted sum of all future rewards for the length of the episode.   $v_{t}$ is then,\n",
        "\n",
        "\\begin{equation}\n",
        "\\color{green} G_t \n",
        "= \\sum_{n=t}^T \\gamma^{n-t} \n",
        "\\color{green} R(\\color{red}{s_t}, \\color{blue}{a_t}, \\color{red}{s_{t+1}}).\n",
        "\\end{equation}\n",
        "\n",
        "where $\\gamma$ is the discount factor (0.99).  For example, if an episode lasts 5 steps, the reward for each step will be [4.90, 3.94, 2.97, 1.99, 1].\n",
        "Next we scale our reward vector by substracting the mean from each element and scaling to unit variance by dividing by the standard deviation.  This practice is common for machine learning applications and the same operation as Scikit Learn's __[StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)__.  It also has the effect of compensating for future uncertainty.\n",
        "\n",
        "## Update Policy\n",
        "After each episode we apply Monte-Carlo Policy Gradient to improve our policy according to the equation:\n",
        "\n",
        "\\begin{equation}\n",
        "\\Delta\\theta_t = \\alpha\\nabla_\\theta \\, \\log \\pi_\\theta (s_t,a_t)G_t\n",
        "\\end{equation}\n",
        "\n",
        "We will then feed our policy history multiplied by our rewards to our optimizer and update the weights of our neural network using stochastic gradient **ascent**.  This should increase the likelihood of actions that got our agent a larger reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "aklU4WQvnnGj"
      },
      "source": [
        "The following function ```update_policy``` updates the network weights and therefore the policy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "mojCZBC_nnGj"
      },
      "source": [
        "def update_policy():\n",
        "  R = 0\n",
        "  rewards = []\n",
        "\n",
        "  # Discount future rewards back to the present using gamma\n",
        "  for r in policy.reward_episode[::-1]:\n",
        "    R = r + policy.gamma * R\n",
        "    rewards.insert(0, R)\n",
        "\n",
        "  # Scale rewards\n",
        "  rewards = torch.FloatTensor(rewards)\n",
        "  rewards = (rewards - rewards.mean()) / (rewards.std() +\n",
        "                                          np.finfo(np.float32).eps)\n",
        "\n",
        "  # Calculate loss\n",
        "  pg_loss = (torch.sum(torch.mul(policy.past_policy,\n",
        "                              Variable(rewards)).mul(-1), -1))\n",
        "  # Update network weights\n",
        "  # Use zero_grad(), backward() and step() methods of the optimizer instance.\n",
        "  pg_optimizer.zero_grad()\n",
        "  pg_loss.backward()\n",
        "  # Update the weights\n",
        "  for param in policy.parameters():\n",
        "      param.grad.data.clamp_(-1, 1)\n",
        "  pg_optimizer.step()\n",
        "\n",
        "  # Save and intialize episode past counters\n",
        "  policy.past_loss.append(pg_loss.item())\n",
        "  policy.past_reward.append(np.sum(policy.reward_episode))\n",
        "  policy.past_policy = Variable(torch.Tensor())\n",
        "  policy.reward_episode= []"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Uim1eO1gnnGj"
      },
      "source": [
        "### Training\n",
        "This is our main policy training loop.  For each step in a training episode, we choose an action, take a step through the environment, and record the resulting new state and reward.  We call update_policy() at the end of each episode to feed the episode history to our neural network and improve our policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "I0oGhVUtnnGk"
      },
      "source": [
        "def policy_gradient_train(episodes):\n",
        "  running_reward = 10\n",
        "  for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    for time in range(1000):\n",
        "      action = select_action(state)\n",
        "      # Step through environment using chosen action\n",
        "      state, reward, done, _ = env.step(action.item())\n",
        "\n",
        "      # Save reward\n",
        "      policy.reward_episode.append(reward)\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    # Used to determine when the environment is solved.\n",
        "    running_reward = (running_reward * gamma) + (time * (1 - gamma))\n",
        "\n",
        "    update_policy()\n",
        "\n",
        "    if episode % 50 == 0:\n",
        "      print(f\"Episode {episode}\\tLast length: {time:5.0f}\"\n",
        "            f\"\\tAverage length: {running_reward:.2f}\")\n",
        "\n",
        "    if running_reward > env.spec.reward_threshold:\n",
        "      print(f\"Solved! Running reward is now {running_reward} \"\n",
        "            f\"and the last episode runs to {time} time steps!\")\n",
        "      break"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "uXdo1OofnnGk"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "fssUSjeZnnGk",
        "outputId": "fa23d56e-8f25-459d-8fc8-4dffe86a6083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "episodes = 500   #@param {type:\"integer\"}\n",
        "policy_gradient_train(episodes)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0\tLast length:    12\tAverage length: 10.02\n",
            "Episode 50\tLast length:   394\tAverage length: 40.32\n",
            "Episode 100\tLast length:   289\tAverage length: 117.11\n",
            "Episode 150\tLast length:   132\tAverage length: 189.72\n",
            "Episode 200\tLast length:   273\tAverage length: 242.07\n",
            "Episode 250\tLast length:   233\tAverage length: 278.92\n",
            "Episode 300\tLast length:   499\tAverage length: 340.06\n",
            "Episode 350\tLast length:   499\tAverage length: 367.78\n",
            "Episode 400\tLast length:   306\tAverage length: 379.29\n",
            "Episode 450\tLast length:   297\tAverage length: 394.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4UMqgHqYnnGk"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Oq3EphXBnnGl"
      },
      "source": [
        "#@title Plot the training performance for policy gradient\n",
        "\n",
        "def plot_policy_gradient_training():\n",
        "  window = int(episodes / 20)\n",
        "\n",
        "  fig, ((ax1), (ax2)) = plt.subplots(1, 2, sharey=True, figsize=[15, 4]);\n",
        "  rolling_mean = pd.Series(policy.past_reward).rolling(window).mean()\n",
        "  std = pd.Series(policy.past_reward).rolling(window).std()\n",
        "  ax1.plot(rolling_mean)\n",
        "  ax1.fill_between(range(len(policy.past_reward)),\n",
        "                   rolling_mean-std, rolling_mean+std,\n",
        "                   color='orange', alpha=0.2)\n",
        "  ax1.set_title(f\"Episode Length Moving Average ({window}-episode window)\")\n",
        "  ax1.set_xlabel('Episode'); ax1.set_ylabel('Episode Length')\n",
        "\n",
        "  ax2.plot(policy.past_reward)\n",
        "  ax2.set_title('Episode Length')\n",
        "  ax2.set_xlabel('Episode')\n",
        "  ax2.set_ylabel('Episode Length')\n",
        "\n",
        "  fig.tight_layout(pad=2)\n",
        "  plt.show()\n",
        "\n",
        "plot_policy_gradient_training()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "CMK8wMq6nnGl"
      },
      "source": [
        "### Exercise 8.1: Explore different hyperparameters.\n",
        "\n",
        "Try running the model again, by modifying the hyperparameters and observe the outputs. Be sure to rerun the function definition cells in order to pick up on the updated values.\n",
        "\n",
        "What do you see when you \n",
        "\n",
        "1. increase learning rate\n",
        "2. decrease learning rate\n",
        "3. decrease gamma\n",
        "4. increase number of hidden neurons in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1fMEyDVJnnGl"
      },
      "source": [
        "## Section 8.2: Actor-critic\n",
        "\n",
        "Recall the policy gradient\n",
        "\n",
        "\\begin{quation}\n",
        "\\nabla J(\\theta) \n",
        "= \\mathbb{E}\n",
        "\\left[\n",
        "  \\sum_{t=0}^T \\color{green} G_t \n",
        "  \\nabla\\log\\color{blue}\\pi_\\theta(\\color{red}{s_t})\n",
        "\\right]\n",
        "\\end{equation}\n",
        "\n",
        "The policy parameters are updated using Monte Carlo technique and uses random samples. This introduces high variability in log probabilities and cumulative reward values. This leads to noisy gradients and can cause unstable learning.\n",
        "\n",
        "One way to reduce variance and increase stability is subtracting the cumulative reward by a baseline:\n",
        "\n",
        "\\begin{equation}\n",
        "\\nabla J(\\theta) \n",
        "= \\mathbb{E}\n",
        "\\left[\n",
        "   \\sum_{t=0}^T \\color{green} (G_t  - b)\n",
        "  \\nabla\\log\\color{blue}\\pi_\\theta(\\color{red}{s_t})\n",
        "\\right]\n",
        "\\end{equation}\n",
        "\n",
        "Intuitively, reducing cumulative reward will make smaller gradients and thus smaller and more stable (hopefully) updates.\n",
        "\n",
        "From the lecture slides, we know that in Actor Critic Method:\n",
        "1. The Critic estimates the value function. This could be the action-value (the Q value) or state-value (the V value).\n",
        "2. The Actor updates the policy distribution in the direction suggested by the Critic (such as with policy gradients).\n",
        "\n",
        "Both the Critic and Actor functions are parameterized with neural networks. The \"Critic\" network parameterizes the Q-value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "UaZJcBtinnGl"
      },
      "source": [
        "# @title Set the hyperparameters for Actor Critic\n",
        "\n",
        "SEED=2021\n",
        "learning_rate = 0.01  # @param {type:\"number\"}\n",
        "gamma = 0.99  # @param {type:\"number\"}\n",
        "dropout = 0.6\n",
        "\n",
        "# Only used in Actor-Critic Method\n",
        "hidden_size = 256  #@ param {type:\"integer\"}\n",
        "\n",
        "num_steps = 300"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kENjC665nnGm"
      },
      "source": [
        "### Actor Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "POMqrtxznnGm"
      },
      "source": [
        "class ActorCriticNet(nn.Module):\n",
        "  def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "    super(ActorCriticNet, self).__init__()\n",
        "\n",
        "    self.num_actions = num_actions\n",
        "    self.critic_linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "    self.critic_linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    self.actor_linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "    self.actor_linear2 = nn.Linear(hidden_size, num_actions)\n",
        "\n",
        "    self.all_rewards = []\n",
        "    self.all_lengths = []\n",
        "    self.average_lengths = []\n",
        "\n",
        "  def forward(self, state):\n",
        "    state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "    value = F.relu(self.critic_linear1(state))\n",
        "    value = self.critic_linear2(value)\n",
        "\n",
        "    policy_dist = F.relu(self.actor_linear1(state))\n",
        "    policy_dist = F.softmax(self.actor_linear2(policy_dist), dim=1)\n",
        "\n",
        "    return value, policy_dist"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "s0g5hWQ6nnGm"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "eJ_EXdpNnnGn"
      },
      "source": [
        "def actor_critic_train(episodes):\n",
        "  all_lengths = []\n",
        "  average_lengths = []\n",
        "  all_rewards = []\n",
        "  entropy_term = 0\n",
        "\n",
        "  for episode in range(episodes):\n",
        "    log_probs = []\n",
        "    values = []\n",
        "    rewards = []\n",
        "\n",
        "    state = env.reset()\n",
        "    for steps in range(num_steps):\n",
        "      value, policy_dist = actor_critic.forward(state)\n",
        "      value = value.detach().numpy()[0, 0]\n",
        "      dist = policy_dist.detach().numpy()\n",
        "\n",
        "      action = np.random.choice(num_outputs, p=np.squeeze(dist))\n",
        "      log_prob = torch.log(policy_dist.squeeze(0)[action])\n",
        "      entropy = -np.sum(np.mean(dist) * np.log(dist))\n",
        "      new_state, reward, done, _ = env.step(action)\n",
        "\n",
        "      rewards.append(reward)\n",
        "      values.append(value)\n",
        "      log_probs.append(log_prob)\n",
        "      entropy_term += entropy\n",
        "      state = new_state\n",
        "\n",
        "      if done or steps == num_steps - 1:\n",
        "        qval, _ = actor_critic.forward(new_state)\n",
        "        qval = qval.detach().numpy()[0, 0]\n",
        "        all_rewards.append(np.sum(rewards))\n",
        "        all_lengths.append(steps)\n",
        "        average_lengths.append(np.mean(all_lengths[-10:]))\n",
        "        if episode % 50 == 0:\n",
        "          print(f\"episode: {episode},\\treward: {np.sum(rewards)},\"\n",
        "                f\"\\ttotal length: {steps},\"\n",
        "                f\"\\taverage length: {average_lengths[-1]}\")\n",
        "        break\n",
        "\n",
        "    # compute Q values\n",
        "    qvals = np.zeros_like(values)\n",
        "    for t in reversed(range(len(rewards))):\n",
        "      qval = rewards[t] + gamma * qval\n",
        "      qvals[t] = qval\n",
        "\n",
        "    #update actor critic\n",
        "    values = torch.FloatTensor(values)\n",
        "    qvals = torch.FloatTensor(qvals)\n",
        "    log_probs = torch.stack(log_probs)\n",
        "\n",
        "    advantage = qvals - values\n",
        "    actor_loss = (-log_probs * advantage).mean()\n",
        "    critic_loss = 0.5 * advantage.pow(2).mean()\n",
        "    ac_loss = actor_loss + critic_loss + 0.001 * entropy_term\n",
        "\n",
        "    ac_optimizer.zero_grad()\n",
        "    ac_loss.backward()\n",
        "    ac_optimizer.step()\n",
        "\n",
        "  # Store results\n",
        "  actor_critic.average_lengths = average_lengths\n",
        "  actor_critic.all_rewards = all_rewards\n",
        "  actor_critic.all_lengths = all_lengths"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ks79T8EnnnGo"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "YW7x54gmnnGo",
        "cellView": "form",
        "outputId": "48fd1ce3-143e-44a0-d77f-3a6cdad7a740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "episodes = 500   # @param {type:\"integer\"}\n",
        "\n",
        "env.reset()\n",
        "\n",
        "num_inputs = env.observation_space.shape[0]\n",
        "num_outputs = env.action_space.n\n",
        "\n",
        "actor_critic = ActorCriticNet(num_inputs, num_outputs, hidden_size)\n",
        "ac_optimizer = optim.Adam(actor_critic.parameters())\n",
        "\n",
        "actor_critic_train(episodes)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0,\treward: 34.0,\ttotal length: 33,\taverage length: 33.0\n",
            "episode: 50,\treward: 41.0,\ttotal length: 40,\taverage length: 34.1\n",
            "episode: 100,\treward: 17.0,\ttotal length: 16,\taverage length: 29.1\n",
            "episode: 150,\treward: 32.0,\ttotal length: 31,\taverage length: 32.3\n",
            "episode: 200,\treward: 86.0,\ttotal length: 85,\taverage length: 65.4\n",
            "episode: 250,\treward: 17.0,\ttotal length: 16,\taverage length: 44.2\n",
            "episode: 300,\treward: 21.0,\ttotal length: 20,\taverage length: 78.6\n",
            "episode: 350,\treward: 109.0,\ttotal length: 108,\taverage length: 89.6\n",
            "episode: 400,\treward: 176.0,\ttotal length: 175,\taverage length: 161.0\n",
            "episode: 450,\treward: 127.0,\ttotal length: 126,\taverage length: 113.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3DSpczLynnGo"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "cellView": "form",
        "id": "dxedhtW7nnGp"
      },
      "source": [
        "# @title Plot the training performance for Actor Critic\n",
        "def plot_actor_critic_training():\n",
        "  window = int(episodes / 20)\n",
        "\n",
        "  plt.figure(figsize=(15, 4))\n",
        "  plt.subplot(1, 2, 1)\n",
        "\n",
        "  smoothed_rewards = pd.Series(actor_critic.all_rewards).rolling(window).mean()\n",
        "  std = pd.Series(actor_critic.all_rewards).rolling(window).std()\n",
        "\n",
        "  plt.plot(smoothed_rewards, label='Smoothed rewards')\n",
        "  plt.fill_between(range(len(smoothed_rewards)),\n",
        "                   smoothed_rewards-std, smoothed_rewards+std,\n",
        "                   color='orange', alpha=0.2)\n",
        "\n",
        "  plt.xlabel('Episode')\n",
        "  plt.ylabel('Reward')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(actor_critic.all_lengths, label='All lengths')\n",
        "  plt.plot(actor_critic.average_lengths, label='Average lengths')\n",
        "  plt.xlabel('Episode')\n",
        "  plt.ylabel('Episode length')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "plot_actor_critic_training()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "O03xS8uZnnGp"
      },
      "source": [
        "### Exercise 8.3: Effect of episodes on performance\n",
        "\n",
        "Change the episodes from 500 to 3000 and observe the performance impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "FLjC-EPpnnGp"
      },
      "source": [
        "### Exercise 8.4: Effect of learning rate on performance\n",
        "\n",
        "Modify the hyperparameters related to learning_rate and gamma and observe the impact on the performance.\n",
        "\n",
        "Be sure to rerun the function definition cells in order to pick up on the updated values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Z1HFJuuynnGq"
      },
      "source": [
        "---\n",
        "# Section 9: RL in the real world"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "huRUESssnnGq",
        "cellView": "form",
        "outputId": "32cbf63f-f7f2-444d-f60b-6458f6574e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "cd0a059e3fd44dc9b082b634cf43f20c",
            "5501078a93754e359f226f249e3d2efa",
            "53a707f62ba1455292927059337d2d5d",
            "5ce456791ed64fb5be81c94349e61122",
            "f42011b31b884199bb94d273b5837c8b",
            "9c4589b30b8f45829017ed9ddc9ee452"
          ]
        }
      },
      "source": [
        "# @title Video 9: Real-world applications and ethics\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1Nq4y1X7AF\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"5kBtiW88QVw\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd0a059e3fd44dc9b082b634cf43f20c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3-UnLM8unnGq"
      },
      "source": [
        "## Exercise 9: Group discussion\n",
        "\n",
        "Form a group of 2-3 and have discussions (roughly 3 minutes each) of the following questions:\n",
        "\n",
        "1. **Safety**: what are some safety issues that arise in RL that dont arise with e.g. supervised learning?\n",
        "\n",
        "2. **Generalization**: What happens if your RL agent is presented with data it hasnt trained on? (goes out of distribution)\n",
        "\n",
        "3. How important do you think **interpretability** is in the ethical and safe deployment of RL agents in the real world? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "OGa5gVhdnnGq",
        "outputId": "96f4cf02-e483-4d6e-ebdb-c1d5c23a134a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# to_remove explanation\n",
        "\"\"\"\n",
        "For TAs:\n",
        "\n",
        "Encourage students to consider different examples of RL in the real\n",
        "world that have safety issues that don't necessarily come up with supervised\n",
        "learning, due to the fact that in RL, agents must *interact* with the world,\n",
        "and explore.\n",
        "\n",
        "Self-driving cars is a really salient example, but also consider using RL in\n",
        "the health-care setting, where exploration would be unethical. What can be done\n",
        "in this case? (Consider offline RL, using simulations, safeguards, etc.)\n",
        "\n",
        "Interpretability can help with the safe deployment of deep RL algorithms\n",
        "because we can have higher expectation that our agents will not perform\n",
        "unpredictable actions, or if they do, we can at least understand why they did,\n",
        "and work to prevent such occurrences in the future.\n",
        "\n",
        "This should be a very open-ended discussion. Try to have everyone say at least\n",
        "one thing. They can either take these 3 questions in turn, with 3-4 minutes\n",
        "allotted to each, or address them all at once, and allow for a more natural\n",
        "conversation.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nFor TAs:\\n\\nEncourage students to consider different examples of RL in the real\\nworld that have safety issues that don't necessarily come up with supervised\\nlearning, due to the fact that in RL, agents must *interact* with the world,\\nand explore.\\n\\nSelf-driving cars is a really salient example, but also consider using RL in\\nthe health-care setting, where exploration would be unethical. What can be done\\nin this case? (Consider offline RL, using simulations, safeguards, etc.)\\n\\nInterpretability can help with the safe deployment of deep RL algorithms\\nbecause we can have higher expectation that our agents will not perform\\nunpredictable actions, or if they do, we can at least understand why they did,\\nand work to prevent such occurrences in the future.\\n\\nThis should be a very open-ended discussion. Try to have everyone say at least\\none thing. They can either take these 3 questions in turn, with 3-4 minutes\\nallotted to each, or address them all at once, and allow for a more natural\\nconversation.\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "DQpGjUaznnGq"
      },
      "source": [
        "---\n",
        "# Section 10: How to learn more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "PhoJ-8BGnnGr",
        "cellView": "form",
        "outputId": "f4c0c552-d98c-48a7-8894-454601530e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "a6bf8154b2b24b06bbf3b96f79bf8f85",
            "f5f86358cc394424864aaa487affaf6d",
            "8a77803a3b7e4aa48dacb9bea954cba8",
            "260d539b672e42f5be296d4f09ceca74",
            "7e3ef32ba7534aecb29567e1e43891cf",
            "1b2058db7a9940f3882abb0f46b2224f"
          ]
        }
      },
      "source": [
        "# @title Video 10: How to learn more\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1WM4y1T7G5\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"dKaOpgor5Ek\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6bf8154b2b24b06bbf3b96f79bf8f85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9VVWewLSnnGr"
      },
      "source": [
        "---\n",
        "# Appendix and further reading\n",
        "\n",
        "Books and lecture notes\n",
        "*   [Reinforcement Learning: an Introduction by Sutton & Barto](http://incompleteideas.net/book/RLbook2018.pdf)\n",
        "* [Algorithms for Reinforcement Learning by Csaba Szepesvari](https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf)\n",
        "\n",
        "Lectures and course \n",
        "*   [RL Course by David Silver](https://www.youtube.com/playlist?list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-)\n",
        "*   [Reinforcement Learning Course | UCL & DeepMind](https://www.youtube.com/playlist?list=PLqYmG7hTraZBKeNJ-JE_eyJHZ7XgBoAyb)\n",
        "*   [Emma Brunskill Stanford RL Course](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)\n",
        "*   [RL Course on Coursera by Martha White & Adam White](https://www.coursera.org/specializations/reinforcement-learning)\n",
        "\n",
        "More practical:\n",
        "* [Spinning Up in Deep RL by Josh Achiam](https://spinningup.openai.com/en/latest/)\n",
        "*   [Acme white paper](https://arxiv.org/abs/2006.00979) & [Colab tutorial](https://github.com/deepmind/acme/blob/master/examples/tutorial.ipynb)\n",
        "\n",
        " <br>\n",
        "\n",
        "[Link to the tweet thread with resources recommended by the community](https://twitter.com/FeryalMP/status/1407272291579355136?s=20). \n",
        " \n",
        "<br>\n",
        "\n",
        "This Colab is based on the [EEML 2020 RL practical](https://colab.research.google.com/github/eemlcommunity/PracticalSessions2020/blob/master/rl/EEML2020_RL_Tutorial.ipynb) by Feryal Behbahani & Gheorghe Comanici. If you are interested in JAX you should try the colab. If you are interested in Tensorflow, there is also a version of the colab for the [MLSS 2020 RL Tutorial](https://github.com/Feryal/rl_mlss_2020) that you can try :)\n"
      ]
    }
  ]
}